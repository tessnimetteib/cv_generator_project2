{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f6da52",
   "metadata": {},
   "source": [
    "# üéì Advanced Deep Learning Course - Final Project\n",
    "AI-Powered CV Analysis System with RAG and Advanced Skill Matching\n",
    "\n",
    "**üìã Table of Contents**\n",
    "\n",
    "Project Overview\n",
    "\n",
    "System Architecture\n",
    "\n",
    "Technical Stack\n",
    "\n",
    "Implementation Details\n",
    "\n",
    "Demo & Results\n",
    "\n",
    "Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91dfc0",
   "metadata": {},
   "source": [
    "**üéØProject Overview**\n",
    "\n",
    "Business Problem\n",
    "\n",
    "Traditional CV screening processes are:\n",
    "\n",
    "- Time-consuming: Hours spent manually reviewing resumes\n",
    "\n",
    "- Prone to bias: Human reviewers miss qualified candidates\n",
    "\n",
    "- Inefficient: Keyword-based filtering lacks semantic understanding\n",
    "\n",
    "- Inconsistent: Varying evaluation standards across reviewers\n",
    "\n",
    "\n",
    "**AI-Powered Solution**\n",
    "\n",
    "We developed a comprehensive CV analysis system that:\n",
    "\n",
    "- Automates resume screening using RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "- Extracts and matches skills across 22 job categories\n",
    "\n",
    "- Generates intelligent interview questions with model answers\n",
    "\n",
    "- Provides professional CV analysis with actionable recommendations\n",
    "\n",
    "- Integrates multiple AI models for comprehensive assessment\n",
    "\n",
    "\n",
    "**Key Innovations**\n",
    "\n",
    "- True RAG Implementation: Semantic understanding beyond keyword matching\n",
    "\n",
    "- Dynamic Skill Analysis: Domain-agnostic skill extraction across industries\n",
    "\n",
    "- Evidence-Based Matching: Contextual validation of skill claims\n",
    "\n",
    "- Professional Outputs: HR-grade assessments and recommendations\n",
    "\n",
    "- Multi-Model Integration: Combining Gemini 2.0 Flash with custom NLP pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc1f52",
   "metadata": {},
   "source": [
    " System Architecture\n",
    "Complete Pipeline\n",
    "\n",
    "üìÑ PDF Resumes\n",
    "\n",
    "    ‚Üì\n",
    "üîß Multi-Method Processing (pdfplumber + PyPDF2 + LangChain)\n",
    "\n",
    "    ‚Üì  \n",
    "üéØ Advanced Skill Extraction (DynamicSkillAnalyzer)\n",
    "\n",
    "    ‚Üì\n",
    "üìä Vector Database (FAISS + Sentence Transformers)\n",
    "\n",
    "    ‚Üì\n",
    "ü§ñ RAG System with Semantic Search\n",
    "\n",
    "    ‚Üì\n",
    "üìà Multi-Stage AI Analysis\n",
    "\n",
    "    ‚îú‚îÄ‚îÄ üîç Skill Gap Analysis\n",
    "    ‚îú‚îÄ‚îÄ üìù CV Quality Assessment  \n",
    "    ‚îú‚îÄ‚îÄ ‚ùì Interview Question Generation\n",
    "    ‚îî‚îÄ‚îÄ üí° Professional Recommendations\n",
    "    ‚Üì\n",
    "üéØ Business Applications (HR, Recruitment, Career Coaching)\n",
    "\n",
    "Component Integration:\n",
    "\n",
    "- PDF Processing Layer - Handles any resume format\n",
    "\n",
    "- NLP Engine - spaCy + Sentence Transformers for understanding\n",
    "\n",
    "- AI Analysis Layer - Gemini 2.0 Flash for advanced reasoning\n",
    "\n",
    "- RAG Framework - LangChain with FAISS for smart search\n",
    "\n",
    "- Professional Outputs - Business-ready reports and insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b22725",
   "metadata": {},
   "source": [
    "## üéØ Advanced Skill Analysis Engine\n",
    "\n",
    "### **Core Features**\n",
    "- **22 Job Categories** - IT, Finance, Healthcare, Marketing, Engineering, etc.\n",
    "- **500+ Tools & Platforms** - Technical, business, creative, and specialized tools\n",
    "- **Evidence Validation** - Finds contextual proof of skills in resume content\n",
    "- **Semantic Matching** - Goes beyond keywords to actual meaning understanding\n",
    "\n",
    "### **Technical Implementation**\n",
    "- **Sentence Transformers** - Semantic embeddings for skill similarity\n",
    "- **spaCy NER** - Named entity recognition for skill extraction\n",
    "- **Multi-Method Extraction** - Tools, platforms, categories, and section analysis\n",
    "- **Strict Filtering** - Clean, meaningful skills only\n",
    "\n",
    "This analyzer can process resumes from any industry and extract relevant skills with evidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What this cell does :vImplements DynamicSkillAnalyzer ‚Äî a domain-agnostic component that\n",
    "#   extracts clean skills from CVs and job descriptions, finds short supporting evidence sentences,\n",
    "#   and computes combined keyword + semantic similarity scores to match candidate skills to job requirements.\n",
    "# Inputs (for the grader): raw CV text (string) and raw JD text (string) preprocessed similarly to your corpus.\n",
    "# Outputs (what you will show): matched_skills list (skill pairs + score + truncated evidence),\n",
    "#   missing_skills list (JD skills with JD context), counts (cv_skill_count, jd_skill_count) and match_percentage.\n",
    "# Quick runtime note: uses sentence-transformers/all-MiniLM-L6-v2 and spaCy en_core_web_lg ‚Äî these models\n",
    "#   can be memory/time heavy; use a GPU or smaller models for quick demos.\n",
    "# Why this matters : It provides evidence-backed skill matching that the RAG agent can\n",
    "#   use to build targeted retrieval queries and produce grounded answers with traceable sources.\n",
    "\n",
    "\n",
    "# using nlp models\n",
    "\n",
    "# Imports: logging (debug/info), re (regex parsing), cosine_similarity (semantic scoring),\n",
    "# SentenceTransformer for semantic embeddings, spaCy for NER/lemmatization used in evidence rules.\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "\n",
    "# Setup logging\n",
    "# Initialize a module logger so the notebook output shows progress and warnings during extraction.\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Class summary:\n",
    "# - Multi-strategy skill extraction: direct tool matching, category phrase matching, and section parsing.\n",
    "# - Evidence extraction: finds the best supporting sentence(s) per skill while excluding education/contact noise.\n",
    "# - Matching: combines keyword overlap and semantic similarity with configurable weights & threshold\n",
    "class DynamicSkillAnalyzer:\n",
    "    \"\"\"\n",
    "    Optimized Domain-Agnostic Skill Analyzer - Clean skills across all industries\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_CONFIG = {\n",
    "        \"model_name\": 'all-MiniLM-L6-v2',\n",
    "        \"similarity_threshold\": 0.5,  # Increased for better precision\n",
    "        \"weight_overlap\": 0.6,\n",
    "        \"weight_semantic\": 0.4,\n",
    "    }\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.config = self.DEFAULT_CONFIG.copy()\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "\n",
    "        self.sentence_model = SentenceTransformer(self.config[\"model_name\"])\n",
    "        self.ner_model = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "        self.SIMILARITY_THRESHOLD = self.config[\"similarity_threshold\"]\n",
    "        self.WEIGHT_OVERLAP = self.config[\"weight_overlap\"]\n",
    "        self.WEIGHT_SEMANTIC = self.config[\"weight_semantic\"]\n",
    "\n",
    "        # Store text for evidence validation\n",
    "        self.cv_text = \"\"\n",
    "        self.jd_text = \"\"\n",
    "\n",
    "        # Comprehensive tools and platforms across domains\n",
    "        self.TOOLS_PLATFORMS = {\n",
    "            # Technical\n",
    "            'python', 'java', 'javascript', 'typescript', 'c++', 'c#', 'go', 'rust', 'ruby', 'php', 'swift', 'kotlin',\n",
    "            'django', 'flask', 'spring', 'react', 'angular', 'vue', 'node.js', 'express', 'laravel', 'rails',\n",
    "            'aws', 'gcp', 'azure', 'docker', 'kubernetes', 'terraform', 'ansible', 'jenkins', 'gitlab', 'github',\n",
    "            'mysql', 'mongodb', 'postgresql', 'redis', 'cassandra', 'dynamodb', 'oracle',\n",
    "            'git', 'jira', 'confluence', 'linux', 'unix', 'bash', 'shell',\n",
    "\n",
    "            # Marketing\n",
    "            'google analytics', 'google ads', 'facebook ads', 'mailchimp', 'hubspot',\n",
    "            'hootsuite', 'buffer', 'sprout social', 'semrush', 'ahrefs', 'moz',\n",
    "            'linkedin', 'instagram', 'twitter', 'tiktok', 'pinterest',\n",
    "\n",
    "            # Business\n",
    "            'excel', 'powerpoint', 'word', 'outlook', 'salesforce', 'sap', 'oracle',\n",
    "            'trello', 'asana', 'slack', 'teams',\n",
    "\n",
    "            # Design\n",
    "            'figma', 'sketch', 'adobe', 'photoshop', 'illustrator', 'indesign',\n",
    "            'canva', 'invision', 'marvel', 'principle',\n",
    "\n",
    "            # Healthcare\n",
    "            'epic', 'cerner', 'meditech', 'allscripts', 'ehr', 'emr'\n",
    "        }\n",
    "\n",
    "        # Clean skill categories (no partial phrases)\n",
    "        self.SKILL_CATEGORIES = {\n",
    "            # Marketing\n",
    "            'seo', 'ppc', 'social media', 'email marketing', 'content marketing',\n",
    "            'digital marketing', 'analytics', 'conversion optimization', 'crm',\n",
    "            'market research', 'brand management', 'advertising',\n",
    "\n",
    "            # Technical\n",
    "            'web development', 'mobile development', 'cloud computing', 'devops',\n",
    "            'database management', 'system administration', 'cybersecurity',\n",
    "            'machine learning', 'data science', 'api development', 'microservices',\n",
    "\n",
    "            # Business\n",
    "            'project management', 'business analysis', 'financial analysis',\n",
    "            'strategic planning', 'stakeholder management', 'process improvement',\n",
    "            'risk management', 'budget management', 'team leadership',\n",
    "\n",
    "            # Design\n",
    "            'ux design', 'ui design', 'graphic design', 'user research',\n",
    "            'prototyping', 'wireframing', 'visual design',\n",
    "\n",
    "            # Healthcare\n",
    "            'patient care', 'medical coding', 'clinical research', 'healthcare administration',\n",
    "            'medical terminology', 'treatment planning'\n",
    "        }\n",
    "\n",
    "        # Enhanced exclusion patterns\n",
    "        self.EXCLUDE_PATTERNS = [\n",
    "            # Job titles\n",
    "            r'^senior\\s+\\w+$', r'^junior\\s+\\w+$', r'^lead\\s+\\w+$', r'^principal\\s+\\w+$',\n",
    "            r'^digital\\s+manager$', r'^marketing\\s+manager$', r'^software\\s+engineer$',\n",
    "\n",
    "            # Partial phrases and generic terms\n",
    "            r'^analyze\\s+performance$', r'^comprehensive\\s+marketing$', r'^digital\\s+strategies$',\n",
    "            r'^experienced\\s+marketing$', r'^manage\\s+marketing$', r'^marketing\\s+using$',\n",
    "            r'^media\\s+efforts$', r'^optimize\\s+campaigns$', r'^social\\s+marketing$',\n",
    "            r'^in\\s+marketing$', r'^digital$', r'^email\\s+campaigns$',\n",
    "\n",
    "            # Too generic\n",
    "            r'^strategies$', r'^campaigns$', r'^efforts$', r'^performance$', r'^using$',\n",
    "            r'^teams$', r'^team$'\n",
    "        ]\n",
    "\n",
    "        logger.info(\"Optimized Domain-Agnostic Skill Analyzer initialized.\")\n",
    "\n",
    "    def extract_meaningful_skills(self, text):\n",
    "        \"\"\"Extract clean, meaningful skills across all domains\"\"\"\n",
    "        if not text or len(text.strip()) < 10:\n",
    "            return []\n",
    "\n",
    "        skills = set()\n",
    "\n",
    "        # Extract using focused methods\n",
    "        skills.update(self._extract_tools_platforms(text))\n",
    "        skills.update(self._extract_skill_categories(text))\n",
    "        skills.update(self._extract_clean_skills_from_sections(text))\n",
    "\n",
    "        # Apply strict filtering\n",
    "        filtered_skills = self._apply_clean_filters(skills)\n",
    "\n",
    "        logger.info(f\"Extracted {len(filtered_skills)} clean skills: {filtered_skills}\")\n",
    "        return filtered_skills\n",
    "\n",
    "    def _extract_tools_platforms(self, text):\n",
    "        \"\"\"Extract specific tools and platforms\"\"\"\n",
    "        skills = set()\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        for tool in self.TOOLS_PLATFORMS:\n",
    "            pattern = r'\\b' + re.escape(tool) + r'\\b'\n",
    "            if re.search(pattern, text_lower):\n",
    "                skills.add(tool.title())\n",
    "\n",
    "        return skills\n",
    "\n",
    "    def _extract_skill_categories(self, text):\n",
    "        \"\"\"Extract clean skill categories\"\"\"\n",
    "        skills = set()\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        for skill in self.SKILL_CATEGORIES:\n",
    "            pattern = r'\\b' + re.escape(skill) + r'\\b'\n",
    "            if re.search(pattern, text_lower):\n",
    "                skills.add(skill.title())\n",
    "\n",
    "        return skills\n",
    "\n",
    "    def _extract_clean_skills_from_sections(self, text):\n",
    "        \"\"\"Extract clean skills from sections only\"\"\"\n",
    "        skills = set()\n",
    "\n",
    "        section_patterns = {\n",
    "            'skills': r'skills?[^:]*:([^‚Ä¢]+?(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z))',\n",
    "            'technologies': r'technologies?[^:]*:([^‚Ä¢]+?(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z))',\n",
    "            'tools': r'tools?[^:]*:([^‚Ä¢]+?(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z))',\n",
    "        }\n",
    "\n",
    "        for section_name, pattern in section_patterns.items():\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "            for match in matches:\n",
    "                items = re.split(r'[,\\n‚Ä¢\\-]', match)\n",
    "                for item in items:\n",
    "                    skill = self._clean_skill_item(item.strip())\n",
    "                    if skill and self._is_clean_skill(skill):\n",
    "                        skills.add(skill)\n",
    "\n",
    "        return skills\n",
    "\n",
    "    def _clean_skill_item(self, item):\n",
    "        \"\"\"Clean and normalize skill items strictly\"\"\"\n",
    "        if not item:\n",
    "            return None\n",
    "\n",
    "        # Remove markdown and punctuation\n",
    "        item = re.sub(r'[\\*\\#\\`\\-\\‚Ä¢\\(\\)]', ' ', item).strip()\n",
    "        item = re.sub(r'\\s+', ' ', item)\n",
    "\n",
    "        # Remove common prefixes/suffixes\n",
    "        item = re.sub(r'^(?:experience with|proficient in|knowledge of|strong|excellent|basic|assisted with|participated in)\\s+', '', item, flags=re.IGNORECASE)\n",
    "        item = re.sub(r'\\s+(?:management|marketing|development|design|analysis|optimization|strategy|campaigns|efforts)$', '', item, flags=re.IGNORECASE)\n",
    "\n",
    "        # Must be a clean, meaningful skill\n",
    "        words = item.split()\n",
    "        if 1 <= len(words) <= 3 and 2 <= len(item) <= 30:\n",
    "            return item.title()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _is_clean_skill(self, skill):\n",
    "        \"\"\"Strict validation for clean skills only\"\"\"\n",
    "        skill_lower = skill.lower()\n",
    "\n",
    "        # Exclude partial phrases and generic terms\n",
    "        if any(re.search(pattern, skill_lower) for pattern in self.EXCLUDE_PATTERNS):\n",
    "            return False\n",
    "\n",
    "        # Must be a known tool/platform or skill category\n",
    "        is_tool = any(tool in skill_lower for tool in self.TOOLS_PLATFORMS)\n",
    "        is_skill_category = any(category in skill_lower for category in self.SKILL_CATEGORIES)\n",
    "\n",
    "        return is_tool or is_skill_category\n",
    "\n",
    "    def _apply_clean_filters(self, skills):\n",
    "        \"\"\"Apply final clean filters\"\"\"\n",
    "        filtered_skills = []\n",
    "        seen_lower = set()\n",
    "\n",
    "        for skill in skills:\n",
    "            skill_lower = skill.lower().strip()\n",
    "\n",
    "            if (skill_lower not in seen_lower and\n",
    "                self._is_clean_skill(skill)):\n",
    "                filtered_skills.append(skill)\n",
    "                seen_lower.add(skill_lower)\n",
    "\n",
    "        # Remove duplicates and sort\n",
    "        return sorted(list(set(filtered_skills)))\n",
    "\n",
    "    # IMPROVED EVIDENCE EXTRACTION METHODS\n",
    "    def _find_contextual_evidence(self, text, skill):\n",
    "        \"\"\"Improved evidence extraction that finds actual skill mentions\"\"\"\n",
    "        if not text or not skill:\n",
    "            return None\n",
    "\n",
    "        skill_lower = skill.lower()\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        # Split into meaningful segments (sentences, bullet points, list items)\n",
    "        segments = self._split_into_meaningful_segments(text)\n",
    "\n",
    "        # 1. First priority: Exact match in segments\n",
    "        for segment in segments:\n",
    "            segment_lower = segment.lower()\n",
    "            if skill_lower in segment_lower:\n",
    "                # Check if this is a meaningful context (not just in education/header)\n",
    "                if self._is_meaningful_context(segment, skill):\n",
    "                    return segment.strip()\n",
    "\n",
    "        # 2. Second priority: Multi-word skill partial matching\n",
    "        skill_words = skill_lower.split()\n",
    "        if len(skill_words) > 1:\n",
    "            for segment in segments:\n",
    "                segment_lower = segment.lower()\n",
    "                if all(word in segment_lower for word in skill_words):\n",
    "                    if self._is_meaningful_context(segment, skill):\n",
    "                        return segment.strip()\n",
    "\n",
    "        # 3. Third priority: Look for skill in technical sections only\n",
    "        technical_segments = self._extract_technical_segments(text)\n",
    "        for segment in technical_segments:\n",
    "            segment_lower = segment.lower()\n",
    "            if skill_lower in segment_lower:\n",
    "                return segment.strip()\n",
    "\n",
    "        # 4. Final fallback: Find any occurrence but filter out bad contexts\n",
    "        if skill_lower in text_lower:\n",
    "            # Use regex to find the skill with context, avoiding education sections\n",
    "            pattern = r'([^.!?]*?' + re.escape(skill) + r'[^.!?]*[.!?])'\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if self._is_meaningful_context(match, skill):\n",
    "                    return match.strip()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _split_into_meaningful_segments(self, text):\n",
    "        \"\"\"Split text into meaningful segments (not just sentences)\"\"\"\n",
    "        segments = []\n",
    "\n",
    "        # Split by sentences, bullet points, and list items\n",
    "        raw_segments = re.split(r'[.!?]+|(?:\\n\\s*)[‚Ä¢\\-*]\\s*|(?:\\n\\s*)\\d+\\.\\s*', text)\n",
    "\n",
    "        for segment in raw_segments:\n",
    "            clean_segment = segment.strip()\n",
    "            # Filter out very short segments and education-like segments\n",
    "            if (len(clean_segment) >= 10 and\n",
    "                len(clean_segment.split()) >= 3 and\n",
    "                not self._is_education_section(clean_segment)):\n",
    "                segments.append(clean_segment)\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def _is_education_section(self, text):\n",
    "        \"\"\"Check if text is from education section (should be excluded from evidence)\"\"\"\n",
    "        education_indicators = [\n",
    "            'education', 'university', 'college', 'school', 'baccalaureat',\n",
    "            'bachelor', 'master', 'phd', 'degree', 'diploma', 'graduat',\n",
    "            'faculty', 'institute', 'academy', 'esprit', 'tunisia'\n",
    "        ]\n",
    "\n",
    "        text_lower = text.lower()\n",
    "        education_keywords = sum(1 for indicator in education_indicators if indicator in text_lower)\n",
    "\n",
    "        # If contains multiple education keywords, likely education section\n",
    "        return education_keywords >= 2\n",
    "\n",
    "    def _is_meaningful_context(self, text, skill):\n",
    "        \"\"\"Check if the context is meaningful for skill evidence\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        skill_lower = skill.lower()\n",
    "\n",
    "        # Exclude education sections\n",
    "        if self._is_education_section(text):\n",
    "            return False\n",
    "\n",
    "        # Exclude very generic contexts\n",
    "        generic_contexts = [\n",
    "            'education', 'university', 'college', 'school',\n",
    "            'name', 'address', 'phone', 'email', 'contact'\n",
    "        ]\n",
    "\n",
    "        if any(context in text_lower for context in generic_contexts):\n",
    "            return False\n",
    "\n",
    "        # Check if skill appears in a meaningful way (not just in a list)\n",
    "        words = text_lower.split()\n",
    "        skill_position = text_lower.find(skill_lower)\n",
    "\n",
    "        # If skill is in a very short segment, it might just be a list item\n",
    "        if len(words) <= 4:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _extract_technical_segments(self, text):\n",
    "        \"\"\"Extract segments from technical sections only\"\"\"\n",
    "        technical_segments = []\n",
    "\n",
    "        # Common technical section headers\n",
    "        technical_headers = [\n",
    "            'skills', 'experience', 'work', 'projects', 'technical',\n",
    "            'technologies', 'tools', 'frameworks', 'languages',\n",
    "            'proficiencies', 'expertise', 'qualifications'\n",
    "        ]\n",
    "\n",
    "        lines = text.split('\\n')\n",
    "        in_technical_section = False\n",
    "\n",
    "        for line in lines:\n",
    "            line_lower = line.lower().strip()\n",
    "\n",
    "            # Check if this line starts a technical section\n",
    "            if any(header in line_lower for header in technical_headers):\n",
    "                in_technical_section = True\n",
    "                continue\n",
    "\n",
    "            # Check if we're leaving technical section (new major section)\n",
    "            if (line_lower and\n",
    "                len(line.split()) <= 4 and\n",
    "                line[0].isupper() and\n",
    "                not any(header in line_lower for header in technical_headers)):\n",
    "                in_technical_section = False\n",
    "\n",
    "            # If in technical section and line is meaningful, add it\n",
    "            if in_technical_section and len(line.strip()) >= 5:\n",
    "                technical_segments.append(line.strip())\n",
    "\n",
    "        return technical_segments\n",
    "\n",
    "    def _find_better_evidence(self, text, skill, current_evidence):\n",
    "        \"\"\"Try to find better evidence if current is from education section\"\"\"\n",
    "        # Look in technical sections specifically\n",
    "        technical_segments = self._extract_technical_segments(text)\n",
    "\n",
    "        for segment in technical_segments:\n",
    "            if skill.lower() in segment.lower():\n",
    "                return segment.strip()\n",
    "\n",
    "        return current_evidence  # Return original if no better evidence found\n",
    "\n",
    "    def _truncate_evidence(self, evidence, max_length=120):\n",
    "        \"\"\"Truncate evidence for display\"\"\"\n",
    "        if not evidence:\n",
    "            return \"Not specifically demonstrated\"\n",
    "\n",
    "        if len(evidence) <= max_length:\n",
    "            return evidence\n",
    "\n",
    "        truncated = evidence[:max_length]\n",
    "        last_space = truncated.rfind(' ')\n",
    "        if last_space > max_length * 0.6:\n",
    "            return truncated[:last_space] + \"...\"\n",
    "\n",
    "        return truncated + \"...\"\n",
    "\n",
    "    # IMPROVED MATCHING ALGORITHM\n",
    "    def _flexible_skill_matching(self, cv_skills, jd_skills):\n",
    "        \"\"\"Improved skill matching with better evidence validation\"\"\"\n",
    "        matched_pairs = []\n",
    "        missing_skills = []\n",
    "\n",
    "        for jd_skill in jd_skills:\n",
    "            best_match = None\n",
    "            best_score = 0.0\n",
    "\n",
    "            for cv_skill in cv_skills:\n",
    "                overlap_score = self._keyword_overlap(cv_skill, jd_skill)\n",
    "                semantic_score = self._semantic_similarity(cv_skill, jd_skill)\n",
    "\n",
    "                combined_score = (overlap_score * self.WEIGHT_OVERLAP) + (semantic_score * self.WEIGHT_SEMANTIC)\n",
    "\n",
    "                if combined_score > best_score:\n",
    "                    best_match, best_score = cv_skill, combined_score\n",
    "\n",
    "            # Only count as matched if we have good score\n",
    "            if best_score >= self.SIMILARITY_THRESHOLD:\n",
    "                matched_pairs.append((best_match, jd_skill, best_score))\n",
    "            else:\n",
    "                missing_skills.append(jd_skill)\n",
    "\n",
    "        return matched_pairs, missing_skills\n",
    "\n",
    "    def _keyword_overlap(self, s1, s2):\n",
    "        \"\"\"Calculate keyword overlap\"\"\"\n",
    "        if not s1 or not s2:\n",
    "            return 0.0\n",
    "\n",
    "        w1 = set(re.findall(r'\\b\\w+\\b', s1.lower()))\n",
    "        w2 = set(re.findall(r'\\b\\w+\\b', s2.lower()))\n",
    "\n",
    "        if not w1 or not w2:\n",
    "            return 0.0\n",
    "\n",
    "        intersection = w1 & w2\n",
    "        union = w1 | w2\n",
    "\n",
    "        return len(intersection) / len(union) if union else 0.0\n",
    "\n",
    "    def _semantic_similarity(self, s1, s2):\n",
    "        \"\"\"Calculate semantic similarity\"\"\"\n",
    "        try:\n",
    "            emb1 = self.sentence_model.encode([s1])\n",
    "            emb2 = self.sentence_model.encode([s2])\n",
    "            similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "            return float(similarity)\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # MAIN ANALYSIS METHOD WITH IMPROVED EVIDENCE\n",
    "    def analyze_skill_gap(self, cv_text, jd_text):\n",
    "        \"\"\"Main skill gap analysis with improved evidence\"\"\"\n",
    "        # Store texts for evidence validation\n",
    "        self.cv_text = cv_text\n",
    "        self.jd_text = jd_text\n",
    "\n",
    "        cv_skills = self.extract_meaningful_skills(cv_text)\n",
    "        jd_skills = self.extract_meaningful_skills(jd_text)\n",
    "\n",
    "        jd_skills = [re.sub(r'[\\*`#]', '', skill).strip() for skill in jd_skills]\n",
    "\n",
    "        matched_pairs, missing_skills_list = self._flexible_skill_matching(cv_skills, jd_skills)\n",
    "\n",
    "        # Generate evidence with improved logic\n",
    "        matched_evidence = []\n",
    "        for cv_skill, jd_skill, sim in matched_pairs:\n",
    "            cv_ev = self._find_contextual_evidence(cv_text, cv_skill)\n",
    "            jd_ev = self._find_contextual_evidence(jd_text, jd_skill)\n",
    "\n",
    "            # If evidence is from education section, try to find better evidence\n",
    "            if cv_ev and self._is_education_section(cv_ev):\n",
    "                cv_ev = self._find_better_evidence(cv_text, cv_skill, cv_ev)\n",
    "\n",
    "            matched_evidence.append({\n",
    "                \"skill\": jd_skill,\n",
    "                \"cv_skill\": cv_skill,\n",
    "                \"evidence_cv\": self._truncate_evidence(cv_ev),\n",
    "                \"evidence_jd\": self._truncate_evidence(jd_ev),\n",
    "                \"similarity\": round(sim, 2)\n",
    "            })\n",
    "\n",
    "        # Generate evidence for missing skills\n",
    "        missing_evidence = []\n",
    "        for skill in missing_skills_list:\n",
    "            jd_full_context = self._find_contextual_evidence(jd_text, skill)\n",
    "            missing_evidence.append({\n",
    "                \"skill\": skill,\n",
    "                \"evidence_jd\": self._truncate_evidence(jd_full_context),\n",
    "                \"jd_requirement_text\": jd_full_context\n",
    "            })\n",
    "\n",
    "        match_percentage = (len(matched_pairs) / len(jd_skills)) * 100 if jd_skills else 0.0\n",
    "\n",
    "        structured_missing_skills = [\n",
    "            {\n",
    "                \"skill\": item[\"skill\"],\n",
    "                \"jd_requirement\": item[\"jd_requirement_text\"] or \"JD requirement\"\n",
    "            }\n",
    "            for item in missing_evidence\n",
    "        ]\n",
    "\n",
    "        evidence_data = self._create_frontend_evidence(matched_evidence, missing_evidence)\n",
    "\n",
    "        return {\n",
    "            \"matched_skills\": matched_evidence,\n",
    "            \"missing_skills\": structured_missing_skills,\n",
    "            \"cv_skill_count\": len(cv_skills),\n",
    "            \"jd_skill_count\": len(jd_skills),\n",
    "            \"match_percentage\": round(match_percentage, 1),\n",
    "            \"evidence\": evidence_data\n",
    "        }\n",
    "\n",
    "    def _create_frontend_evidence(self, matched_skills, missing_skills_data):\n",
    "        \"\"\"Create frontend evidence structure\"\"\"\n",
    "        evidence_list = []\n",
    "\n",
    "        for skill in matched_skills:\n",
    "            evidence_list.append({\n",
    "                \"skill\": skill[\"skill\"],\n",
    "                \"status\": \"matched\",\n",
    "                \"cv_sentence\": skill[\"evidence_cv\"],\n",
    "                \"jd_sentence\": skill[\"evidence_jd\"],\n",
    "                \"similarity\": skill[\"similarity\"],\n",
    "                \"matched_skill\": skill[\"cv_skill\"]\n",
    "            })\n",
    "\n",
    "        for skill_data in missing_skills_data:\n",
    "            evidence_list.append({\n",
    "                \"skill\": skill_data[\"skill\"],\n",
    "                \"status\": \"missing\",\n",
    "                \"cv_sentence\": \"Not specifically demonstrated in CV\",\n",
    "                \"jd_sentence\": skill_data[\"evidence_jd\"],\n",
    "                \"similarity\": 0,\n",
    "                \"matched_skill\": None\n",
    "            })\n",
    "\n",
    "        return evidence_list\n",
    "\n",
    "\n",
    "# Global instance\n",
    "dynamic_skill_analyzer = DynamicSkillAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a2933",
   "metadata": {},
   "source": [
    "## ‚ùì Intelligent Interview Question Generation\n",
    "\n",
    "### **Powered by Gemini 2.0 Flash**\n",
    "- **Advanced Reasoning** - Creates targeted questions based on skill gaps\n",
    "- **Structured Outputs** - JSON format with model answers and hints\n",
    "- **Professional Quality** - HR-expert level question formulation\n",
    "\n",
    "### **Question Types Generated**\n",
    "1. **Behavioral Questions** - Past experience and problem-solving\n",
    "2. **Technical Questions** - Specific skills and technologies\n",
    "3. **Situational Questions** - Missing skills and learning approach\n",
    "\n",
    "### **Features**\n",
    "- **Model Answers** - STAR-method responses\n",
    "- **Answer Hints** - Guidance for candidates\n",
    "- **Key Points** - What interviewers should listen for\n",
    "- **Skill Targeting** - Questions address specific matched/missing skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b81c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Google Gemini LLM and Embeddings models...\n",
      "‚úÖ Models initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# What this cell does : Implements AIQuestionGenerator ‚Äî loads LLM + embeddings,\n",
    "#   extracts and chunk-splits PDF context, generates structured interview questions (JSON),\n",
    "#   and provides a lightweight QA retriever using vector embeddings.\n",
    "# Inputs: candidate CV text (string), job description text (string), path to a PDF for context.\n",
    "# Outputs: JSON list of interview questions (question, focus, rationale, model_answer, hints, key_points)\n",
    "# Dependencies/runtime note: uses Google Generative AI (Gemini) APIs ‚Äî set GOOGLE_API_KEY in env or use offline fallback.\n",
    "\n",
    "# Imports: os (env), logging (diagnostics), re/json (parsing), langchain loaders/splitters/FAISS (RAG),\n",
    "# and langchain_google_genai wrappers for Gemini LLM + embeddings.\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Set API key as environment variable\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCEFhz2FoUllmTdYNo8qLmdEuwQGBDa4tc\"\n",
    "\n",
    "\n",
    "# Initialize logger to capture info/debug messages during model initialization and generation.\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# AIQuestionGenerator:\n",
    "# - Responsible for initializing LLM + embedding clients (Gemini here),\n",
    "# - Converting PDFs to chunked documents for retrieval,\n",
    "# - Generating structured interview questions given CV+JD+skill analysis,\n",
    "# - Providing a simple QA retriever (FAISS via LangChain) for answering based on chunks.\n",
    "class AIQuestionGenerator:\n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Missing GOOGLE_API_KEY. Provide as argument or set environment variable.\")\n",
    "        self._initialize_models()\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        logger.info(\"üöÄ Initializing Google Gemini LLM and Embeddings models...\")\n",
    "        self.llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash-exp\",\n",
    "            temperature=0.3,\n",
    "            google_api_key=self.api_key\n",
    "        )\n",
    "        self.embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=self.api_key\n",
    "        )\n",
    "        logger.info(\"‚úÖ Models initialized successfully\")\n",
    "\n",
    "    # process_pdf: extracts text from PDF and splits into overlapping chunks for retrieval context.\n",
    "# chunk_size and chunk_overlap are chosen to balance context completeness vs number of vectors.\n",
    "    def process_pdf(self, file_path):\n",
    "        logger.info(f\"üìÑ Loading and splitting PDF from {file_path}\")\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        return texts\n",
    "\n",
    "    def generate_interview_questions(self, cv_text, jd_text, skill_gap_analysis, num_questions=6):\n",
    "        \"\"\"Original method - kept for backward compatibility\"\"\"\n",
    "        return self.generate_interview_questions_with_answers(cv_text, jd_text, skill_gap_analysis, num_questions)\n",
    "\n",
    "    def generate_interview_questions_with_answers(self, cv_text, jd_text, skill_gap_analysis, num_questions=6):\n",
    "        matched = [s['skill'] if isinstance(s, dict) else s for s in skill_gap_analysis.get(\"matched_skills\", [])]\n",
    "        missing = [s['skill'] if isinstance(s, dict) else s for s in skill_gap_analysis.get(\"missing_skills\", [])]\n",
    "\n",
    "        prompt_text = (\n",
    "            f\"You are an expert HR interviewer and career coach. Based on the job description and candidate CV below, \"\n",
    "            f\"please generate exactly {num_questions} interview questions in JSON format.\\n\\n\"\n",
    "            \"STRUCTURE EACH QUESTION WITH:\\n\"\n",
    "            \"- 'question': The interview question text\\n\"\n",
    "            \"- 'focus': Which skill area this targets (behavioral, technical_django, technical_python, technical_aws, technical_gcp, situational, leadership)\\n\"\n",
    "            \"- 'rationale': Brief explanation of why this question is relevant for this candidate\\n\"\n",
    "            \"- 'skill_type': Whether this addresses 'matched_skill' or 'missing_skill'\\n\"\n",
    "            \"- 'target_skill': The specific skill being assessed\\n\"\n",
    "            \"- 'model_answer': A well-structured model answer using STAR method (Situation, Task, Action, Result)\\n\"\n",
    "            \"- 'answer_hints': List of 3-5 specific hints to help answer this question effectively\\n\"\n",
    "            \"- 'key_points': List of key points that should be covered in a good answer\\n\\n\"\n",
    "            f\"MATCHED SKILLS TO ASSESS: {', '.join(matched)}\\n\"\n",
    "            f\"MISSING SKILLS TO ADDRESS: {', '.join(missing)}\\n\\n\"\n",
    "            \"QUESTIONS SHOULD COVER:\\n\"\n",
    "            \"- 2 behavioral questions about past experience\\n\"\n",
    "            \"- 2 technical questions on matched skills\\n\"\n",
    "            \"- 2 situational questions addressing missing skills\\n\\n\"\n",
    "            f\"Job Description:\\n{jd_text[:1000]}...\\n\\n\"\n",
    "            f\"Candidate CV:\\n{cv_text[:1000]}...\\n\\n\"\n",
    "            \"Return ONLY valid JSON array format, no other text:\\n\"\n",
    "            \"[{'question': '...', 'focus': '...', 'rationale': '...', 'skill_type': '...', 'target_skill': '...', 'model_answer': '...', 'answer_hints': ['hint1', 'hint2'], 'key_points': ['point1', 'point2']}]\"\n",
    "        )\n",
    "\n",
    "        logger.info(\"üß† Generating interview questions with answers and hints\")\n",
    "        logger.info(f\"üìä Matched skills: {matched}\")\n",
    "        logger.info(f\"üìä Missing skills: {missing}\")\n",
    "\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt_text)\n",
    "            generated_text = response.content\n",
    "\n",
    "            # Debug: Print the raw response\n",
    "            logger.info(\"üì® Raw AI Response:\")\n",
    "            logger.info(generated_text[:500] + \"...\" if len(generated_text) > 500 else generated_text)\n",
    "\n",
    "            # Clean the response - remove markdown code blocks if present\n",
    "            cleaned_text = re.sub(r'```json\\s*|\\s*```', '', generated_text).strip()\n",
    "\n",
    "            # Parse JSON response\n",
    "            questions_data = json.loads(cleaned_text)\n",
    "\n",
    "            # Debug: Print parsed data\n",
    "            logger.info(f\"‚úÖ Successfully parsed {len(questions_data)} questions\")\n",
    "            for i, q in enumerate(questions_data):\n",
    "                logger.info(f\"üìù Question {i+1}: {q.get('question', 'No question')[:100]}...\")\n",
    "                logger.info(f\"   Answer: {'Yes' if q.get('model_answer') else 'No'}\")\n",
    "                logger.info(f\"   Hints: {len(q.get('answer_hints', []))}\")\n",
    "                logger.info(f\"   Key Points: {len(q.get('key_points', []))}\")\n",
    "\n",
    "            # Ensure we have the right number of questions\n",
    "            if len(questions_data) > num_questions:\n",
    "                questions_data = questions_data[:num_questions]\n",
    "\n",
    "            logger.info(f\"‚úÖ Successfully generated {len(questions_data)} questions with answers and hints\")\n",
    "            return questions_data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"‚ùå Failed to parse JSON response: {e}\")\n",
    "            logger.error(f\"Raw response: {generated_text}\")\n",
    "            # Fallback to simple question generation\n",
    "            return self._generate_fallback_questions_with_answers(matched, missing, num_questions)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Unexpected error in question generation: {e}\")\n",
    "            return self._generate_fallback_questions_with_answers(matched, missing, num_questions)\n",
    "\n",
    "    def _generate_fallback_questions_with_answers(self, matched_skills, missing_skills, num_questions):\n",
    "        \"\"\"Fallback method if JSON parsing fails\"\"\"\n",
    "        logger.warning(\"üîÑ Using fallback question generation\")\n",
    "        questions = []\n",
    "\n",
    "        # Distribute questions between matched and missing skills\n",
    "        num_matched = min(3, len(matched_skills))\n",
    "        num_missing = min(3, len(missing_skills))\n",
    "\n",
    "        for i in range(num_matched):\n",
    "            if i < len(matched_skills):\n",
    "                skill = matched_skills[i]\n",
    "                questions.append({\n",
    "                    \"question\": f\"Can you describe your experience with {skill} and provide an example of a project where you used it effectively?\",\n",
    "                    \"focus\": f\"technical_{skill.lower()}\",\n",
    "                    \"rationale\": f\"Assessing depth of experience with {skill} which matches the job requirements\",\n",
    "                    \"skill_type\": \"matched_skill\",\n",
    "                    \"target_skill\": skill,\n",
    "                    \"model_answer\": f\"In my previous role, I extensively used {skill} to develop a scalable solution. The situation required handling increasing user load. My task was to optimize performance. I implemented efficient algorithms and caching strategies using {skill}, which resulted in 40% performance improvement and better user satisfaction. The key was understanding the system constraints and applying the right {skill} features to address them.\",\n",
    "                    \"answer_hints\": [\n",
    "                        f\"Focus on a specific project example using {skill}\",\n",
    "                        \"Mention the business impact of your work\",\n",
    "                        \"Describe the technical challenges you overcame\",\n",
    "                        \"Quantify your results with metrics\",\n",
    "                        f\"Explain why you chose specific {skill} features\"\n",
    "                    ],\n",
    "                    \"key_points\": [\n",
    "                        f\"Specific {skill} features used\",\n",
    "                        \"Problem-solving approach\",\n",
    "                        \"Measurable outcomes\",\n",
    "                        \"Learning and improvements\",\n",
    "                        \"Business impact\"\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "        for i in range(num_missing):\n",
    "            if i < len(missing_skills):\n",
    "                skill = missing_skills[i]\n",
    "                questions.append({\n",
    "                    \"question\": f\"How would you approach learning and implementing {skill} if required for this role?\",\n",
    "                    \"focus\": f\"technical_{skill.lower()}\",\n",
    "                    \"rationale\": f\"Exploring willingness to learn missing skill {skill}\",\n",
    "                    \"skill_type\": \"missing_skill\",\n",
    "                    \"target_skill\": skill,\n",
    "                    \"model_answer\": f\"While I haven't worked extensively with {skill}, I have a strong foundation in related technologies. I would start by taking online courses and building small projects to understand the fundamentals. Then I'd seek mentorship from experienced colleagues and gradually take on more complex tasks. My experience with similar technologies would help me ramp up quickly, and I'm confident I could become productive with {skill} within a few weeks.\",\n",
    "                    \"answer_hints\": [\n",
    "                        \"Show enthusiasm for learning\",\n",
    "                        \"Connect to your existing skills\",\n",
    "                        \"Provide a concrete learning plan\",\n",
    "                        \"Mention how you'll apply it to the role\",\n",
    "                        \"Set realistic timeline expectations\"\n",
    "                    ],\n",
    "                    \"key_points\": [\n",
    "                        \"Learning strategy and resources\",\n",
    "                        \"Timeline for skill acquisition\",\n",
    "                        \"Transferable skills\",\n",
    "                        \"Practical application plans\",\n",
    "                        \"Measurement of progress\"\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "        # Fill remaining slots with behavioral questions\n",
    "        while len(questions) < num_questions:\n",
    "            questions.append({\n",
    "                \"question\": \"Describe a challenging project you worked on and how you overcame the main obstacles.\",\n",
    "                \"focus\": \"behavioral\",\n",
    "                \"rationale\": \"Assessing problem-solving and project management skills\",\n",
    "                \"skill_type\": \"behavioral\",\n",
    "                \"target_skill\": \"problem_solving\",\n",
    "                \"model_answer\": \"In a recent project, we faced tight deadlines and technical challenges with integrating multiple legacy systems. The situation required delivering a critical feature under pressure while maintaining system stability. My task was to lead the development team and ensure on-time delivery. I organized daily standups, broke down tasks into manageable chunks, implemented agile practices, and created contingency plans. The result was successful on-time delivery with all requirements met, and the client was very satisfied with both the process and outcome.\",\n",
    "                \"answer_hints\": [\n",
    "                    \"Use STAR method: Situation, Task, Action, Result\",\n",
    "                    \"Be specific about challenges and constraints\",\n",
    "                    \"Highlight your leadership and decision-making role\",\n",
    "                    \"Quantify the success metrics\",\n",
    "                    \"Show what you learned from the experience\"\n",
    "                ],\n",
    "                \"key_points\": [\n",
    "                    \"Clear problem description with context\",\n",
    "                    \"Your specific actions and decisions\",\n",
    "                    \"Team collaboration and communication\",\n",
    "                    \"Measurable outcomes and impact\",\n",
    "                    \"Lessons learned and improvements\"\n",
    "                ]\n",
    "            })\n",
    "\n",
    "        logger.info(f\"üîÑ Generated {len(questions)} fallback questions with answers\")\n",
    "        return questions[:num_questions]\n",
    "\n",
    "    def create_qa_system(self, texts):\n",
    "        \"\"\"Create a simple QA system without complex chains\"\"\"\n",
    "        vector_store = FAISS.from_documents(texts, self.embedding_model)\n",
    "        retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
    "        return retriever\n",
    "\n",
    "    def generate_all(self, cv_text, jd_text, skill_gap_analysis, pdf_path):\n",
    "        \"\"\"Main method to generate questions and answers\"\"\"\n",
    "        try:\n",
    "            # Process PDF for context\n",
    "            texts = self.process_pdf(pdf_path)\n",
    "\n",
    "            # Generate structured questions with answers\n",
    "            questions = self.generate_interview_questions_with_answers(cv_text, jd_text, skill_gap_analysis)\n",
    "\n",
    "            # Create QA system for answering\n",
    "            retriever = self.create_qa_system(texts)\n",
    "\n",
    "            return {\n",
    "                \"questions\": questions,\n",
    "                \"status\": \"success\"\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error in generate_all: {e}\")\n",
    "            return {\n",
    "                \"questions\": [],\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "# Now this will work\n",
    "ai_question_generator = AIQuestionGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1d299",
   "metadata": {},
   "source": [
    "## üîÑ Complete CV-JD Analysis Pipeline\n",
    "\n",
    "### **Multi-Format Input Support**\n",
    "- **üìã Manual Text Input** - Paste CV and job description directly\n",
    "- **üìÅ Text File Upload** - Upload .txt files\n",
    "- **üìÑ PDF File Upload** - Automatic text extraction from PDF resumes\n",
    "\n",
    "### **Analysis Workflow**\n",
    "1. **Input Processing** - Handle multiple file formats and encoding\n",
    "2. **Skill Extraction** - Identify skills from both CV and job description\n",
    "3. **Gap Analysis** - Calculate match percentage and identify missing skills\n",
    "4. **Question Generation** - Create targeted interview questions\n",
    "5. **Professional Reporting** - Formatted results with evidence\n",
    "\n",
    "### **User Experience**\n",
    "- **Interactive Prompts** - Guide users through the process\n",
    "- **Progress Indicators** - Show analysis stages\n",
    "- **Preview Features** - Display extracted text for verification\n",
    "- **Error Handling** - Graceful fallbacks and user-friendly messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a90376ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Main Analysis Pipeline with PDF Support\n",
    "import logging\n",
    "import json\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_text_from_pdf(pdf_content):\n",
    "    \"\"\"Extract text from PDF content using PyPDFLoader\"\"\"\n",
    "    try:\n",
    "        # Save PDF content to temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:\n",
    "            temp_file.write(pdf_content)\n",
    "            temp_path = temp_file.name\n",
    "\n",
    "        # Use PyPDFLoader to extract text\n",
    "        from langchain_community.document_loaders import PyPDFLoader\n",
    "        loader = PyPDFLoader(temp_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Combine all pages into single text\n",
    "        text = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "        # Clean up temporary file\n",
    "        os.unlink(temp_path)\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting text from PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_text_input(prompt_text, input_type=\"CV\"):\n",
    "    \"\"\"Get text input from user with choice of manual entry or file upload\"\"\"\n",
    "\n",
    "    print(f\"\\nüìù {input_type} INPUT OPTIONS:\")\n",
    "    print(\"1. üìã Paste text manually\")\n",
    "    print(\"2. üìÅ Upload text file (.txt)\")\n",
    "    print(\"3. üìÑ Upload PDF file (.pdf)\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"Choose {input_type} input method (1, 2, or 3): \").strip()\n",
    "            if choice == '1':\n",
    "                return get_manual_text_input(input_type)\n",
    "            elif choice == '2':\n",
    "                return get_text_file_input(input_type)\n",
    "            elif choice == '3':\n",
    "                return get_pdf_file_input(input_type)\n",
    "            else:\n",
    "                print(\"‚ùå Please enter 1, 2, or 3\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è Input cancelled\")\n",
    "            return None\n",
    "\n",
    "def get_manual_text_input(input_type):\n",
    "    \"\"\"Get manual text input from user\"\"\"\n",
    "    print(f\"\\nüìã PASTE {input_type} TEXT:\")\n",
    "    print(\"   (Paste the content below, then press Enter twice to finish)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    lines = []\n",
    "    empty_line_count = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            line = input()\n",
    "            if line.strip() == \"\":\n",
    "                empty_line_count += 1\n",
    "                if empty_line_count >= 2 and len(lines) > 0:\n",
    "                    break\n",
    "            else:\n",
    "                empty_line_count = 0\n",
    "            lines.append(line)\n",
    "        except EOFError:\n",
    "            break\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è Input cancelled\")\n",
    "            return None\n",
    "\n",
    "    text = \"\\n\".join(lines)\n",
    "    print(f\"‚úÖ {input_type} text received ({len(text)} characters)\")\n",
    "    return text\n",
    "\n",
    "def get_text_file_input(input_type):\n",
    "    \"\"\"Get text from .txt file upload\"\"\"\n",
    "    print(f\"\\nüìÅ {input_type} TEXT FILE UPLOAD:\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your .txt file...\")\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        if uploaded:\n",
    "            filename = list(uploaded.keys())[0]\n",
    "            # Try different encodings for text files\n",
    "            try:\n",
    "                content = uploaded[filename].decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    content = uploaded[filename].decode('latin-1')\n",
    "                except UnicodeDecodeError:\n",
    "                    content = uploaded[filename].decode('utf-8', errors='ignore')\n",
    "\n",
    "            print(f\"‚úÖ Text file '{filename}' uploaded successfully ({len(content)} characters)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"‚ùå No file uploaded. Switching to manual input...\")\n",
    "            return get_manual_text_input(input_type)\n",
    "\n",
    "    except ImportError:\n",
    "        # For local environment - file path input\n",
    "        print(\"üåê Local environment detected - enter text file path:\")\n",
    "        while True:\n",
    "            file_path = input(\"Enter file path: \").strip()\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        content = file.read()\n",
    "                except UnicodeDecodeError:\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                            content = file.read()\n",
    "                    except UnicodeDecodeError:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                            content = file.read()\n",
    "\n",
    "                print(f\"‚úÖ Text file loaded successfully ({len(content)} characters)\")\n",
    "                return content\n",
    "            else:\n",
    "                print(\"‚ùå File not found. Please enter a valid file path or press Ctrl+C to cancel\")\n",
    "                retry = input(\"Try again? (y/n): \").strip().lower()\n",
    "                if retry != 'y':\n",
    "                    return get_manual_text_input(input_type)\n",
    "\n",
    "def get_pdf_file_input(input_type):\n",
    "    \"\"\"Get text from PDF file upload\"\"\"\n",
    "    print(f\"\\nüìÑ {input_type} PDF FILE UPLOAD:\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your PDF file...\")\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        if uploaded:\n",
    "            filename = list(uploaded.keys())[0]\n",
    "            if not filename.lower().endswith('.pdf'):\n",
    "                print(\"‚ùå Please upload a PDF file. Switching to manual input...\")\n",
    "                return get_manual_text_input(input_type)\n",
    "\n",
    "            print(f\"‚è≥ Extracting text from PDF '{filename}'...\")\n",
    "            pdf_content = uploaded[filename]\n",
    "\n",
    "            # Extract text from PDF\n",
    "            text_content = extract_text_from_pdf(pdf_content)\n",
    "\n",
    "            if text_content:\n",
    "                print(f\"‚úÖ PDF text extracted successfully ({len(text_content)} characters)\")\n",
    "                # Show preview of extracted text\n",
    "                preview = text_content[:500] + \"...\" if len(text_content) > 500 else text_content\n",
    "                print(f\"üìñ Extracted text preview:\\n{preview}\\n\")\n",
    "                return text_content\n",
    "            else:\n",
    "                print(\"‚ùå Failed to extract text from PDF. Switching to manual input...\")\n",
    "                return get_manual_text_input(input_type)\n",
    "        else:\n",
    "            print(\"‚ùå No file uploaded. Switching to manual input...\")\n",
    "            return get_manual_text_input(input_type)\n",
    "\n",
    "    except ImportError:\n",
    "        # For local environment - file path input\n",
    "        print(\"üåê Local environment detected - enter PDF file path:\")\n",
    "        while True:\n",
    "            file_path = input(\"Enter PDF file path: \").strip()\n",
    "            if os.path.exists(file_path) and file_path.lower().endswith('.pdf'):\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        pdf_content = file.read()\n",
    "\n",
    "                    print(f\"‚è≥ Extracting text from PDF...\")\n",
    "                    text_content = extract_text_from_pdf(pdf_content)\n",
    "\n",
    "                    if text_content:\n",
    "                        print(f\"‚úÖ PDF text extracted successfully ({len(text_content)} characters)\")\n",
    "                        preview = text_content[:500] + \"...\" if len(text_content) > 500 else text_content\n",
    "                        print(f\"üìñ Extracted text preview:\\n{preview}\\n\")\n",
    "                        return text_content\n",
    "                    else:\n",
    "                        print(\"‚ùå Failed to extract text from PDF.\")\n",
    "                        retry = input(\"Try another file? (y/n): \").strip().lower()\n",
    "                        if retry != 'y':\n",
    "                            return get_manual_text_input(input_type)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error reading PDF file: {e}\")\n",
    "                    retry = input(\"Try another file? (y/n): \").strip().lower()\n",
    "                    if retry != 'y':\n",
    "                        return get_manual_text_input(input_type)\n",
    "            else:\n",
    "                print(\"‚ùå PDF file not found or not a PDF. Please enter a valid PDF file path.\")\n",
    "                retry = input(\"Try again? (y/n): \").strip().lower()\n",
    "                if retry != 'y':\n",
    "                    return get_manual_text_input(input_type)\n",
    "\n",
    "def run_complete_analysis():\n",
    "    \"\"\"Main function to run complete CV-JD analysis and question generation\"\"\"\n",
    "\n",
    "    print(\"üéØ ===========================================\")\n",
    "    print(\"üéØ CV-JD SKILL GAP ANALYSIS & QUESTION GENERATOR\")\n",
    "    print(\"üéØ ===========================================\")\n",
    "    print()\n",
    "    print(\"Choose input method for CV and JD:\")\n",
    "    print(\"‚Ä¢ Option 1: üìã Paste text manually\")\n",
    "    print(\"‚Ä¢ Option 2: üìÅ Upload text files (.txt)\")\n",
    "    print(\"‚Ä¢ Option 3: üìÑ Upload PDF files (.pdf)\")\n",
    "    print()\n",
    "\n",
    "    # Get CV input\n",
    "    cv_text = get_text_input(\"Enter Candidate CV\", \"CV\")\n",
    "    if cv_text is None:\n",
    "        print(\"‚ùå CV input cancelled\")\n",
    "        return None\n",
    "\n",
    "    # Get JD input\n",
    "    jd_text = get_text_input(\"Enter Job Description\", \"JD\")\n",
    "    if jd_text is None:\n",
    "        print(\"‚ùå JD input cancelled\")\n",
    "        return None\n",
    "\n",
    "    print()\n",
    "    print(\"‚è≥ Analyzing skills and generating questions...\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        # Step 1: Run Skill Gap Analysis\n",
    "        logger.info(\"üîç Running skill gap analysis...\")\n",
    "        skill_gap_analysis = dynamic_skill_analyzer.analyze_skill_gap(cv_text, jd_text)\n",
    "\n",
    "        # Display Skill Gap Results\n",
    "        display(Markdown(\"## üìä SKILL GAP ANALYSIS RESULTS\"))\n",
    "        display(Markdown(f\"**Match Percentage:** {skill_gap_analysis['match_percentage']}%\"))\n",
    "        display(Markdown(f\"**CV Skills Found:** {skill_gap_analysis['cv_skill_count']}\"))\n",
    "        display(Markdown(f\"**JD Skills Required:** {skill_gap_analysis['jd_skill_count']}\"))\n",
    "\n",
    "        # Display Matched Skills\n",
    "        if skill_gap_analysis['matched_skills']:\n",
    "            display(Markdown(\"### ‚úÖ MATCHED SKILLS\"))\n",
    "            for i, skill in enumerate(skill_gap_analysis['matched_skills'], 1):\n",
    "                display(Markdown(f\"**{i}. {skill['skill']}** (Similarity: {skill['similarity']})\"))\n",
    "                display(Markdown(f\"   - CV Evidence: *{skill['evidence_cv']}*\"))\n",
    "                display(Markdown(f\"   - JD Requirement: *{skill['evidence_jd']}*\"))\n",
    "                print()\n",
    "\n",
    "        # Display Missing Skills\n",
    "        if skill_gap_analysis['missing_skills']:\n",
    "            display(Markdown(\"### ‚ùå MISSING SKILLS\"))\n",
    "            for i, skill in enumerate(skill_gap_analysis['missing_skills'], 1):\n",
    "                display(Markdown(f\"**{i}. {skill['skill']}**\"))\n",
    "                if skill.get('jd_requirement'):\n",
    "                    display(Markdown(f\"   - JD Context: *{skill['jd_requirement']}*\"))\n",
    "                print()\n",
    "\n",
    "        print()\n",
    "        print(\"üîÑ Generating interview questions based on analysis...\")\n",
    "        print()\n",
    "\n",
    "        # Step 2: Generate Interview Questions\n",
    "        questions_result = ai_question_generator.generate_interview_questions_with_answers(\n",
    "            cv_text, jd_text, skill_gap_analysis\n",
    "        )\n",
    "\n",
    "        # Display Generated Questions\n",
    "        display(Markdown(\"## üéØ GENERATED INTERVIEW QUESTIONS\"))\n",
    "        display(Markdown(f\"**Total Questions Generated:** {len(questions_result)}\"))\n",
    "\n",
    "        for i, question in enumerate(questions_result, 1):\n",
    "            display(Markdown(f\"### ‚ùì Question {i}: {question['question']}\"))\n",
    "            display(Markdown(f\"**Focus:** {question['focus']} | **Skill Type:** {question['skill_type']}\"))\n",
    "            display(Markdown(f\"**Target Skill:** {question['target_skill']}\"))\n",
    "            display(Markdown(f\"**Rationale:** {question['rationale']}\"))\n",
    "\n",
    "            display(Markdown(\"#### üí° Model Answer:\"))\n",
    "            display(Markdown(f\"{question['model_answer']}\"))\n",
    "\n",
    "            display(Markdown(\"#### üéØ Answer Hints:\"))\n",
    "            for j, hint in enumerate(question['answer_hints'], 1):\n",
    "                display(Markdown(f\"{j}. {hint}\"))\n",
    "\n",
    "            display(Markdown(\"#### üîë Key Points to Cover:\"))\n",
    "            for j, point in enumerate(question['key_points'], 1):\n",
    "                display(Markdown(f\"{j}. {point}\"))\n",
    "\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "        # Return the complete results for further use\n",
    "        return {\n",
    "            \"skill_gap_analysis\": skill_gap_analysis,\n",
    "            \"questions\": questions_result,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error in analysis pipeline: {e}\")\n",
    "        display(Markdown(\"## ‚ùå ERROR\"))\n",
    "        display(Markdown(f\"An error occurred during analysis: `{str(e)}`\"))\n",
    "        return {\n",
    "            \"skill_gap_analysis\": None,\n",
    "            \"questions\": [],\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b752c",
   "metadata": {},
   "source": [
    "## üìä Professional CV Assessment Engine\n",
    "\n",
    "### **Gemini 2.0 Flash Integration**\n",
    "- **LangChain Framework** - Structured AI interactions\n",
    "- **Professional Prompting** - HR-expert level analysis\n",
    "- **Structured JSON Output** - Consistent, parseable results\n",
    "\n",
    "### **Analysis Dimensions**\n",
    "1. **Overall Scoring** - Realistic 5-9 scale based on content quality\n",
    "2. **Strengths & Weaknesses** - Specific to actual CV content\n",
    "3. **Actionable Recommendations** - Concrete improvement suggestions\n",
    "4. **Content Analysis** - Clarity, relevance, achievements, uniqueness\n",
    "5. **Skill Analysis** - Technical and soft skills evaluation\n",
    "6. **Formatting Assessment** - Readability, structure, professionalism\n",
    "\n",
    "### **Advanced Features**\n",
    "- **Evidence-Based** - References specific technologies and experiences\n",
    "- **Non-Generic** - Feedback applies only to the specific CV\n",
    "- **Professional Standards** - HR-grade assessment quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6c95d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LangChain with Gemini 2.0 Flash initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# cv_analyzer.py - USING LANGCHAIN WITH GEMINI 2.0 FLASH\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from typing import Dict, List, Any\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langchain_core.messages import HumanMessage, SystemMessage\n",
    "    LANGCHAIN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGCHAIN_AVAILABLE = False\n",
    "    logging.warning(\"LangChain not available. Install with: pip install langchain-google-genai\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CVAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.api_key = os.getenv('GOOGLE_API_KEY', 'key')\n",
    "\n",
    "        if LANGCHAIN_AVAILABLE and self.api_key:\n",
    "            try:\n",
    "                self.llm = ChatGoogleGenerativeAI(\n",
    "                    model=\"gemini-2.0-flash-exp\",\n",
    "                    temperature=0.7,\n",
    "                    google_api_key=self.api_key\n",
    "                )\n",
    "                self.langchain_available = True\n",
    "                logger.info(\"LangChain with Gemini 2.0 Flash initialized successfully\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to initialize LangChain: {e}\")\n",
    "                self.langchain_available = False\n",
    "        else:\n",
    "            self.langchain_available = False\n",
    "            logger.warning(\"LangChain not available or API key missing\")\n",
    "\n",
    "    def analyze_cv(self, cv_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Use Gemini 2.0 Flash via LangChain for CV analysis\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting CV analysis with Gemini 2.0 Flash...\")\n",
    "\n",
    "        # Try LangChain with Gemini first\n",
    "        if self.langchain_available:\n",
    "            gemini_result = self._try_langchain_gemini(cv_text)\n",
    "            if gemini_result:\n",
    "                logger.info(\"Successfully got Gemini 2.0 Flash analysis via LangChain\")\n",
    "                return gemini_result\n",
    "\n",
    "        # Fallback to intelligent analysis\n",
    "        logger.info(\"Using intelligent fallback analysis\")\n",
    "        return self._create_intelligent_fallback(cv_text)\n",
    "\n",
    "    def _try_langchain_gemini(self, cv_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Use LangChain with Gemini 2.0 Flash Experimental\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prompt = self._create_langchain_prompt(cv_text)\n",
    "\n",
    "            messages = [\n",
    "                SystemMessage(content=\"You are an expert CV consultant with 15+ years experience in tech recruitment.\"),\n",
    "                HumanMessage(content=prompt)\n",
    "            ]\n",
    "\n",
    "            logger.info(\"Sending request to Gemini 2.0 Flash via LangChain...\")\n",
    "            response = self.llm.invoke(messages)\n",
    "\n",
    "            if response and hasattr(response, 'content'):\n",
    "                content = response.content\n",
    "                logger.info(f\"Gemini 2.0 Flash response received: {len(content)} characters\")\n",
    "                return self._parse_gemini_response(content, cv_text)\n",
    "            else:\n",
    "                logger.error(\"No content in Gemini response\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"LangChain Gemini failed: {str(e)}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _create_langchain_prompt(self, cv_text: str) -> str:\n",
    "        \"\"\"Create optimized prompt for LangChain with Gemini\"\"\"\n",
    "        return f\"\"\"\n",
    "        You are an expert CV consultant specializing in technology professionals.\n",
    "        Analyze the following CV in extreme detail and provide highly specific, actionable feedback , all the recommendations ,all the ares of improvements and all the strengths.\n",
    "\n",
    "        CRITICAL REQUIREMENTS:\n",
    "        - Be EXTREMELY specific to the ACTUAL content of this CV\n",
    "        - Reference exact technologies, projects, experiences, and achievements mentioned\n",
    "        - Provide feedback that ONLY applies to this specific CV\n",
    "        - Do NOT use generic phrases that could apply to any CV\n",
    "        - Score realistically based on actual content quality (5-9 range)\n",
    "        - Focus on actionable improvements with clear examples\n",
    "\n",
    "        CV CONTENT TO ANALYZE:\n",
    "        {cv_text[:3500]}\n",
    "\n",
    "        Provide your analysis in this EXACT JSON format:\n",
    "\n",
    "        {{\n",
    "            \"overall_score\": \"realistic_score/10\",\n",
    "            \"strengths\": [\n",
    "                \"specific strength mentioning actual technologies or experiences from CV\",\n",
    "                \"specific strength about content quality or structure\",\n",
    "                \"specific strength about skills or achievements\"\n",
    "            ],\n",
    "            \"weaknesses\": [\n",
    "                \"specific weakness with concrete examples from CV\",\n",
    "                \"specific area needing improvement with references to actual content\"\n",
    "            ],\n",
    "            \"recommendations\": [\n",
    "                \"highly specific, actionable recommendation tied to CV content\",\n",
    "                \"concrete suggestion with examples of how to implement\",\n",
    "                \"specific improvement that addresses actual gaps found\"\n",
    "            ],\n",
    "            \"content_analysis\": {{\n",
    "                \"clarity\": \"specific assessment of writing clarity based on actual text\",\n",
    "                \"relevance\": \"assessment of relevance for the roles/technologies mentioned\",\n",
    "                \"achievements\": \"detailed evaluation of achievement presentation quality\",\n",
    "                \"uniqueness\": \"what makes this CV unique based on its actual content\"\n",
    "            }},\n",
    "            \"skill_analysis\": {{\n",
    "                \"technical_skills\": \"detailed assessment of technical skills mentioned\",\n",
    "                \"soft_skills\": \"evaluation of soft skills presentation\",\n",
    "                \"skill_gaps\": \"specific skill gaps identified from content\",\n",
    "                \"skill_strengths\": \"particular technical strengths found\"\n",
    "            }},\n",
    "            \"formatting_analysis\": {{\n",
    "                \"readability\": \"specific readability assessment with examples\",\n",
    "                \"structure\": \"evaluation of CV structure and organization\",\n",
    "                \"professionalism\": \"assessment of professional presentation\"\n",
    "            }},\n",
    "            \"key_insights\": [\n",
    "                \"unique insight specific to this CV's content\",\n",
    "                \"observation about career trajectory or specialization\",\n",
    "                \"notable pattern or standout feature in CV\"\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        IMPORTANT:\n",
    "        - If you see Python, Django, AWS, or other specific technologies, mention them by name\n",
    "        - If you see leadership experience, quantify it specifically\n",
    "        - If you see projects or achievements, reference them directly\n",
    "        - Be brutally honest and constructive\n",
    "        - Provide feedback that would only make sense for THIS specific CV\n",
    "        \"\"\"\n",
    "\n",
    "    def _parse_gemini_response(self, content: str, cv_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parse Gemini response from LangChain\"\"\"\n",
    "        try:\n",
    "            # Try to extract JSON from the response\n",
    "            json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group()\n",
    "\n",
    "                # Clean common JSON issues\n",
    "                json_str = re.sub(r',\\s*}', '}', json_str)\n",
    "                json_str = re.sub(r',\\s*]', ']', json_str)\n",
    "                json_str = re.sub(r'\\\\\"', '\"', json_str)\n",
    "\n",
    "                gemini_data = json.loads(json_str)\n",
    "\n",
    "                # Enhance with metadata\n",
    "                enhanced_data = self._enhance_gemini_data(gemini_data, cv_text)\n",
    "                return enhanced_data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"JSON decode error: {e}\")\n",
    "            logger.error(f\"Problematic content: {content[:500]}...\")\n",
    "\n",
    "        # If JSON parsing fails, structure the text response\n",
    "        return self._structure_text_response(content, cv_text)\n",
    "\n",
    "    def _enhance_gemini_data(self, gemini_data: Dict[str, Any], cv_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Enhance and validate Gemini data\"\"\"\n",
    "        enhanced = {\n",
    "            \"overall_score\": gemini_data.get('overall_score', str(self._calculate_fallback_score(cv_text))),\n",
    "            \"strengths\": self._ensure_array(gemini_data.get('strengths'), [\n",
    "                \"Professional content quality and structure\",\n",
    "                \"Clear career progression information\"\n",
    "            ]),\n",
    "            \"weaknesses\": self._ensure_array(gemini_data.get('weaknesses'), [\n",
    "                \"Opportunity for more specific achievement quantification\"\n",
    "            ]),\n",
    "            \"recommendations\": self._ensure_array(gemini_data.get('recommendations'), [\n",
    "                \"Add specific metrics to key achievements\",\n",
    "                \"Enhance project descriptions with technical details\",\n",
    "                \"Highlight leadership experience with team sizes\"\n",
    "            ]),\n",
    "            \"content_analysis\": {\n",
    "                \"clarity\": gemini_data.get('content_analysis', {}).get('clarity', \"Clear professional writing style\"),\n",
    "                \"relevance\": gemini_data.get('content_analysis', {}).get('relevance', \"Relevant for technical roles\"),\n",
    "                \"achievements\": gemini_data.get('content_analysis', {}).get('achievements', \"Good achievement foundation\"),\n",
    "                \"uniqueness\": gemini_data.get('content_analysis', {}).get('uniqueness', \"Unique professional background\")\n",
    "            },\n",
    "            \"skill_analysis\": {\n",
    "                \"technical_skills\": gemini_data.get('skill_analysis', {}).get('technical_skills', \"Solid technical foundation\"),\n",
    "                \"soft_skills\": gemini_data.get('skill_analysis', {}).get('soft_skills', \"Good interpersonal skills\"),\n",
    "                \"skill_gaps\": gemini_data.get('skill_analysis', {}).get('skill_gaps', \"Opportunities for skill expansion\"),\n",
    "                \"skill_strengths\": gemini_data.get('skill_analysis', {}).get('skill_strengths', \"Strong core competencies\")\n",
    "            },\n",
    "            \"formatting_analysis\": {\n",
    "                \"readability\": gemini_data.get('formatting_analysis', {}).get('readability', \"Generally readable format\"),\n",
    "                \"structure\": gemini_data.get('formatting_analysis', {}).get('structure', \"Good structural organization\"),\n",
    "                \"professionalism\": gemini_data.get('formatting_analysis', {}).get('professionalism', \"Professional presentation\")\n",
    "            },\n",
    "            \"key_insights\": self._ensure_array(gemini_data.get('key_insights'), [\n",
    "                \"Good foundation with specific enhancement opportunities\",\n",
    "                \"Well-positioned for technical role applications\"\n",
    "            ]),\n",
    "            \"analysis_source\": \"gemini_2.0_flash_langchain\",\n",
    "            \"analysis_timestamp\": datetime.now().isoformat(),\n",
    "            \"content_preview\": cv_text[:200] + \"...\" if len(cv_text) > 200 else cv_text,\n",
    "            \"model_used\": \"gemini-2.0-flash-exp\",\n",
    "            \"ai_generated\": True\n",
    "        }\n",
    "\n",
    "        return enhanced\n",
    "\n",
    "    def _structure_text_response(self, text: str, cv_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Structure text response when JSON parsing fails\"\"\"\n",
    "        logger.info(\"Structuring text response from Gemini\")\n",
    "\n",
    "        # Extract information from text\n",
    "        analysis = self._analyze_response_text(text)\n",
    "\n",
    "        return {\n",
    "            \"overall_score\": analysis.get('score', '7'),\n",
    "            \"strengths\": analysis.get('strengths', [\"Professional CV with good structure\"]),\n",
    "            \"weaknesses\": analysis.get('weaknesses', [\"Opportunity to enhance specific achievements\"]),\n",
    "            \"recommendations\": analysis.get('recommendations', [\n",
    "                \"Add quantifiable metrics to achievements\",\n",
    "                \"Enhance technical skill descriptions\",\n",
    "                \"Improve project documentation\"\n",
    "            ]),\n",
    "            \"content_analysis\": {\n",
    "                \"clarity\": analysis.get('clarity', \"Clear and professional writing\"),\n",
    "                \"relevance\": analysis.get('relevance', \"Relevant for target roles\"),\n",
    "                \"achievements\": analysis.get('achievements', \"Good achievement foundation\"),\n",
    "                \"uniqueness\": analysis.get('uniqueness', \"Unique professional elements\")\n",
    "            },\n",
    "            \"skill_analysis\": {\n",
    "                \"technical_skills\": analysis.get('technical_skills', \"Solid technical skills\"),\n",
    "                \"soft_skills\": analysis.get('soft_skills', \"Good soft skills presentation\"),\n",
    "                \"skill_gaps\": analysis.get('skill_gaps', \"Some skill enhancement opportunities\"),\n",
    "                \"skill_strengths\": analysis.get('skill_strengths', \"Strong core competencies\")\n",
    "            },\n",
    "            \"formatting_analysis\": {\n",
    "                \"readability\": analysis.get('readability', \"Generally good readability\"),\n",
    "                \"structure\": analysis.get('structure', \"Well-structured format\"),\n",
    "                \"professionalism\": analysis.get('professionalism', \"Professional presentation\")\n",
    "            },\n",
    "            \"key_insights\": analysis.get('insights', [\n",
    "                \"Good potential for specific enhancements\",\n",
    "                \"Solid foundation for technical roles\"\n",
    "            ]),\n",
    "            \"analysis_source\": \"gemini_2.0_flash_text\",\n",
    "            \"analysis_timestamp\": datetime.now().isoformat(),\n",
    "            \"content_preview\": cv_text[:200] + \"...\" if len(cv_text) > 200 else cv_text,\n",
    "            \"model_used\": \"gemini-2.0-flash-exp\",\n",
    "            \"ai_generated\": True\n",
    "        }\n",
    "\n",
    "    def _analyze_response_text(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze text response from Gemini\"\"\"\n",
    "        analysis = {}\n",
    "\n",
    "        # Extract score\n",
    "        score_match = re.search(r'(\\d+)(?:\\s*\\/\\s*10)?|score.*?(\\d+)', text.lower())\n",
    "        analysis['score'] = score_match.group(1) or score_match.group(2) if score_match else '7'\n",
    "\n",
    "        # Extract sections\n",
    "        sections = self._extract_sections_from_text(text)\n",
    "        analysis.update(sections)\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _extract_sections_from_text(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract sections from text response\"\"\"\n",
    "        sections = {}\n",
    "\n",
    "        section_patterns = {\n",
    "            'strengths': r'(?:strengths?|positives?).*?[:\\n](.*?)(?=weaknesses|improvements|recommendations|$)',\n",
    "            'weaknesses': r'(?:weaknesses?|improvements?).*?[:\\n](.*?)(?=strengths|recommendations|$)',\n",
    "            'recommendations': r'(?:recommendations?|suggestions?).*?[:\\n](.*?)(?=strengths|weaknesses|$)'\n",
    "        }\n",
    "\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        for section, pattern in section_patterns.items():\n",
    "            match = re.search(pattern, text_lower, re.IGNORECASE | re.DOTALL)\n",
    "            if match:\n",
    "                content = match.group(1).strip()\n",
    "                items = self._extract_items(content)\n",
    "                if items:\n",
    "                    sections[section] = items\n",
    "\n",
    "        return sections\n",
    "\n",
    "    def _extract_items(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract items from text\"\"\"\n",
    "        items = []\n",
    "\n",
    "        # Multiple extraction strategies\n",
    "        lines = text.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            # Skip empty lines and very short lines\n",
    "            if line and len(line) > 15:\n",
    "                # Remove bullet points and numbers\n",
    "                clean_line = re.sub(r'^[‚Ä¢\\-*\\d\\.\\s]+', '', line)\n",
    "                if clean_line and len(clean_line) > 10:\n",
    "                    items.append(clean_line)\n",
    "\n",
    "        return items[:4] if items else []\n",
    "\n",
    "    def _ensure_array(self, value: Any, default: List[str]) -> List[str]:\n",
    "        \"\"\"Ensure value is a proper array\"\"\"\n",
    "        if isinstance(value, list) and len(value) > 0:\n",
    "            return value\n",
    "        return default\n",
    "\n",
    "    def _calculate_fallback_score(self, cv_text: str) -> int:\n",
    "        \"\"\"Calculate fallback score based on content quality\"\"\"\n",
    "        cv_lower = cv_text.lower()\n",
    "\n",
    "        score = 6\n",
    "        if len(cv_text) > 1200:\n",
    "            score += 1\n",
    "        if any(tech in cv_lower for tech in ['python', 'django', 'aws', 'docker']):\n",
    "            score += 1\n",
    "        if len(re.findall(r'\\d+%|\\$\\d+', cv_text)) >= 2:\n",
    "            score += 1\n",
    "\n",
    "        return min(9, max(5, score))\n",
    "\n",
    "    def _create_intelligent_fallback(self, cv_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        High-quality fallback when Gemini fails\n",
    "        \"\"\"\n",
    "        cv_lower = cv_text.lower()\n",
    "\n",
    "        # Analyze content\n",
    "        analysis = self._analyze_content_intelligently(cv_text, cv_lower)\n",
    "\n",
    "        return {\n",
    "            \"overall_score\": str(analysis['score']),\n",
    "            \"strengths\": analysis['strengths'],\n",
    "            \"weaknesses\": analysis['weaknesses'],\n",
    "            \"recommendations\": analysis['recommendations'],\n",
    "            \"content_analysis\": {\n",
    "                \"clarity\": analysis['clarity'],\n",
    "                \"relevance\": analysis['relevance'],\n",
    "                \"achievements\": analysis['achievements'],\n",
    "                \"uniqueness\": analysis['uniqueness']\n",
    "            },\n",
    "            \"skill_analysis\": {\n",
    "                \"technical_skills\": analysis['technical_skills'],\n",
    "                \"soft_skills\": analysis['soft_skills'],\n",
    "                \"skill_gaps\": analysis['skill_gaps'],\n",
    "                \"skill_strengths\": analysis['skill_strengths']\n",
    "            },\n",
    "            \"formatting_analysis\": {\n",
    "                \"readability\": analysis['readability'],\n",
    "                \"structure\": analysis['structure'],\n",
    "                \"professionalism\": analysis['professionalism']\n",
    "            },\n",
    "            \"key_insights\": analysis['insights'],\n",
    "            \"analysis_source\": \"intelligent_fallback\",\n",
    "            \"analysis_timestamp\": datetime.now().isoformat(),\n",
    "            \"content_preview\": cv_text[:200] + \"...\" if len(cv_text) > 200 else cv_text,\n",
    "            \"model_used\": \"fallback_analysis\",\n",
    "            \"ai_generated\": False\n",
    "        }\n",
    "\n",
    "    def _analyze_content_intelligently(self, cv_text: str, cv_lower: str) -> Dict[str, Any]:\n",
    "        \"\"\"Intelligent content analysis\"\"\"\n",
    "        # Simple technology analysis\n",
    "        technologies = []\n",
    "        tech_keywords = ['python', 'django', 'aws', 'docker', 'javascript', 'react', 'java', 'sql']\n",
    "        for tech in tech_keywords:\n",
    "            if tech in cv_lower:\n",
    "                technologies.append(tech)\n",
    "\n",
    "        # Basic metrics\n",
    "        word_count = len(cv_text.split())\n",
    "        bullet_count = cv_text.count('‚Ä¢') + cv_text.count('- ')\n",
    "        achievement_count = len(re.findall(r'\\d+%|\\$\\d+', cv_text))\n",
    "\n",
    "        return {\n",
    "            'score': self._calculate_intelligent_score(technologies, word_count, bullet_count, achievement_count),\n",
    "            'strengths': self._generate_intelligent_strengths(technologies, word_count, cv_text),\n",
    "            'weaknesses': self._generate_intelligent_weaknesses(technologies, bullet_count, achievement_count),\n",
    "            'recommendations': self._generate_intelligent_recommendations(technologies, achievement_count),\n",
    "            'clarity': \"Very clear\" if word_count > 1000 else \"Clear\" if word_count > 500 else \"Generally clear\",\n",
    "            'relevance': \"Highly relevant\" if len(technologies) >= 3 else \"Relevant\",\n",
    "            'achievements': \"Strong\" if achievement_count >= 3 else \"Good\" if achievement_count >= 1 else \"Needs improvement\",\n",
    "            'uniqueness': \"Unique combination of skills\" if len(technologies) >= 4 else \"Good professional background\",\n",
    "            'technical_skills': f\"Strong in {', '.join(technologies[:3])}\" if technologies else \"Good technical foundation\",\n",
    "            'soft_skills': \"Well demonstrated\" if any(skill in cv_lower for skill in ['communication', 'leadership', 'teamwork']) else \"Good indication\",\n",
    "            'skill_gaps': \"Opportunity to expand\" if len(technologies) < 5 else \"Well-rounded\",\n",
    "            'skill_strengths': f\"Expertise in {', '.join(technologies[:2])}\" if technologies else \"Solid core skills\",\n",
    "            'readability': \"Excellent\" if bullet_count >= 8 else \"Good\" if bullet_count >= 4 else \"Needs improvement\",\n",
    "            'structure': \"Professional\" if any(section in cv_lower for section in ['experience', 'education', 'skills']) else \"Good\",\n",
    "            'professionalism': \"Highly professional\",\n",
    "            'insights': [\n",
    "                f\"Strong foundation in {len(technologies)} technologies\" if technologies else \"Good professional foundation\",\n",
    "                \"Opportunity to enhance quantitative achievements\" if achievement_count < 3 else \"Good achievement documentation\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _calculate_intelligent_score(self, technologies: List[str], word_count: int, bullet_count: int, achievement_count: int) -> int:\n",
    "        \"\"\"Calculate intelligent score\"\"\"\n",
    "        score = 6\n",
    "\n",
    "        if len(technologies) >= 3:\n",
    "            score += 1\n",
    "        if word_count > 800:\n",
    "            score += 1\n",
    "        if bullet_count >= 5:\n",
    "            score += 1\n",
    "        if achievement_count >= 2:\n",
    "            score += 1\n",
    "\n",
    "        return min(9, max(5, score))\n",
    "\n",
    "    def _generate_intelligent_strengths(self, technologies: List[str], word_count: int, cv_text: str) -> List[str]:\n",
    "        \"\"\"Generate intelligent strengths\"\"\"\n",
    "        strengths = []\n",
    "\n",
    "        if technologies:\n",
    "            strengths.append(f\"Strong technical skills in {', '.join(technologies[:3])}\")\n",
    "\n",
    "        if word_count > 1000:\n",
    "            strengths.append(\"Comprehensive and detailed professional background\")\n",
    "\n",
    "        if any(term in cv_text.lower() for term in ['led', 'managed', 'directed']):\n",
    "            strengths.append(\"Clear leadership and management experience\")\n",
    "\n",
    "        return strengths if strengths else [\"Professional presentation with clear information\"]\n",
    "\n",
    "    def _generate_intelligent_weaknesses(self, technologies: List[str], bullet_count: int, achievement_count: int) -> List[str]:\n",
    "        \"\"\"Generate intelligent weaknesses\"\"\"\n",
    "        weaknesses = []\n",
    "\n",
    "        if achievement_count < 2:\n",
    "            weaknesses.append(\"Limited quantifiable achievements - add specific metrics\")\n",
    "\n",
    "        if bullet_count < 5:\n",
    "            weaknesses.append(\"Could benefit from more bullet points for better readability\")\n",
    "\n",
    "        if len(technologies) < 2:\n",
    "            weaknesses.append(\"Opportunity to showcase more technical skills\")\n",
    "\n",
    "        return weaknesses if weaknesses else [\"Opportunity to enhance specific accomplishments\"]\n",
    "\n",
    "    def _generate_intelligent_recommendations(self, technologies: List[str], achievement_count: int) -> List[str]:\n",
    "        \"\"\"Generate intelligent recommendations\"\"\"\n",
    "        recommendations = [\n",
    "            \"Add 2-3 quantifiable achievements with specific numbers and percentages\",\n",
    "            \"Use bullet points consistently throughout role descriptions\",\n",
    "            \"Highlight key projects and their business impact\"\n",
    "        ]\n",
    "\n",
    "        if 'python' in technologies:\n",
    "            recommendations.append(\"Showcase specific Python projects or contributions\")\n",
    "\n",
    "        if 'aws' in technologies:\n",
    "            recommendations.append(\"Detail specific AWS services and architectures used\")\n",
    "\n",
    "        if achievement_count < 2:\n",
    "            recommendations.append(\"Use the STAR method (Situation, Task, Action, Result) for achievements\")\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "# Create the instance for import\n",
    "cv_analyzer = CVAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59c570",
   "metadata": {},
   "source": [
    "## üé™ Interactive CV Analysis Demo\n",
    "\n",
    "### **User-Friendly Interface**\n",
    "- **Multiple Input Methods** - Text, file upload, PDF processing\n",
    "- **Real-time Preview** - Show extracted content before analysis\n",
    "- **Professional Display** - Formatted results with collapsible sections\n",
    "\n",
    "### **Demo Features**\n",
    "- **Live Analysis** - Process CVs in real-time\n",
    "- **Comprehensive Reports** - All analysis dimensions displayed\n",
    "- **Raw Data Access** - JSON output for developers\n",
    "- **Error Resilience** - Handles various file formats and encodings\n",
    "\n",
    "### **Output Sections**\n",
    "- Overall score and summary\n",
    "- Strengths with specific examples\n",
    "- Areas for improvement\n",
    "- Actionable recommendations\n",
    "- Detailed skill analysis\n",
    "- Formatting assessment\n",
    "- Key insights and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb2b25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test CV Analyzer with File Upload\n",
    "import logging\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Setup logging to see the analysis process\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def test_cv_analyzer():\n",
    "    \"\"\"Test the CV analyzer with file upload\"\"\"\n",
    "\n",
    "    print(\"üéØ ===========================================\")\n",
    "    print(\"üéØ CV ANALYZER TEST - GEMINI 2.0 FLASH\")\n",
    "    print(\"üéØ ===========================================\")\n",
    "    print()\n",
    "\n",
    "    # Get CV input\n",
    "    cv_text = get_cv_input()\n",
    "    if cv_text is None:\n",
    "        print(\"‚ùå CV input cancelled\")\n",
    "        return None\n",
    "\n",
    "    print()\n",
    "    print(\"‚è≥ Analyzing CV with Gemini 2.0 Flash...\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        # Analyze the CV\n",
    "        analysis_result = cv_analyzer.analyze_cv(cv_text)\n",
    "\n",
    "        # Display results\n",
    "        display_analysis_results(analysis_result)\n",
    "\n",
    "        return analysis_result\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error in CV analysis: {e}\")\n",
    "        display(Markdown(\"## ‚ùå ERROR\"))\n",
    "        display(Markdown(f\"An error occurred during CV analysis: `{str(e)}`\"))\n",
    "        return None\n",
    "\n",
    "def get_cv_input():\n",
    "    \"\"\"Get CV input from user with multiple options\"\"\"\n",
    "\n",
    "    print(\"üìù CV INPUT OPTIONS:\")\n",
    "    print(\"1. üìã Paste CV text manually\")\n",
    "    print(\"2. üìÅ Upload text file (.txt)\")\n",
    "    print(\"3. üìÑ Upload PDF file (.pdf)\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"Choose CV input method (1, 2, or 3): \").strip()\n",
    "            if choice == '1':\n",
    "                return get_manual_cv_input()\n",
    "            elif choice == '2':\n",
    "                return get_text_file_input()\n",
    "            elif choice == '3':\n",
    "                return get_pdf_file_input()\n",
    "            else:\n",
    "                print(\"‚ùå Please enter 1, 2, or 3\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è Input cancelled\")\n",
    "            return None\n",
    "\n",
    "def get_manual_cv_input():\n",
    "    \"\"\"Get manual CV text input\"\"\"\n",
    "    print(f\"\\nüìã PASTE CV TEXT:\")\n",
    "    print(\"   (Paste the CV content below, then press Enter twice to finish)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    lines = []\n",
    "    empty_line_count = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            line = input()\n",
    "            if line.strip() == \"\":\n",
    "                empty_line_count += 1\n",
    "                if empty_line_count >= 2 and len(lines) > 0:\n",
    "                    break\n",
    "            else:\n",
    "                empty_line_count = 0\n",
    "            lines.append(line)\n",
    "        except EOFError:\n",
    "            break\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è Input cancelled\")\n",
    "            return None\n",
    "\n",
    "    text = \"\\n\".join(lines)\n",
    "    print(f\"‚úÖ CV text received ({len(text)} characters)\")\n",
    "\n",
    "    # Show preview\n",
    "    preview = text[:300] + \"...\" if len(text) > 300 else text\n",
    "    print(f\"üìñ CV Preview:\\n{preview}\\n\")\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_text_file_input():\n",
    "    \"\"\"Get CV from text file upload\"\"\"\n",
    "    print(f\"\\nüìÅ CV TEXT FILE UPLOAD:\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your .txt CV file...\")\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        if uploaded:\n",
    "            filename = list(uploaded.keys())[0]\n",
    "            # Try different encodings for text files\n",
    "            try:\n",
    "                content = uploaded[filename].decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    content = uploaded[filename].decode('latin-1')\n",
    "                except UnicodeDecodeError:\n",
    "                    content = uploaded[filename].decode('utf-8', errors='ignore')\n",
    "\n",
    "            print(f\"‚úÖ Text file '{filename}' uploaded successfully ({len(content)} characters)\")\n",
    "\n",
    "            # Show preview\n",
    "            preview = content[:300] + \"...\" if len(content) > 300 else content\n",
    "            print(f\"üìñ CV Preview:\\n{preview}\\n\")\n",
    "\n",
    "            return content\n",
    "        else:\n",
    "            print(\"‚ùå No file uploaded. Switching to manual input...\")\n",
    "            return get_manual_cv_input()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"‚ùå File upload not available in this environment\")\n",
    "        return get_manual_cv_input()\n",
    "\n",
    "def get_pdf_file_input():\n",
    "    \"\"\"Get CV from PDF file upload\"\"\"\n",
    "    print(f\"\\nüìÑ CV PDF FILE UPLOAD:\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"üì§ Please upload your PDF CV file...\")\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        if uploaded:\n",
    "            filename = list(uploaded.keys())[0]\n",
    "            if not filename.lower().endswith('.pdf'):\n",
    "                print(\"‚ùå Please upload a PDF file. Switching to manual input...\")\n",
    "                return get_manual_cv_input()\n",
    "\n",
    "            print(f\"‚è≥ Extracting text from PDF '{filename}'...\")\n",
    "            pdf_content = uploaded[filename]\n",
    "\n",
    "            # Extract text from PDF using the same method as in cell 3\n",
    "            text_content = extract_text_from_pdf(pdf_content)\n",
    "\n",
    "            if text_content:\n",
    "                print(f\"‚úÖ PDF text extracted successfully ({len(text_content)} characters)\")\n",
    "                # Show preview of extracted text\n",
    "                preview = text_content[:300] + \"...\" if len(text_content) > 300 else text_content\n",
    "                print(f\"üìñ Extracted CV Preview:\\n{preview}\\n\")\n",
    "                return text_content\n",
    "            else:\n",
    "                print(\"‚ùå Failed to extract text from PDF. Switching to manual input...\")\n",
    "                return get_manual_cv_input()\n",
    "        else:\n",
    "            print(\"‚ùå No file uploaded. Switching to manual input...\")\n",
    "            return get_manual_cv_input()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"‚ùå PDF upload not available in this environment\")\n",
    "        return get_manual_cv_input()\n",
    "\n",
    "def extract_text_from_pdf(pdf_content):\n",
    "    \"\"\"Extract text from PDF content using PyPDFLoader\"\"\"\n",
    "    try:\n",
    "        # Save PDF content to temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:\n",
    "            temp_file.write(pdf_content)\n",
    "            temp_path = temp_file.name\n",
    "\n",
    "        # Use PyPDFLoader to extract text\n",
    "        from langchain_community.document_loaders import PyPDFLoader\n",
    "        loader = PyPDFLoader(temp_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Combine all pages into single text\n",
    "        text = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "        # Clean up temporary file\n",
    "        os.unlink(temp_path)\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting text from PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_analysis_results(analysis_result):\n",
    "    \"\"\"Display the CV analysis results in a formatted way\"\"\"\n",
    "\n",
    "    display(Markdown(\"## üìä CV ANALYSIS RESULTS\"))\n",
    "    display(Markdown(f\"**Analysis Source:** {analysis_result.get('analysis_source', 'Unknown')}\"))\n",
    "    display(Markdown(f\"**Model Used:** {analysis_result.get('model_used', 'Unknown')}\"))\n",
    "    display(Markdown(f\"**AI Generated:** {'Yes' if analysis_result.get('ai_generated', False) else 'No'}\"))\n",
    "\n",
    "    # Overall Score\n",
    "    display(Markdown(f\"### üéØ Overall Score: {analysis_result.get('overall_score', 'N/A')}\"))\n",
    "\n",
    "    # Strengths\n",
    "    display(Markdown(\"### ‚úÖ STRENGTHS\"))\n",
    "    strengths = analysis_result.get('strengths', [])\n",
    "    if strengths:\n",
    "        for i, strength in enumerate(strengths, 1):\n",
    "            display(Markdown(f\"{i}. {strength}\"))\n",
    "    else:\n",
    "        display(Markdown(\"*No specific strengths identified*\"))\n",
    "\n",
    "    # Weaknesses\n",
    "    display(Markdown(\"### ‚ùå AREAS FOR IMPROVEMENT\"))\n",
    "    weaknesses = analysis_result.get('weaknesses', [])\n",
    "    if weaknesses:\n",
    "        for i, weakness in enumerate(weaknesses, 1):\n",
    "            display(Markdown(f\"{i}. {weakness}\"))\n",
    "    else:\n",
    "        display(Markdown(\"*No specific weaknesses identified*\"))\n",
    "\n",
    "    # Recommendations\n",
    "    display(Markdown(\"### üí° RECOMMENDATIONS\"))\n",
    "    recommendations = analysis_result.get('recommendations', [])\n",
    "    if recommendations:\n",
    "        for i, recommendation in enumerate(recommendations, 1):\n",
    "            display(Markdown(f\"{i}. {recommendation}\"))\n",
    "    else:\n",
    "        display(Markdown(\"*No specific recommendations*\"))\n",
    "\n",
    "    # Content Analysis\n",
    "    display(Markdown(\"### üìù CONTENT ANALYSIS\"))\n",
    "    content_analysis = analysis_result.get('content_analysis', {})\n",
    "    display(Markdown(f\"- **Clarity:** {content_analysis.get('clarity', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Relevance:** {content_analysis.get('relevance', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Achievements:** {content_analysis.get('achievements', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Uniqueness:** {content_analysis.get('uniqueness', 'N/A')}\"))\n",
    "\n",
    "    # Skill Analysis\n",
    "    display(Markdown(\"### üîß SKILL ANALYSIS\"))\n",
    "    skill_analysis = analysis_result.get('skill_analysis', {})\n",
    "    display(Markdown(f\"- **Technical Skills:** {skill_analysis.get('technical_skills', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Soft Skills:** {skill_analysis.get('soft_skills', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Skill Gaps:** {skill_analysis.get('skill_gaps', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Skill Strengths:** {skill_analysis.get('skill_strengths', 'N/A')}\"))\n",
    "\n",
    "    # Formatting Analysis\n",
    "    display(Markdown(\"### üìê FORMATTING ANALYSIS\"))\n",
    "    formatting_analysis = analysis_result.get('formatting_analysis', {})\n",
    "    display(Markdown(f\"- **Readability:** {formatting_analysis.get('readability', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Structure:** {formatting_analysis.get('structure', 'N/A')}\"))\n",
    "    display(Markdown(f\"- **Professionalism:** {formatting_analysis.get('professionalism', 'N/A')}\"))\n",
    "\n",
    "    # Key Insights\n",
    "    display(Markdown(\"### üîç KEY INSIGHTS\"))\n",
    "    insights = analysis_result.get('key_insights', [])\n",
    "    if insights:\n",
    "        for i, insight in enumerate(insights, 1):\n",
    "            display(Markdown(f\"{i}. {insight}\"))\n",
    "    else:\n",
    "        display(Markdown(\"*No specific insights*\"))\n",
    "\n",
    "    # Raw JSON view (collapsible)\n",
    "    display(Markdown(\"### üìã RAW ANALYSIS DATA\"))\n",
    "    display(HTML(\"\"\"\n",
    "    <details>\n",
    "    <summary>Click to view raw JSON data</summary>\n",
    "    <pre style=\"background: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto;\">\n",
    "    \"\"\" + json.dumps(analysis_result, indent=2) + \"\"\"\n",
    "    </pre>\n",
    "    </details>\n",
    "    \"\"\"))\n",
    "\n",
    "# Quick test function for already loaded text\n",
    "def quick_analyze_cv(cv_text):\n",
    "    \"\"\"Quick analysis function for already loaded CV text\"\"\"\n",
    "    print(\"‚è≥ Quick analyzing CV...\")\n",
    "    result = cv_analyzer.analyze_cv(cv_text)\n",
    "    display_analysis_results(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7064b5e",
   "metadata": {},
   "source": [
    "# üìÑ Demo of our agent‚Äôs functionality the Analysis Pipeline\n",
    "The function below runs the complete CV‚ÄìJD analysis pipeline.\n",
    "It orchestrates text parsing, skill extraction, and LLM-based reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8313d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ===========================================\n",
      "üéØ CV-JD SKILL GAP ANALYSIS & QUESTION GENERATOR\n",
      "üéØ ===========================================\n",
      "\n",
      "Choose input method for CV and JD:\n",
      "‚Ä¢ Option 1: üìã Paste text manually\n",
      "‚Ä¢ Option 2: üìÅ Upload text files (.txt)\n",
      "‚Ä¢ Option 3: üìÑ Upload PDF files (.pdf)\n",
      "\n",
      "\n",
      "üìù CV INPUT OPTIONS:\n",
      "1. üìã Paste text manually\n",
      "2. üìÅ Upload text file (.txt)\n",
      "3. üìÑ Upload PDF file (.pdf)\n",
      "\n",
      "üìã PASTE CV TEXT:\n",
      "   (Paste the content below, then press Enter twice to finish)\n",
      "--------------------------------------------------\n",
      "‚úÖ CV text received (862 characters)\n",
      "\n",
      "üìù JD INPUT OPTIONS:\n",
      "1. üìã Paste text manually\n",
      "2. üìÅ Upload text file (.txt)\n",
      "3. üìÑ Upload PDF file (.pdf)\n",
      "‚ùå Please enter 1, 2, or 3\n",
      "\n",
      "üìã PASTE JD TEXT:\n",
      "   (Paste the content below, then press Enter twice to finish)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Running skill gap analysis...\n",
      "Extracted 14 clean skills: ['Django', 'Docker', 'Flask', 'Git', 'Javascript', 'Jira', 'Kubernetes', 'Languages: Python', 'Microservices', 'Python', 'React', 'React Tools: Git', 'Sql Frameworks: Django', 'Team Leadership']\n",
      "Extracted 4 clean skills: ['Aws', 'Django', 'Gcp', 'Python']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ JD text received (877 characters)\n",
      "\n",
      "‚è≥ Analyzing skills and generating questions...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 82.08it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 69.86it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 84.17it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 83.64it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 82.63it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 82.71it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 78.73it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 87.84it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 78.38it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 89.15it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 83.56it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.20it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 75.60it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 82.06it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 82.20it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 98.82it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 80.77it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 96.68it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 93.95it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 87.51it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 83.74it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 66.42it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 88.43it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 79.47it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.73it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 79.83it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 98.90it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.44it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 80.95it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 95.72it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.69it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 80.18it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 105.72it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 101.69it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.73it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 102.75it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 90.21it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 83.44it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 97.75it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 90.00it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 76.15it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 93.69it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 102.68it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 85.98it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.46it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.24it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 104.86it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 89.96it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 84.99it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 70.63it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.82it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.31it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 90.57it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 98.99it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 96.01it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.58it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 77.60it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 101.28it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 91.32it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 95.80it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 99.77it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 88.11it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 77.42it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 95.15it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 89.73it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 98.41it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 87.01it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.76it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 88.88it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 92.52it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 85.85it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 114.48it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 101.43it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 99.22it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 100.21it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 102.65it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 94.41it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 76.41it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 43.22it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 64.76it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.31it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 64.37it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 88.16it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.06it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 77.50it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 75.63it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 107.71it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 85.32it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 108.16it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 113.17it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 87.84it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 94.27it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 100.11it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 88.44it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 117.70it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 105.09it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 115.67it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 90.84it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 95.61it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 100.32it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 105.38it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 81.46it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 116.40it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 96.22it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 86.73it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 102.30it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 71.53it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 117.59it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 109.02it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 108.71it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 106.40it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 89.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìä SKILL GAP ANALYSIS RESULTS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Match Percentage:** 50.0%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CV Skills Found:** 14"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**JD Skills Required:** 4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ MATCHED SKILLS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**1. Django** (Similarity: 1.0)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - CV Evidence: *EXPERIENCE: Senior Software Engineer, TechCorp Inc (2019-Present) - Developed and maintained **scalable microservices...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - JD Requirement: *‚Ä¢ Must have **5+ years of experience** with **Python** and **Django***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**2. Python** (Similarity: 1.0)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - CV Evidence: *EXPERIENCE: Senior Software Engineer, TechCorp Inc (2019-Present) - Developed and maintained **scalable microservices...*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - JD Requirement: *‚Ä¢ Must have **5+ years of experience** with **Python** and **Django***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùå MISSING SKILLS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**1. Aws**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - JD Context: *‚Ä¢ Design, deploy, and maintain solutions on **AWS** and **GCP Cloud Platforms***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**2. Gcp**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - JD Context: *‚Ä¢ Design, deploy, and maintain solutions on **AWS** and **GCP Cloud Platforms***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating interview questions with answers and hints\n",
      "üìä Matched skills: ['Django', 'Python']\n",
      "üìä Missing skills: ['Aws', 'Gcp']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üîÑ Generating interview questions based on analysis...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì® Raw AI Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"question\": \"Describe a time when you had to make a significant architectural decision that had a major impact on a project. What were the key considerations, and how did you ensure buy-in from the team?\",\n",
      "    \"focus\": \"behavioral\",\n",
      "    \"rationale\": \"This question assesses the candidate's ability to make strategic architectural decisions and influence others, which is crucial for a Senior Software Architect role.\",\n",
      "    \"skill_type\": \"matched_skill\",\n",
      "    \"target_skill\": \"Softwar...\n",
      "‚úÖ Successfully parsed 6 questions\n",
      "üìù Question 1: Describe a time when you had to make a significant architectural decision that had a major impact on...\n",
      "   Answer: Yes\n",
      "   Hints: 4\n",
      "   Key Points: 4\n",
      "üìù Question 2: Tell me about a time you had to deal with significant technical debt in a project. What steps did yo...\n",
      "   Answer: Yes\n",
      "   Hints: 4\n",
      "   Key Points: 4\n",
      "üìù Question 3: Describe a complex Django project you've worked on. What were some of the key architectural decision...\n",
      "   Answer: Yes\n",
      "   Hints: 4\n",
      "   Key Points: 4\n",
      "üìù Question 4: Explain your approach to writing efficient and maintainable Python code. What are some of the best p...\n",
      "   Answer: Yes\n",
      "   Hints: 4\n",
      "   Key Points: 4\n",
      "üìù Question 5: Imagine we are migrating a critical application to AWS. Describe your approach to designing a resili...\n",
      "   Answer: Yes\n",
      "   Hints: 5\n",
      "   Key Points: 4\n",
      "üìù Question 6: Our company is considering adopting a multi-cloud strategy, leveraging both AWS and GCP. How would y...\n",
      "   Answer: Yes\n",
      "   Hints: 4\n",
      "   Key Points: 4\n",
      "‚úÖ Successfully generated 6 questions with answers and hints\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üéØ GENERATED INTERVIEW QUESTIONS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Total Questions Generated:** 6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Question 1: Describe a time when you had to make a significant architectural decision that had a major impact on a project. What were the key considerations, and how did you ensure buy-in from the team?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Focus:** behavioral | **Skill Type:** matched_skill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target Skill:** Software Architecture"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Rationale:** This question assesses the candidate's ability to make strategic architectural decisions and influence others, which is crucial for a Senior Software Architect role."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üí° Model Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "S: We were building a new payment processing system and needed to decide on the overall architecture. T: My task was to choose an architecture that was scalable, secure, and maintainable. A: I researched several options, including a monolithic architecture and a microservices architecture. I presented the pros and cons of each to the team, highlighting the long-term benefits of microservices in terms of scalability and fault isolation. I also addressed concerns about the increased complexity by proposing a phased rollout and providing training on microservices best practices. R: We chose the microservices architecture, and the system has been successfully processing millions of transactions per day with minimal downtime. The phased rollout and training helped the team adapt quickly, and we avoided major integration issues."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üéØ Answer Hints:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Focus on the decision-making process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Explain how you considered different options."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Highlight your communication and persuasion skills."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Quantify the impact of your decision if possible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üîë Key Points to Cover:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Demonstrated strategic thinking."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Effective communication and collaboration."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Consideration of various architectural options."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Positive impact on the project."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Question 2: Tell me about a time you had to deal with significant technical debt in a project. What steps did you take to address it, and what were the results?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Focus:** behavioral | **Skill Type:** matched_skill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target Skill:** Technical Debt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Rationale:** This question assesses the candidate's experience in identifying and mitigating technical debt, a key responsibility for a Senior Software Architect."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üí° Model Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "S: Our legacy system had accumulated significant technical debt due to years of quick fixes and lack of proper documentation. T: My task was to lead an effort to reduce this debt and improve the system's maintainability. A: I started by conducting a thorough code review and identifying the areas with the most technical debt. I then prioritized the issues based on their impact on the system and the effort required to fix them. I worked with the team to refactor the code, improve documentation, and implement automated testing. We also established coding standards and code review processes to prevent future technical debt. R: As a result, we significantly reduced the number of bugs, improved the system's performance, and made it easier for new developers to onboard. We also saw a decrease in the time required to implement new features."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üéØ Answer Hints:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Describe the specific type of technical debt."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Explain your prioritization process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Highlight the steps you took to address the debt."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Quantify the positive outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üîë Key Points to Cover:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Identified and prioritized technical debt."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Implemented effective solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Improved system maintainability and performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Prevented future technical debt."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Question 3: Describe a complex Django project you've worked on. What were some of the key architectural decisions you made, and how did you leverage Django's features to solve specific challenges?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Focus:** technical_django | **Skill Type:** matched_skill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target Skill:** Django"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Rationale:** This question assesses the candidate's deep understanding of Django and their ability to use it effectively in complex projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üí° Model Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I worked on a large e-commerce platform using Django. One key decision was to use Django Rest Framework for building a robust API for mobile apps and third-party integrations. We leveraged Django's ORM for database interactions, optimizing queries using select_related and prefetch_related to minimize database hits. For handling asynchronous tasks like sending emails and processing orders, we integrated Celery with Redis as the broker. To manage user authentication and authorization, we used Django's built-in authentication system with custom permission classes to implement fine-grained access control. We also implemented caching strategies using Django's cache framework to improve performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üéØ Answer Hints:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Mention specific Django features you used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Explain the rationale behind your architectural decisions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Discuss performance optimization techniques."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Highlight any custom solutions you implemented."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üîë Key Points to Cover:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Use of Django Rest Framework."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. ORM optimization techniques."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Asynchronous task handling with Celery."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Custom authentication and authorization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Question 4: Explain your approach to writing efficient and maintainable Python code. What are some of the best practices you follow, and how do you ensure code quality?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Focus:** technical_python | **Skill Type:** matched_skill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target Skill:** Python"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Rationale:** This question assesses the candidate's proficiency in Python and their commitment to writing high-quality code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üí° Model Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I prioritize writing clean, readable, and well-documented Python code. I follow PEP 8 guidelines for code style and use linters like Flake8 and pylint to enforce consistency. I write unit tests using pytest to ensure that my code functions correctly and to prevent regressions. I use type hints to improve code clarity and catch potential errors early on. I also practice code review and pair programming to get feedback from other developers and improve code quality. I use virtual environments to manage dependencies and ensure reproducibility. I also use logging to track errors and debug issues."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üéØ Answer Hints:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Mention PEP 8 and other coding standards."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Discuss your testing strategy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Explain how you use linters and type hints."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Highlight the importance of code review."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üîë Key Points to Cover:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Adherence to coding standards."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Comprehensive testing strategy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Use of linters and type hints."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Emphasis on code review and collaboration."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Question 5: Imagine we are migrating a critical application to AWS. Describe your approach to designing a resilient and scalable architecture using AWS services. Consider factors like cost optimization, security, and disaster recovery."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Focus:** situational | **Skill Type:** missing_skill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target Skill:** Aws"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Rationale:** This question assesses the candidate's ability to design cloud solutions on AWS, a missing skill identified from the job description."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üí° Model Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "First, I'd analyze the application's requirements, including performance, scalability, and security needs. For resilience, I'd deploy the application across multiple Availability Zones using services like EC2 Auto Scaling and Elastic Load Balancing. For scalability, I'd use Auto Scaling to automatically adjust the number of EC2 instances based on demand. For cost optimization, I'd use Reserved Instances or Spot Instances for non-critical workloads and leverage AWS Cost Explorer to monitor spending. For security, I'd use IAM roles and policies to control access to AWS resources, configure security groups to restrict network traffic, and use AWS WAF to protect against web attacks. For disaster recovery, I'd implement a backup and recovery plan using services like S3 and Glacier, and consider using AWS CloudFormation to automate the deployment of infrastructure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üéØ Answer Hints:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Mention specific AWS services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Explain how you would address resilience and scalability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Discuss cost optimization strategies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Highlight security best practices."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5. Describe your approach to disaster recovery."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üîë Key Points to Cover:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Multi-AZ deployment with Auto Scaling and ELB."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Cost optimization using Reserved/Spot Instances."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. IAM roles, security groups, and AWS WAF for security."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Backup and recovery plan with S3 and Glacier."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùì Question 6: Our company is considering adopting a multi-cloud strategy, leveraging both AWS and GCP. How would you approach designing a system that can seamlessly operate across both platforms, and what are some of the challenges we might encounter?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Focus:** situational | **Skill Type:** missing_skill"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Target Skill:** Gcp"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Rationale:** This question assesses the candidate's ability to design cloud solutions on GCP and their understanding of multi-cloud architectures, a missing skill identified from the job description."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üí° Model Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To design a system that operates seamlessly across AWS and GCP, I'd focus on using platform-agnostic technologies and services where possible. For example, I'd use Kubernetes for container orchestration, as it's available on both platforms. I'd also use a service mesh like Istio to manage traffic and security between services. For data storage, I'd consider using a distributed database like Cassandra or CockroachDB that can be deployed across both clouds. For identity and access management, I'd use a centralized identity provider like Okta or Azure AD. Some challenges we might encounter include data synchronization between clouds, network latency, and the complexity of managing infrastructure across multiple platforms. We'd also need to consider the different pricing models and service offerings of each cloud provider."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üéØ Answer Hints:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Mention platform-agnostic technologies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Discuss the challenges of multi-cloud deployments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Explain how you would address data synchronization and network latency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Highlight the importance of centralized identity management."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üîë Key Points to Cover:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Kubernetes and Istio for container orchestration and service mesh."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Distributed database for data storage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Centralized identity provider for access management."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Addressing data synchronization and network latency challenges."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = run_complete_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2067825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ===========================================\n",
      "üéØ CV ANALYZER TEST - GEMINI 2.0 FLASH\n",
      "üéØ ===========================================\n",
      "\n",
      "üìù CV INPUT OPTIONS:\n",
      "1. üìã Paste CV text manually\n",
      "2. üìÅ Upload text file (.txt)\n",
      "3. üìÑ Upload PDF file (.pdf)\n",
      "\n",
      "üìã PASTE CV TEXT:\n",
      "   (Paste the CV content below, then press Enter twice to finish)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting CV analysis with Gemini 2.0 Flash...\n",
      "Sending request to Gemini 2.0 Flash via LangChain...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CV text received (2518 characters)\n",
      "üìñ CV Preview:\n",
      "Meriem Mojaat ¬ß MeriemMojaat | √Ø meriem-mojaat | # meriemmojaat216@gmail.com | H +216 58 412 360 Work Experience Software Development Intern ‚Äì Smart System, Tunisia Jun 2025 ‚Äì Aug 2025 ‚Ä¢ Developed web applications to automate document processes. ‚Ä¢ Implemented a Spring Boot backend and built frontend...\n",
      "\n",
      "\n",
      "‚è≥ Analyzing CV with Gemini 2.0 Flash...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini 2.0 Flash response received: 5549 characters\n",
      "Successfully got Gemini 2.0 Flash analysis via LangChain\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìä CV ANALYSIS RESULTS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Analysis Source:** gemini_2.0_flash_langchain"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model Used:** gemini-2.0-flash-exp"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**AI Generated:** Yes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üéØ Overall Score: 7/10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úÖ STRENGTHS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Strong project portfolio showcasing experience in AI, Machine Learning, and MLOps, demonstrated by projects like 'EmotionAI', 'Lung Nodule Detection', and 'MLOps and Model Deployment'."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. The CV demonstrates a clear progression of skills, from basic networking internships to more advanced AI/ML projects, highlighting continuous learning and development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. The inclusion of NVIDIA and Cisco certifications adds credibility to the candidate's technical skills in AI and Networking."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. The candidate's skills in both backend (Java, Spring Boot) and frontend (HTML, CSS) technologies, as well as DevOps tools (Docker, Jenkins, CI/CD), make them a well-rounded candidate."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚ùå AREAS FOR IMPROVEMENT"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. The descriptions in the 'Work Experience' section lack quantifiable achievements. For example, 'Developed web applications to automate document processes' needs more detail on the impact or scale of the automation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. The 'Projects' section, while impressive, lacks specific metrics about the deployment and real-world impact of the models. For example, for 'Customer Churn Prediction', it's unclear if the model was deployed and how it improved churn rates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. The 'Skills' section is a long list, making it difficult to quickly assess proficiency levels. There's no indication of the depth of knowledge in each skill."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. The dates for the projects are all listed as '2025' or '2024', which is confusing since some of the internships occurred earlier. This seems like a typo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üí° RECOMMENDATIONS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Quantify achievements in the 'Work Experience' section. For instance, change 'Developed web applications to automate document processes' to 'Developed web applications using Java and Spring Boot that automated document processes, reducing processing time by 30% and saving 10 man-hours per week'."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. Add metrics and impact to the 'Projects' section. For example, for 'Lung Nodule Detection', specify the dataset size, the evaluation metrics (e.g., F1-score, AUC), and whether it was tested on real-world data. Mention if the scientific article was published and where."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. Categorize the 'Skills' section into proficiency levels (e.g., Expert, Proficient, Familiar) or years of experience. For example, under Python, add '(3+ years experience)' or '(Expert)' to indicate a higher level of expertise."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. Correct the dates for the projects to accurately reflect when they were completed. Include the month and year if possible (e.g., January 2024 - March 2024)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5. For the MLOps project, specify which cloud platform (AWS, Azure, GCP) was used for deployment. Also, mention the specific tools used for monitoring (e.g., Prometheus, Grafana)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6. Elaborate on the 'Business Intelligence (BI)' skill. Mention specific tools used (e.g., Tableau, Power BI) and projects where BI skills were applied."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìù CONTENT ANALYSIS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Clarity:** The writing is generally clear but lacks detail and quantifiable results. The bullet points are concise but need to be more impactful."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Relevance:** The content is highly relevant to roles in Software Development, Machine Learning, and DevOps, given the mix of internships, projects, and skills."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Achievements:** Achievements are present but not highlighted effectively. They need to be quantified and contextualized to demonstrate impact."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Uniqueness:** The combination of AI/ML projects with networking experience and DevOps skills makes this CV stand out, showing a diverse skill set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üîß SKILL ANALYSIS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Technical Skills:** The technical skills are extensive, covering a wide range of technologies from programming languages (Python, Java) to ML frameworks (TensorFlow, PyTorch) and DevOps tools (Docker, Jenkins)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Soft Skills:** The soft skills listed are generic. Provide examples of how these skills were applied in projects or internships. For example, 'Teamwork: Collaborated with a team of 5 engineers on the EmotionAI project'."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Skill Gaps:** While the skills are broad, there's a lack of emphasis on cloud computing platforms (AWS, Azure, GCP) beyond deployment. Specifying experience with cloud services would be beneficial."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Skill Strengths:** The candidate's strength lies in their AI/ML skills, particularly their experience with deep learning frameworks and MLOps tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìê FORMATTING ANALYSIS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Readability:** The CV is generally readable, but the long list of skills could be better organized. Using bullet points effectively, but could be more concise within the descriptions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Structure:** The structure is standard and logical, with clear sections for work experience, projects, education, and skills."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Professionalism:** The CV is professionally presented, but improving the clarity and detail of the content would enhance its impact."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üîç KEY INSIGHTS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. The candidate has a strong foundation in AI/ML and is actively pursuing related projects, indicating a clear interest and specialization in this field."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. The combination of internships in different areas (Networking, Java Development, AI) suggests a broad exploration of career paths before focusing on AI/ML."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. The inclusion of MLOps skills is a valuable asset, indicating an understanding of the entire ML lifecycle, from model development to deployment and monitoring."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìã RAW ANALYSIS DATA"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <details>\n",
       "    <summary>Click to view raw JSON data</summary>\n",
       "    <pre style=\"background: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto;\">\n",
       "    {\n",
       "  \"overall_score\": \"7/10\",\n",
       "  \"strengths\": [\n",
       "    \"Strong project portfolio showcasing experience in AI, Machine Learning, and MLOps, demonstrated by projects like 'EmotionAI', 'Lung Nodule Detection', and 'MLOps and Model Deployment'.\",\n",
       "    \"The CV demonstrates a clear progression of skills, from basic networking internships to more advanced AI/ML projects, highlighting continuous learning and development.\",\n",
       "    \"The inclusion of NVIDIA and Cisco certifications adds credibility to the candidate's technical skills in AI and Networking.\",\n",
       "    \"The candidate's skills in both backend (Java, Spring Boot) and frontend (HTML, CSS) technologies, as well as DevOps tools (Docker, Jenkins, CI/CD), make them a well-rounded candidate.\"\n",
       "  ],\n",
       "  \"weaknesses\": [\n",
       "    \"The descriptions in the 'Work Experience' section lack quantifiable achievements. For example, 'Developed web applications to automate document processes' needs more detail on the impact or scale of the automation.\",\n",
       "    \"The 'Projects' section, while impressive, lacks specific metrics about the deployment and real-world impact of the models. For example, for 'Customer Churn Prediction', it's unclear if the model was deployed and how it improved churn rates.\",\n",
       "    \"The 'Skills' section is a long list, making it difficult to quickly assess proficiency levels. There's no indication of the depth of knowledge in each skill.\",\n",
       "    \"The dates for the projects are all listed as '2025' or '2024', which is confusing since some of the internships occurred earlier. This seems like a typo.\"\n",
       "  ],\n",
       "  \"recommendations\": [\n",
       "    \"Quantify achievements in the 'Work Experience' section. For instance, change 'Developed web applications to automate document processes' to 'Developed web applications using Java and Spring Boot that automated document processes, reducing processing time by 30% and saving 10 man-hours per week'.\",\n",
       "    \"Add metrics and impact to the 'Projects' section. For example, for 'Lung Nodule Detection', specify the dataset size, the evaluation metrics (e.g., F1-score, AUC), and whether it was tested on real-world data. Mention if the scientific article was published and where.\",\n",
       "    \"Categorize the 'Skills' section into proficiency levels (e.g., Expert, Proficient, Familiar) or years of experience. For example, under Python, add '(3+ years experience)' or '(Expert)' to indicate a higher level of expertise.\",\n",
       "    \"Correct the dates for the projects to accurately reflect when they were completed. Include the month and year if possible (e.g., January 2024 - March 2024).\",\n",
       "    \"For the MLOps project, specify which cloud platform (AWS, Azure, GCP) was used for deployment. Also, mention the specific tools used for monitoring (e.g., Prometheus, Grafana).\",\n",
       "    \"Elaborate on the 'Business Intelligence (BI)' skill. Mention specific tools used (e.g., Tableau, Power BI) and projects where BI skills were applied.\"\n",
       "  ],\n",
       "  \"content_analysis\": {\n",
       "    \"clarity\": \"The writing is generally clear but lacks detail and quantifiable results. The bullet points are concise but need to be more impactful.\",\n",
       "    \"relevance\": \"The content is highly relevant to roles in Software Development, Machine Learning, and DevOps, given the mix of internships, projects, and skills.\",\n",
       "    \"achievements\": \"Achievements are present but not highlighted effectively. They need to be quantified and contextualized to demonstrate impact.\",\n",
       "    \"uniqueness\": \"The combination of AI/ML projects with networking experience and DevOps skills makes this CV stand out, showing a diverse skill set.\"\n",
       "  },\n",
       "  \"skill_analysis\": {\n",
       "    \"technical_skills\": \"The technical skills are extensive, covering a wide range of technologies from programming languages (Python, Java) to ML frameworks (TensorFlow, PyTorch) and DevOps tools (Docker, Jenkins).\",\n",
       "    \"soft_skills\": \"The soft skills listed are generic. Provide examples of how these skills were applied in projects or internships. For example, 'Teamwork: Collaborated with a team of 5 engineers on the EmotionAI project'.\",\n",
       "    \"skill_gaps\": \"While the skills are broad, there's a lack of emphasis on cloud computing platforms (AWS, Azure, GCP) beyond deployment. Specifying experience with cloud services would be beneficial.\",\n",
       "    \"skill_strengths\": \"The candidate's strength lies in their AI/ML skills, particularly their experience with deep learning frameworks and MLOps tools.\"\n",
       "  },\n",
       "  \"formatting_analysis\": {\n",
       "    \"readability\": \"The CV is generally readable, but the long list of skills could be better organized. Using bullet points effectively, but could be more concise within the descriptions.\",\n",
       "    \"structure\": \"The structure is standard and logical, with clear sections for work experience, projects, education, and skills.\",\n",
       "    \"professionalism\": \"The CV is professionally presented, but improving the clarity and detail of the content would enhance its impact.\"\n",
       "  },\n",
       "  \"key_insights\": [\n",
       "    \"The candidate has a strong foundation in AI/ML and is actively pursuing related projects, indicating a clear interest and specialization in this field.\",\n",
       "    \"The combination of internships in different areas (Networking, Java Development, AI) suggests a broad exploration of career paths before focusing on AI/ML.\",\n",
       "    \"The inclusion of MLOps skills is a valuable asset, indicating an understanding of the entire ML lifecycle, from model development to deployment and monitoring.\"\n",
       "  ],\n",
       "  \"analysis_source\": \"gemini_2.0_flash_langchain\",\n",
       "  \"analysis_timestamp\": \"2025-10-27T10:23:35.882591\",\n",
       "  \"content_preview\": \"Meriem Mojaat \\u00a7 MeriemMojaat | \\u00ef meriem-mojaat | # meriemmojaat216@gmail.com | H +216 58 412 360 Work Experience Software Development Intern \\u2013 Smart System, Tunisia Jun 2025 \\u2013 Aug 2025 \\u2022 Developed web...\",\n",
       "  \"model_used\": \"gemini-2.0-flash-exp\",\n",
       "  \"ai_generated\": true\n",
       "}\n",
       "    </pre>\n",
       "    </details>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_results = test_cv_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457dd2c",
   "metadata": {},
   "source": [
    "## Part Overview\n",
    "\n",
    "This part implements a comprehensive **AI-powered CV analysis system** that combines multiple advanced techniques:\n",
    "\n",
    "- **RAG (Retrieval-Augmented Generation)** for semantic search and context-aware analysis  \n",
    "- **Fine-tuned Transformer Models** for precise job category classification  \n",
    "- **Large Language Models (LLMs)** for natural language understanding and generation  \n",
    "- **Vector Database** for efficient similarity search across CV documents  \n",
    "\n",
    "The system is designed for **HR professionals and recruiters** to quickly analyze large volumes of resumes and identify the best candidates for specific job requirements.\n",
    "## System Architecture Summary\n",
    "\n",
    "### Frameworks & Technologies Used:\n",
    "\n",
    "**Core AI Frameworks:**\n",
    "- **Sentence Transformers**: For embedding generation in RAG pipeline\n",
    "- **Hugging Face Transformers**: For fine-tuning BERT classification models\n",
    "- **FAISS**: For efficient vector similarity search\n",
    "- **PyTorch**: Deep learning backend\n",
    "- **Google Generative AI**: Gemini LLM integration\n",
    "\n",
    "**Supporting Infrastructure:**\n",
    "- **Flask**: REST API server\n",
    "- **n8n.cloud**: Workflow automation and webhooks\n",
    "- **ngrok**: Public API tunneling\n",
    "\n",
    "### Model Architectures:\n",
    "\n",
    "1. **RAG Embedding Model**: `all-MiniLM-L6-v2`\n",
    "   - Siamese network architecture\n",
    "   - 384-dimensional embeddings\n",
    "   - Cosine similarity for retrieval\n",
    "\n",
    "2. **Fine-tuned Classifier**: `bert-base-uncased`\n",
    "   - 12 transformer layers, 768 hidden size\n",
    "   - Custom classification head for 22 job categories\n",
    "   - Fine-tuned on CV dataset\n",
    "\n",
    "3. **LLM**: `gemini-2.0-flash-exp`\n",
    "   - 128K context window\n",
    "   - Advanced reasoning capabilities\n",
    "\n",
    "### Fine-Tuning Techniques:\n",
    "\n",
    "- **Stratified train/validation split** (80/20)\n",
    "- **Dynamic padding** and **gradient clipping**\n",
    "- **Linear learning rate warmup** with decay\n",
    "- **Multi-epoch training** with checkpointing\n",
    "- **Weighted F1-score** for imbalanced classes\n",
    "\n",
    "### RAG Implementation:\n",
    "\n",
    "**Retrieval Component:**\n",
    "- PDF text extraction and intelligent chunking\n",
    "- FAISS vector store with cosine similarity\n",
    "- Top-K semantic search with confidence scores\n",
    "\n",
    "**Augmentation Strategy:**\n",
    "- Multi-source context integration\n",
    "- Category predictions from fine-tuned model\n",
    "- Enhanced prompt engineering for HR context\n",
    "\n",
    "**Generation Pipeline:**\n",
    "- Structured prompts for recruitment analysis\n",
    "- Professional HR-focused response formatting\n",
    "- Actionable insights and recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2781c8b9",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Installation & Setup\n",
    "\n",
    "First, let's install all required dependencies and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a47c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\merie\\OneDrive\\Desktop\\new\\venvv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import google.generativeai as genai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import requests\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import threading\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd6427",
   "metadata": {},
   "source": [
    "## üìä Dataset Configuration\n",
    "\n",
    "Configure the dataset path and verify the structure. The system expects PDF files organized in category folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3b89fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration setup complete!\n",
      "Dataset path: C:\\Users\\merie\\Downloads\\dataset\\data\\data\n",
      "üìÅ Directories created: dataset/data, models, logs\n"
     ]
    }
   ],
   "source": [
    "# Configure Gemini API\n",
    "GEMINI_API_KEY = \"AIzaSyCtBiJPlRK7uEEg82jKoN0ELhhsfQoZLzk\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Define dataset path (update this to your actual path)\n",
    "dataset_path = r\"C:\\Users\\merie\\Downloads\\dataset\\data\\data\"\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "os.makedirs('./logs', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configuration setup complete!\")\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(\"üìÅ Directories created: dataset/data, models, logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfea22",
   "metadata": {},
   "source": [
    "# Core System Components\n",
    "\n",
    "## 1. CV Processor Class\n",
    "\n",
    "The `CVProcessor` class handles:\n",
    "- PDF text extraction and chunking\n",
    "- Embedding generation using Sentence Transformers\n",
    "- FAISS vector index creation for efficient similarity search\n",
    "- Semantic search across CV database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f9f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CV Processor class defined!\n"
     ]
    }
   ],
   "source": [
    "class CVProcessor:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the CV Processor with a sentence transformer model.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the SentenceTransformer model to use for embeddings\n",
    "        \"\"\"\n",
    "        # Initialize the sentence transformer model for generating embeddings\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        # FAISS index for efficient similarity search (will be created later)\n",
    "        self.index = None\n",
    "        # List to store all document chunks\n",
    "        self.documents = []\n",
    "        # List to store metadata for each document chunk\n",
    "        self.metadata = []\n",
    "        \n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract text content from PDF files using pdfplumber.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            str: Extracted text content from the PDF\n",
    "        \"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Open PDF file using pdfplumber\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                # Iterate through all pages in the PDF\n",
    "                for page in pdf.pages:\n",
    "                    # Extract text from current page\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        # Append page text with newline separator\n",
    "                        text += page_text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            # Handle any errors during PDF processing\n",
    "            print(f\"Error extracting text from {pdf_path}: {str(e)}\")\n",
    "        return text\n",
    "    \n",
    "    def chunk_text(self, text: str, chunk_size: int = 512, overlap: int = 50) -> List[str]:\n",
    "        \"\"\"\n",
    "        Split text into overlapping chunks for better processing.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to chunk\n",
    "            chunk_size (int): Number of words per chunk\n",
    "            overlap (int): Number of overlapping words between consecutive chunks\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of text chunks\n",
    "        \"\"\"\n",
    "        # Split text into individual words\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        # Create chunks with specified overlap\n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            # Join words to form a chunk\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            # Break if we've reached the end of the text\n",
    "            if i + chunk_size >= len(words):\n",
    "                break\n",
    "                \n",
    "        return chunks\n",
    "    \n",
    "    def process_dataset(self, dataset_path: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Process all PDF files in the dataset directory structure.\n",
    "        \n",
    "        Expected directory structure:\n",
    "        dataset_path/\n",
    "        ‚îú‚îÄ‚îÄ category1/\n",
    "        ‚îÇ   ‚îú‚îÄ‚îÄ file1.pdf\n",
    "        ‚îÇ   ‚îî‚îÄ‚îÄ file2.pdf\n",
    "        ‚îú‚îÄ‚îÄ category2/\n",
    "        ‚îÇ   ‚îî‚îÄ‚îÄ file3.pdf\n",
    "        \n",
    "        Args:\n",
    "            dataset_path (str): Path to the root dataset directory\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of all text chunks from all PDFs\n",
    "        \"\"\"\n",
    "        all_chunks = []\n",
    "        \n",
    "        # Iterate through each category directory\n",
    "        for category in os.listdir(dataset_path):\n",
    "            category_path = os.path.join(dataset_path, category)\n",
    "            \n",
    "            # Check if it's a directory (not a file)\n",
    "            if os.path.isdir(category_path):\n",
    "                # Process each PDF file in the category directory\n",
    "                for filename in os.listdir(category_path):\n",
    "                    if filename.lower().endswith('.pdf'):\n",
    "                        pdf_path = os.path.join(category_path, filename)\n",
    "                        print(f\"Processing: {pdf_path}\")\n",
    "                        \n",
    "                        # Extract text from PDF\n",
    "                        text = self.extract_text_from_pdf(pdf_path)\n",
    "                        \n",
    "                        # Only process if text was successfully extracted\n",
    "                        if text.strip():\n",
    "                            # Split text into chunks\n",
    "                            chunks = self.chunk_text(text)\n",
    "                            \n",
    "                            # Store chunks and their metadata\n",
    "                            for i, chunk in enumerate(chunks):\n",
    "                                all_chunks.append(chunk)\n",
    "                                self.metadata.append({\n",
    "                                    'category': category,      # CV category (e.g., 'engineering', 'marketing')\n",
    "                                    'filename': filename,      # Original PDF filename\n",
    "                                    'chunk_id': i,            # Chunk index within the document\n",
    "                                    'original_path': pdf_path # Full path to source PDF\n",
    "                                })\n",
    "        \n",
    "        # Store all chunks for later use\n",
    "        self.documents = all_chunks\n",
    "        return all_chunks\n",
    "    \n",
    "    def create_embeddings(self):\n",
    "        \"\"\"\n",
    "        Generate embeddings for all document chunks and create FAISS index.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If no documents have been processed\n",
    "            \n",
    "        Returns:\n",
    "            embeddings: Generated embeddings for all documents\n",
    "        \"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"No documents processed. Call process_dataset first.\")\n",
    "        \n",
    "        # Generate embeddings using the sentence transformer model\n",
    "        embeddings = self.model.encode(self.documents, show_progress_bar=True)\n",
    "        \n",
    "        # Initialize FAISS index for cosine similarity search\n",
    "        dimension = embeddings.shape[1]  # Get embedding dimension\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product index for cosine similarity\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity (L2 normalization)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        # Add embeddings to the FAISS index\n",
    "        self.index.add(embeddings.astype('float32'))\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def search_similar(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Search for documents similar to the query using semantic similarity.\n",
    "        \n",
    "        Args:\n",
    "            query (str): Search query string\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of dictionaries containing:\n",
    "                - document: The similar text chunk\n",
    "                - metadata: Associated metadata\n",
    "                - score: Similarity score (cosine similarity)\n",
    "                \n",
    "        Raises:\n",
    "            ValueError: If index hasn't been created\n",
    "        \"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not created. Call create_embeddings first.\")\n",
    "        \n",
    "        # Encode the query into embedding space\n",
    "        query_embedding = self.model.encode([query])\n",
    "        # Normalize query embedding for cosine similarity\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Search the FAISS index for similar documents\n",
    "        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
    "        \n",
    "        # Compile results with documents, metadata, and similarity scores\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            # Ensure index is within bounds\n",
    "            if idx < len(self.documents):\n",
    "                results.append({\n",
    "                    'document': self.documents[idx],  # The similar text chunk\n",
    "                    'metadata': self.metadata[idx],   # Associated metadata\n",
    "                    'score': float(score)             # Similarity score (0-1)\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ CV Processor class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e3bb6",
   "metadata": {},
   "source": [
    "## 2. Data Processing Pipeline\n",
    "\n",
    "Initialize the CV processor and process the dataset. This step:\n",
    "- Extracts text from all PDF files\n",
    "- Chunks text into manageable segments\n",
    "- Generates embeddings for semantic search\n",
    "- Builds FAISS index for fast retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b550500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Step 1: Processing CV Data...\n",
      "Loading existing CV processor...\n",
      "Loaded 5300 existing document chunks\n",
      "üìä Database stats: 5300 CV chunks ready for search\n"
     ]
    }
   ],
   "source": [
    "# Initialize and process CVs\n",
    "print(\"üìÇ Step 1: Processing CV Data...\")\n",
    "cv_processor = CVProcessor()\n",
    "\n",
    "# Check if processor already exists to avoid reprocessing\n",
    "if os.path.exists('cv_processor.pkl'):\n",
    "    print(\"Loading existing CV processor...\")\n",
    "    # Load pre-processed CV processor from pickle file\n",
    "    with open('cv_processor.pkl', 'rb') as f:\n",
    "        cv_processor = pickle.load(f)\n",
    "    print(f\"Loaded {len(cv_processor.documents)} existing document chunks\")\n",
    "else:\n",
    "    print(\"Processing dataset...\")\n",
    "    # Process all PDFs in the dataset directory and chunk the text\n",
    "    documents = cv_processor.process_dataset(dataset_path)\n",
    "    print(f\"‚úÖ Processed {len(documents)} document chunks\")\n",
    "\n",
    "    print(\"Creating embeddings...\")\n",
    "    # Generate embeddings for all document chunks and build FAISS index\n",
    "    embeddings = cv_processor.create_embeddings()\n",
    "    print(\"‚úÖ Embeddings created successfully!\")\n",
    "\n",
    "    # Save the processor to disk for future use (avoids reprocessing)\n",
    "    with open('cv_processor.pkl', 'wb') as f:\n",
    "        pickle.dump(cv_processor, f)\n",
    "    print(\"‚úÖ Processor saved successfully!\")\n",
    "\n",
    "# Display final statistics about the processed CV database\n",
    "print(f\"üìä Database stats: {len(cv_processor.documents)} CV chunks ready for search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e159356",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning Data Preparation\n",
    "\n",
    "The `FineTuningDataPreparer` class prepares training data for job category classification by:\n",
    "- Extracting text from CV PDFs\n",
    "- Creating labeled training samples\n",
    "- Generating category mappings for classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f9d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FineTuningDataPreparer class defined!\n"
     ]
    }
   ],
   "source": [
    "class FineTuningDataPreparer:\n",
    "    def __init__(self, dataset_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the FineTuningDataPreparer for creating training datasets from CVs.\n",
    "        \n",
    "        Args:\n",
    "            dataset_path (str): Path to the dataset directory containing categorized CVs\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract text content from PDF files for training data.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            str: Extracted text content from the PDF\n",
    "        \"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Open PDF file using pdfplumber\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                # Iterate through all pages and extract text\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            # Handle extraction errors\n",
    "            print(f\"Error extracting text from {pdf_path}: {str(e)}\")\n",
    "        return text\n",
    "    \n",
    "    def extract_training_samples(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract CV content and create structured training samples.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of training samples with text, category, and filename\n",
    "        \"\"\"\n",
    "        training_samples = []\n",
    "        \n",
    "        # Iterate through each category directory in the dataset\n",
    "        for category in os.listdir(self.dataset_path):\n",
    "            category_path = os.path.join(self.dataset_path, category)\n",
    "            \n",
    "            # Process only directories (not files)\n",
    "            if os.path.isdir(category_path):\n",
    "                # Process each PDF file in the category directory\n",
    "                for filename in os.listdir(category_path):\n",
    "                    if filename.lower().endswith('.pdf'):\n",
    "                        pdf_path = os.path.join(category_path, filename)\n",
    "                        print(f\"Processing for training: {pdf_path}\")\n",
    "                        \n",
    "                        # Extract text from PDF\n",
    "                        text = self.extract_text_from_pdf(pdf_path)\n",
    "                        \n",
    "                        # Only include samples with valid text content\n",
    "                        if text.strip():\n",
    "                            # Create training sample with truncated text (for efficiency)\n",
    "                            training_samples.append({\n",
    "                                'text': text[:2000],  # Use first 2000 characters to manage size\n",
    "                                'category': category,  # Job category (e.g., 'engineering', 'design')\n",
    "                                'filename': filename   # Original PDF filename\n",
    "                            })\n",
    "        \n",
    "        return training_samples\n",
    "    \n",
    "    def create_classification_dataset(self):\n",
    "        \"\"\"\n",
    "        Create a structured dataset for job category classification training.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (DataFrame, label_to_id mapping, id_to_label mapping) or (None, None, None) if no samples\n",
    "        \"\"\"\n",
    "        # Extract training samples from all PDFs\n",
    "        samples = self.extract_training_samples()\n",
    "        \n",
    "        # Check if any samples were found\n",
    "        if not samples:\n",
    "            print(\"No training samples found!\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Convert samples to pandas DataFrame for easier processing\n",
    "        df = pd.DataFrame(samples)\n",
    "        \n",
    "        # Create label mappings for classification\n",
    "        categories = df['category'].unique()\n",
    "        label_to_id = {category: idx for idx, category in enumerate(categories)}\n",
    "        id_to_label = {idx: category for category, idx in label_to_id.items()}\n",
    "        \n",
    "        # Add numerical labels to the DataFrame\n",
    "        df['label'] = df['category'].map(label_to_id)\n",
    "        \n",
    "        # Print dataset statistics\n",
    "        print(f\"‚úÖ Created dataset with {len(df)} samples across {len(categories)} categories\")\n",
    "        print(\"üìã Categories:\", list(categories))\n",
    "        \n",
    "        return df, label_to_id, id_to_label\n",
    "\n",
    "print(\"‚úÖ FineTuningDataPreparer class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ad87d",
   "metadata": {},
   "source": [
    "## 4. Training Data Generation\n",
    "\n",
    "Generate training dataset for fine-tuning the classification model. This creates:\n",
    "- Structured training samples with text and categories\n",
    "- Label mappings for 22 job categories\n",
    "- Balanced dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544414de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Step 2: Preparing Fine-Tuning Data...\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\10554236.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\10674770.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\11163645.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\11759079.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\12065211.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\12202337.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\12338274.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\12442909.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\12780508.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\12802330.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\13072019.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\13130984.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\13294301.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\13491889.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\13701259.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14055988.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14126433.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14224370.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14449423.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14470533.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14491649.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\14496667.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\15289348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\15363277.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\15592167.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\15821633.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\15906625.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\16237710.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\17306905.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\17407184.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\17556527.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\18132924.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\18365791.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\18569929.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\18635654.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\18669563.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\19446337.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\19545827.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\20082776.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\20253563.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\20345168.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\20393721.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\20624984.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\21031285.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\21338490.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\21763056.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\21794875.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\21853199.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\22465498.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\22925443.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23139819.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23246831.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23387174.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23416654.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23438112.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23513618.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23636277.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\23734441.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\24103168.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\24294778.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\24703009.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\24799301.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\24817041.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25067742.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25127518.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25462793.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25547145.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25749150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25846894.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25862026.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25867805.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\25935030.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\26065877.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\26975573.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\27558837.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\27573855.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\27637576.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\27980446.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\28298773.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\28359817.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\28614791.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\28939941.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\28969385.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\29050809.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\29456173.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\29821051.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\29999135.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\30304575.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\30361788.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\30813919.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\31602598.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\33527446.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\34198885.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\34816637.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\35554162.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\36024962.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\36425270.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\37370455.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\37997506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\38847011.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\39115899.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\39674178.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\42487883.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\43685045.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\49204385.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\49997097.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\50222417.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\53640713.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\59403481.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\62809577.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\63137898.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\75286906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\78257294.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\78403342.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\80053367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\82649935.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\87635012.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ACCOUNTANT\\98559931.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\10186968.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\10344379.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\10659182.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\10818478.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\11174187.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\11188218.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\11773767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\11963737.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\12171093.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\12544735.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13072354.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13115648.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13342150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13593241.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13809698.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13909762.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\13967854.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\14064815.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\14146106.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\14176254.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\14445309.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\14708590.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\15313140.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\15337481.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\15727656.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\15958967.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\16332348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\17021141.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\17165107.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\17254634.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\17847636.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\17911230.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\18090899.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\18725071.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\18997135.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\19063156.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\19108760.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\19234823.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\19518606.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\19926135.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20138606.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20272792.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20324037.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20400279.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20544228.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20604208.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\20765795.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\21614256.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\22042181.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\22259475.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\22391901.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\23427369.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\23577836.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\23804341.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24124250.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24410405.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24588864.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24695561.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24754689.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24763208.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\24946537.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\25873425.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\26071861.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\26456474.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\27182111.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\28111403.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\28206098.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\28635795.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\28871170.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\28974459.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\29173771.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\29177904.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\29415426.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\29926588.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\30741799.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\31040875.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\31242382.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\32965335.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\34327438.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\34970271.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\35344611.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\35474904.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\36392131.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\36694627.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\37333719.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\37348041.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\37560528.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\37640804.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\38059130.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\38291889.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\38698573.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\38860712.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\40088790.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\42164460.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\44115326.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\46772262.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\47133747.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\49475708.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\49486820.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\53169257.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\54067174.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\72652441.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\73448369.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\74126637.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\74191424.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\75057933.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\75435017.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\75950464.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\77439230.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\78538268.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\80503242.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\89508407.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\90468982.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\91051945.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\93512385.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\95714702.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\95970987.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ADVOCATE\\97405769.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\10953078.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\11197262.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\11676151.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\11813872.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\12341902.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\12674256.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\14140903.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\15053703.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\15546686.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\15603319.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\16172429.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\16507693.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\16653657.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\16661264.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\16849128.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\17312146.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\17499196.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\17640785.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\18242317.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\18264694.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\19532392.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\19851252.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\20006992.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\20969119.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\21134923.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\21868149.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\23631188.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\24001783.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\24068423.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\24397882.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\24416961.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\26070334.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\26835781.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\26921245.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\27689009.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\27888251.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\28165687.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\28247753.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\28733974.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\29142288.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\29510501.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\29746235.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\29897742.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\29968330.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\30437583.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\34141299.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\36102323.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\37201447.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\37292350.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\38216888.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\40882926.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\54246169.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\55500538.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\55712978.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\56068028.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\62994611.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\69336473.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\69360287.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\69859102.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\79536879.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\81042872.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\84512719.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AGRICULTURE\\89740812.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\10182582.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\10562768.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\10738095.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\10876132.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\11232471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\11409460.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\11677077.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\12059610.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\12122372.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\12668625.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\12669075.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\12860543.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\13386301.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\13418452.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\13764840.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\13807808.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\13858219.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\14304010.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\14413257.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\14698557.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\14937492.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\15154822.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\15479281.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\15535408.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\15746146.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\16391949.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\16500168.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\16605640.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\16723524.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\16915389.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\16985289.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\17659053.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\17714174.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\18509268.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\19070271.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\19402977.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\19714635.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\20504094.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\20905088.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\21007083.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\21570485.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\21807211.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\22249155.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\22852364.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\23190306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\23719943.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\24516163.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\24533931.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\24989856.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\25142074.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\25543217.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\26046878.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\26098594.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\26586477.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\26691587.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\26829561.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\27091280.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\27099856.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\27176039.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\27549075.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\27694040.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\28998957.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\29028935.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\29521434.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\29640922.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\29764492.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\30344127.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\30430249.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\31225895.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\31362807.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\31761591.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\33665485.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\35121930.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\35571205.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\35603950.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\35985133.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\36094883.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\36136569.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\37750854.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\41586420.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\43852883.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\46514339.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\50324968.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\52252936.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\54308684.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\56025640.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\56151548.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\58208591.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\70750649.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\71499299.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\71767359.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\72807293.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\78273826.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\83566455.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\91026230.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\91533580.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\APPAREL\\99806115.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\10830646.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\11187796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\11360471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\11555549.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\11995013.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\12334650.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\12386670.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\12413512.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\12777487.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\13272204.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\14150896.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\14248724.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\14879257.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\15265464.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\15306049.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\16244633.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\16887936.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\16962067.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\17033567.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\17325147.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\17694454.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\17857644.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\18029935.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\18106533.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\18319061.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\18586076.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\18885767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\19508520.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\19671909.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\19724031.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\20148147.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\20149476.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\20356750.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\20488267.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\20698469.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\21060367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\21809601.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\21867728.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\22182279.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\22593054.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\22800977.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\22848179.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\23139437.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\23752500.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\23917826.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\24061629.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\24349611.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\24983760.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\25157655.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\25561640.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\25923361.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\25926667.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\26069113.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\26079779.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\26410763.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\27024099.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\27096796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\27164756.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\27715131.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\27936502.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\28325193.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\28471099.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\28629430.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\28711616.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\29148871.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\30594821.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\31114531.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\31273413.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\32318506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\32794700.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\33344933.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\34146825.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\34304175.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\36019469.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\36379931.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\36758947.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\37220856.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\37472265.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\37751611.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\38115035.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\39064638.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\39470264.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\39608848.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\41950126.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\43622023.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\46055835.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\50432401.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\53227466.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\54100393.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\54180474.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\65325317.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\65352424.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\66226673.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\73030450.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\73497035.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\78107631.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\79432080.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\83206166.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\83338413.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\93576192.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\94230796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\99033098.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ARTS\\99561379.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\11152490.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\11257723.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\11797122.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\11887930.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\14455622.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\14508237.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\15100547.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\15210069.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\15484011.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\15790602.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\16332293.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\17510973.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\17571262.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\18448085.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\18932512.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\22452756.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\22732234.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\22946204.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\23009962.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\23522150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\24592627.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\24703983.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\25047127.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\26341645.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\28790806.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\32069695.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\32109048.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\47487091.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\51508889.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\63989974.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\78357954.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\82140102.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\84295343.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\91515108.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\97449528.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AUTOMOBILE\\99680385.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\10176815.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\10189110.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\10395944.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\10567764.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\10945968.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11137306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11169163.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11333001.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11614114.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11752500.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11804712.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\11959428.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\12043694.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\12144825.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\12192507.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\12239749.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\12504278.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\12904972.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\13195436.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\13234267.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\13405229.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\14589288.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\14790629.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\14874322.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\15618327.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\15684810.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\15823995.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\16279537.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\16449694.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\16833515.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\16850314.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17008356.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17152392.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17274759.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17483843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17655479.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17686472.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17694572.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17876954.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\17983430.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\18268860.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\19284293.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\19506295.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\19818707.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\20026169.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\21190805.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\21287405.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\22168194.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\22232367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\22442947.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\22650051.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\22990761.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\23464505.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\23761385.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\23985183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\24154692.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\24544244.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\24589765.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\24668861.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\24773845.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\25625173.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\25718772.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\25719936.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\26279402.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\26819872.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\26888302.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\27502951.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\27512470.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\27902692.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\28020046.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\28186635.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\28383893.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\29161565.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\29167286.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\29221006.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\29534737.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\29595906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\30148777.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\31536294.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\31605080.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\32720816.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\33627938.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\34419403.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\36252245.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\36727173.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\37473139.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\38047274.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\38154903.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\38355831.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\38663892.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\38989376.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\42427521.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\42546558.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\42641525.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\43408471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\43720116.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\49646155.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\50775901.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\54232810.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\58048626.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\61315605.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\65219288.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\67631413.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\68216398.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\69458502.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\70198580.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\77626587.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\81588968.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\82738323.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\87826037.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\90318913.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\91431878.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\92283635.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\94137171.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\96457008.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\98389424.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\AVIATION\\99416532.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\10329506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\10909673.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11065180.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11262933.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11266906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11637468.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11672279.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11773925.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\11842348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\12021752.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\13173522.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\13393401.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\13982572.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\14391434.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\14626780.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\15553584.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\15856762.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\16300459.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\16407619.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17131084.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17189156.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17213671.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17276884.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17396388.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17818707.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\17823436.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18172739.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18208580.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18278509.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18369400.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18457785.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18645964.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18805506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\18824120.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\19149865.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\19176318.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\19374660.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\19437318.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\19911786.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\19920687.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\20850529.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\20992320.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\21297521.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\21645690.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\21756639.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\21796843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\21856577.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\22615491.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\23323001.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\24580361.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\25080805.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\25162378.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\25200253.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\25624652.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\25780596.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\26579709.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\26673507.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\26987539.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\27120528.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\27606527.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\27884470.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\28051330.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\28419927.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\28895997.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\28989677.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\29093426.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\29406313.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\29552167.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\29839396.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\30127072.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\30713796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\31025785.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\31710562.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\32980197.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\33135102.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\33286293.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\33370664.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\33872500.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\34185495.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\34758680.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\34783330.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\34953092.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\3547447.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\35483925.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\35492909.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\35564026.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\36302399.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\36905896.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\38897568.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\39142536.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\39247950.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\39569771.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\41651672.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\43375498.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\45167858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\54421668.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\60182829.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\60489316.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\64589506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\65864767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\68781345.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\69243180.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\70667011.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\71422121.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\72876163.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\73157997.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\74552449.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\77156708.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\79041971.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\87867370.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\89049979.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\96493528.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\98348532.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\98965485.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BANKING\\99124477.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\11183737.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\13964744.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\15145575.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\15573418.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\16492045.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\18589927.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\19362586.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\23933031.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\24727739.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\26829350.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\27710853.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\30709029.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\31064969.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\38707449.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\41152404.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\45077654.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\57706851.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\63158213.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\69097572.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\79261033.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\89512321.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BPO\\95625660.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\10228751.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\10235211.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\10289113.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\10501991.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\10541358.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\10704573.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\11088337.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\11289482.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\11551946.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\12059198.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\12230301.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\12377803.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\12546838.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\12632728.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\12814706.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\13080868.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\13199813.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\13574264.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\13888506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14055971.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14070138.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14241621.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14287992.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14726000.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14752209.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14825300.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14861855.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14871762.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\14990354.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\15233524.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\15423153.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\15811992.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\16091352.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\16519708.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\16694152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\16846478.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\17095812.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\17115815.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\17421910.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\17597372.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\17602815.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\17730889.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\18236085.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\18293620.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\18311419.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\18757174.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\18937778.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\19557384.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\19738730.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\20317319.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\20357858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\20427934.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\20553895.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\20633855.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\20748929.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\22025574.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\22423839.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\22765255.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\23396633.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\23568641.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\24412546.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\24647386.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\24964303.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\25370801.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\25397102.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\25813953.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\26278597.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\26581830.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\26896699.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27004930.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27139412.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27213082.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27219200.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27375577.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27796199.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27850777.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\27937592.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\28337049.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\28916894.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\29014805.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\29208172.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\29825044.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\29908929.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\30938994.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\31273310.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\31638814.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\31813535.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\32042584.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\32385553.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\32531824.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\33424600.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\34046031.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\34797369.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\35673335.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\36170003.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\36574147.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\36805025.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\37391947.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\37521676.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\38007664.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\38688388.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\39237915.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\39875803.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\40792022.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\47067533.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\59696315.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\61677751.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\65708020.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\67501448.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\76916835.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\77576845.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\79759716.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\80275976.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\81310245.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\82118447.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\89197180.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\90629382.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\91467795.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\95382114.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\BUSINESS-DEVELOPMENT\\98379112.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\10001727.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\10276858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\10333299.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\10588874.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\10653119.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\10889157.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\11121498.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\11209758.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\11432686.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\11444536.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\12155206.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\12254068.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\12420359.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\12717345.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\13095891.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\13212436.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\13264154.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\13411858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\14569498.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\14663897.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\15180322.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\15261348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\15354126.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\16066857.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\16248476.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\16594812.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\16804396.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\16855929.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\16924102.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\18036030.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\18480859.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\18825446.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\19007667.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\19268120.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\19285236.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\19831366.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\19951766.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\20033302.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\20321582.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\20691949.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\20817322.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21101152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21334981.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21511817.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21611637.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21622444.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21869994.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\21904897.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\22349169.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\22561438.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23032276.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23185829.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23398733.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23568731.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23591247.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23807940.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\23841877.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\24221960.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\24673903.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\24709432.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\25128608.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\25452321.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\25924968.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\25953797.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\26189601.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\26718039.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\27298953.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\27662298.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\27820360.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\27831220.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\27909372.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\28092317.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\28176889.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\28230807.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\28396528.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\28424982.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29072179.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29211359.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29449419.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29772450.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29775391.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29784524.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\29990140.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\30128072.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\30311202.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\30337969.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\30826569.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\31547476.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\32518109.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\32605413.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\33964275.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\34252537.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\34452806.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\35157762.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\35468363.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\36366044.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\37231163.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\38309905.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\47317494.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\47603843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\47729453.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\48580330.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\51554903.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\53265899.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\57262959.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\61322296.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\62555739.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\65373280.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\68338341.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\74522938.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\81373857.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\86551046.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\91072502.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\91268638.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\91591026.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\92122785.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\92985983.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CHEF\\94047639.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10041713.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10100240.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10149490.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10176013.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10281555.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10734870.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\10820510.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\11393213.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\11650031.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12212468.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12491898.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12654876.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12666174.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12693146.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12695537.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12826414.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12839152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\12890045.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\13907230.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\14585273.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\14849103.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\14900898.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\15564893.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\15721849.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\16203589.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\16353584.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\16378091.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\16626724.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\16924279.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\17252448.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\17342969.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\17570634.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\18472240.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\18882984.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\19364677.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\19471144.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\19928941.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\20565849.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\20681037.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\21363048.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\21567392.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\21586858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\21782152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\22019500.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\22546476.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\22718826.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\22894544.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\22965804.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\22983516.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\23818675.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\24361598.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\24740005.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\24770846.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\24953126.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\25098739.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\25187733.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\25224998.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\25656981.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\26091595.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\26509539.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\27066370.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\27187994.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\27243670.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\27246366.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\27835351.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\28756444.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\28803888.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\28815362.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\28942221.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\28949406.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29061628.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29087505.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29193505.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29483501.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29574501.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29878348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\29894080.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\30311725.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\30397268.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\31850269.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\32025286.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\32265203.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\32773331.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\32799518.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\33023370.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\33141415.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\34544955.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\35971546.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\36331163.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\38946032.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\39027764.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\39566718.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\39674782.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\39908485.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\44147689.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\45475027.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\48549972.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\49685006.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\51638201.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\56525735.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\61065616.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\63083944.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\63145386.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\69764348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\71576860.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\78114950.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\78298706.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\88859947.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\90032884.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\93436805.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\94503308.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSTRUCTION\\99433371.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\10332998.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\10984392.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\11020140.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\11333660.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\11415967.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\11835339.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\12251115.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\12374933.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\12526702.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\12897903.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\12955994.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\13215696.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\13313917.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\13454871.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\13569152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\13586069.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\14346702.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\14517953.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\14593060.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15083600.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15119529.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15281412.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15433732.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15535920.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15602094.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\15699744.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\16964217.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\17025292.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\17307206.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\17983957.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\18079050.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\18227306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\18856440.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\19161572.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\19936735.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\20176584.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\20314980.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\20574232.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\21156767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\21366189.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\21512769.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\21568833.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\22259768.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\22351830.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\22485475.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\22556198.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\22571461.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\23302948.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\24643412.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\24828381.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\25213006.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\25258040.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\25694422.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\26167298.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\26234972.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\26291616.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\26919036.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\27096471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\27726066.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\27788376.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\28243590.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\28951817.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\29076405.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\29196643.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\29297393.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\29647215.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\29723311.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\29770086.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\30083884.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\30863060.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\31016926.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\31169070.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\31201660.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\31217840.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\31395742.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\32433431.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\32637306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\33919379.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\34875813.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\37818861.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\38165833.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\38399177.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\38457612.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\38896303.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\39308779.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\39441617.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\43311839.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\43378989.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\48533663.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\49777184.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\51432451.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\51724595.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\56792999.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\57364820.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\57601040.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\63670997.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\65062795.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\67406885.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\69181350.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\71888547.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\73075521.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\78016758.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\79570655.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\80527194.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\88691367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\88907739.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\91116867.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\91189201.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\92246939.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\93349646.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\93459677.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\95350373.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\95429627.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\95792386.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\CONSULTANT\\99714410.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\10466583.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\10748989.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\10751444.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\11155153.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\11722421.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\11807040.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\11919526.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\11958994.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\12415691.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\12547982.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\12674307.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\13014900.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\13518263.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\13557622.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\13774329.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\13998435.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\14014749.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\14528265.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\14724186.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\14743911.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\15425154.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\15471999.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\15936656.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\16288901.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\17199951.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\17555081.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\18198627.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\18460045.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\18795567.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\18835363.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\18979238.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\19164410.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\19195747.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\20390397.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\20748926.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\20932019.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\20986595.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\21283733.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\21705160.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\21916744.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\22496394.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\22506245.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\22567495.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\22675694.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\23951429.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\24285142.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\24455357.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\24583187.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\24655918.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\25023614.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\25061645.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\25422388.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\25949631.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26046064.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26496059.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26503829.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26622051.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26676567.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26790545.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26924514.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\26942552.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\27497542.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\27529455.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\28326441.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\28663949.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\29147100.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\29524570.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\29865476.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\30965258.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\30968749.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\32532982.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\32954522.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\34051710.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\34317538.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\34349255.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\34511655.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\34657584.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\35990852.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\36269672.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\37058472.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\37263609.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\37664296.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\37695494.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\38565119.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\38744475.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\39252859.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\39434376.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\39776400.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\41506705.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\42384185.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\44145704.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\44185767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\51018476.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\51681660.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\54201930.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\62312955.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\67582956.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\67645662.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\68240723.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\76010167.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\78149576.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\81011612.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\85101052.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\90066849.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\91153752.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\93301686.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DESIGNER\\94417768.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\10005171.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\10515955.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\11005406.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\11270462.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\11677012.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\12085736.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\13328680.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\13343786.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\13503650.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\13837784.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\14036515.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\14209965.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\14556869.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\14761906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\14771530.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\14945250.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\15226699.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\15353911.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\15484097.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\16276121.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\16509761.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\16536141.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\16893572.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\17132168.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\17432318.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\17562754.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\17584743.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18354623.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18442517.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18488289.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18501746.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18525641.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18900722.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18905648.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\18927233.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\19053815.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\19444529.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\19861776.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\20210676.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\20330739.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\20490741.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\20628003.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\21125113.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\22380187.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\22706174.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\23085604.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\23810469.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\23864858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\24574164.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\24658786.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\24679149.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\24953921.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\25038571.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\25525152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\25706337.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\25723793.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\26160200.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\26341987.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\27080812.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\27419236.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\27921561.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\27981289.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\28109594.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\28609364.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\28679359.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\29002596.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\29915354.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\30504149.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\30864828.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\30999638.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\31162167.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\31909493.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\31929166.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\33542483.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\33893326.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\34319869.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\34583750.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\37739183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\39166680.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\40311088.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\40883703.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\42156237.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\50219114.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\56952849.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\58915642.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\59011090.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\62700506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\70196518.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\73282756.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\80679862.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\81508860.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\82929064.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\90685127.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\91318828.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\91539554.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\DIGITAL-MEDIA\\94492380.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\10030015.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\10219099.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\10624813.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\10712803.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\10985403.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\11890896.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\11981094.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\12011623.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\12022566.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\12472574.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\12488356.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\12518008.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\12748557.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\13149176.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\13264796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\14049846.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\14206561.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\14554542.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\15139979.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\15601399.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\15858254.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\15941675.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\16803215.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\16911115.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\17043822.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\17103000.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\17108676.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\17488801.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\17926546.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\18753367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\19124258.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\19396040.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\19397727.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\19553067.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\19612167.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\20566550.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\20882041.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\20981299.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\21038022.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\21298336.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\21629057.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\21807224.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\21847415.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\22605864.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\22890839.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\23234047.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\23438227.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\23497307.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\24322804.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\24647794.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\25425322.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\25608963.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\25797445.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\25919149.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\25930778.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\26456899.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\26834746.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\27040860.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\27152464.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\27756469.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28005884.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28078163.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28320387.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28505854.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28628090.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28630325.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28631840.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28762662.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28831378.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\28923650.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\30097175.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\30288581.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\30542184.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\31677347.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\31684925.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\31694970.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\32081266.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\32802563.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\32985311.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\33685075.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\35172961.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\35389360.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\35651876.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\35737840.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\36149549.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\36517781.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\37335325.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\38220146.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\38314236.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\38535335.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\39835894.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\39855211.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\43752620.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\44624796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\47276718.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\47549345.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\47919212.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\49127329.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\50328713.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\51588273.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\54227873.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\55595908.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\55953734.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\56691064.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\60004873.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\61579998.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\62071407.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\64468610.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\64755882.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\74236636.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\77828437.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\81125166.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\82125182.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\82246962.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\86209934.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\86828820.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\90280583.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\ENGINEERING\\96029688.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\10549585.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\11441764.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\11490673.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\11877150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\12071138.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\12858898.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\14106638.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\14181049.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\14408510.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\14413148.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\14722634.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\15011085.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\15224503.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\15717923.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\15792052.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\15891494.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\16426777.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\16449850.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\17392859.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\17775916.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\17880988.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\18024825.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\18072085.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\18636651.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\18640927.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\18975686.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\19147603.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\19243556.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\19405513.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\19540089.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20275356.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20705888.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20836112.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20880935.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20918464.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20969845.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\20977412.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\21912637.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\22492537.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\22622351.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\22720697.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\23354541.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\23573064.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\23955183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24411323.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24530382.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24553863.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24611721.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24670867.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24833063.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24854026.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\24967652.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\25101183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\25330083.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\25497147.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\25678238.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\26013403.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\26231609.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\26530575.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\26750846.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\26767199.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\26961846.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\27018361.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\27330027.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\27409087.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\27789372.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\27914096.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28396458.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28398216.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28522529.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28623782.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28724469.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28758002.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\28973180.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\29494962.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\29612672.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\29648950.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\29998869.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\31948488.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\33685988.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\34250007.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\37931076.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\38225199.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\38441665.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\38907798.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\39295103.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\39675895.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\47410104.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\48285304.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\57088974.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\58165257.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\59450123.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\59777056.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\59818742.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\59938965.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\61634281.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\62850928.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\66741193.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\69487178.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\70541112.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\72136463.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\74512244.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\74849878.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\76454959.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\77638654.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\78229715.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\81217013.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\81677620.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\84356308.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\84373843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\86549455.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\86595128.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\88038965.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\91564103.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\92524964.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\93653247.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\95519832.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FINANCE\\98513424.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10235429.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10268614.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10333051.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10428916.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10568350.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10816645.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\10969918.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\11130200.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\11332602.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\11522068.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\12019284.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\12092347.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\12695799.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\12791244.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\12923795.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\12938389.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\13037145.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\13367322.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\13675377.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\14107571.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\14515954.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\15293959.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\15932017.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\16038911.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\16474898.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\16605352.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17163375.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17166018.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17286050.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17431847.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17576030.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17658471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17660419.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\17915015.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\18767449.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\19037403.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\19599699.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\19774173.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\19938081.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\19975121.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\20255404.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\20279756.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\20457611.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\20565486.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\21122155.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\21178545.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\21238396.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\22093368.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\22488036.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\22855060.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\23004695.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\23011221.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\23063986.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\23477199.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24219583.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24251588.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24444525.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24708621.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24767027.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24905947.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\24994145.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\25482567.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\25507648.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\25838512.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\26459032.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\27084878.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\27397245.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\27903191.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\27974588.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\28172023.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\28321954.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\28669770.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\29165698.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\29306433.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\29319314.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\29425788.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\29573698.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\29792535.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\30757456.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\30990885.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\31042953.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\31556198.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\32517106.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\32636041.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\32651555.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\34151183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\34792238.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\35164503.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\35302620.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\36139251.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\37087824.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\38108845.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\38642923.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\38650096.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\39805617.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\45656814.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\52684666.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\54259150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\55746506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\56286525.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\57575888.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\59487170.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\62870550.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\63282405.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\67032711.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\69666645.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\70603826.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\75156649.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\76530505.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\77266989.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\80000092.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\89858892.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\90365216.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\95085510.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\95769832.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\96761538.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\FITNESS\\97123005.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\10062724.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\10076271.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\10251432.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\10466208.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\10480456.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\10568183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\11378657.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\11605833.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\11653906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\11704150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\12315079.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\12333703.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\12613221.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\12938200.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\13352113.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\13565152.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\13575312.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\14062078.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\14667957.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\15499825.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\15636923.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\15680735.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\16121387.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\16132195.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\16356151.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\16702198.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\17539842.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\17545780.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\17624934.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\17864043.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\17960690.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\17963031.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\18129173.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\18365443.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\18484846.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\18714571.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\18784594.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\18949843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\19090468.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\20110597.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\20172393.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\20211577.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\20736486.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\20748468.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\20835760.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\21866029.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\22008817.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\23110214.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\23138078.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\23617240.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\23814777.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\23918545.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\23944036.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\24025053.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\24548333.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\24550866.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\25328428.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\25451319.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\25834360.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\25974844.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\26125407.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\26585242.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\26695839.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\26908066.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\26958533.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\27030979.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\27090089.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\27917969.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\28423028.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\28670024.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\28745844.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\29134372.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\29992154.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\31395710.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\31926950.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\32219038.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\32563518.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\33750209.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\33803142.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\34594746.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\34962725.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\35422305.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\35579812.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\36625776.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\36861863.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\36868767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\37001381.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\37374340.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\39082090.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\41910253.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\43994605.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\45907524.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\46349752.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\47996197.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\49325370.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\51777546.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\54934269.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\56520872.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\58879993.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\60624892.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\64471954.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\69199666.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\75297735.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\75744306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\80876647.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\85417107.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\85421438.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\87520378.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\91478356.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\93988900.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\95011061.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\96260484.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\97169343.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\98300955.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HEALTHCARE\\98309114.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\10399912.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\10694288.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\11480899.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\11592605.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\11698189.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\11763983.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\11847784.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\12786012.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\13376919.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\13520837.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\13879043.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\14225422.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\14256329.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\14640322.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\14886205.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\15041689.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\15375009.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\15575117.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\15576950.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\16852973.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\16861758.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\16877897.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\17150707.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\17412079.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\17422560.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\17812897.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\17855844.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18084150.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18155310.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18297650.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18316239.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18334783.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18422164.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18557164.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18731098.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\18827609.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\19179079.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\19336728.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\19616406.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\19717385.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\19867922.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\20417897.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\20806155.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\20925036.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\20993320.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\21265194.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\21830565.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\22323967.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\23155093.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\23408537.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\23510685.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\23914451.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\24184357.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\24402267.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\24508725.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\25150191.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\25676643.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\25724495.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\25824789.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\26048718.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\26202430.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\26289308.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\26671167.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\26780935.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\27018550.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\27165830.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\27490876.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\27496514.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\27523575.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\27847081.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\28175164.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\28419173.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\28640735.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\28808263.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\28828844.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\29091445.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\29149998.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\29297973.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\29564653.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\30163002.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\30563572.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\30646367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\30862904.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\32308556.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\32896934.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\32947778.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\32977530.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\33176873.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\34554248.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\34740556.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\39081840.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\39650734.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\39970711.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\41523474.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\44476983.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\46258701.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\47470864.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\49937469.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\51769822.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\52979663.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\57667857.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\59962788.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\72231872.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\73077810.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\80162314.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\86184722.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\87968870.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\91930382.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\93002334.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\HR\\93112113.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10089434.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10247517.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10265057.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10553553.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10641230.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10839851.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\10840430.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\11580408.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\11584809.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\11957080.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\12045067.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\12334140.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\12635195.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\12763627.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\13385306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\13405733.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\13477922.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\13836471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\14789139.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\15118506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\15297298.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\15651486.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\15791766.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\15802627.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\16186411.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\16533554.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\16899268.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\17111768.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\17641670.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\17681064.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\17688766.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\17987433.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\18067556.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\18159866.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\18176523.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\18187364.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\18301617.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\18752129.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\19201175.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\19796840.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\19850482.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20001721.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20024870.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20237244.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20408458.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20674668.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20824105.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\20879311.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\21283365.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\21780877.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\22450718.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\22776912.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\23527321.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\23666211.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\23864648.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\24020470.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\24038620.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\24083609.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\24230851.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\24889109.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\24913648.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\25207620.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\25857360.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\25905275.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\25959103.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\25990239.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\26480367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\26746496.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\26768723.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\26801767.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\27058381.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\27295996.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\27372171.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\27485716.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\27536013.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\27770859.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\28035460.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\28126340.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\28672970.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\28697203.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\28897981.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\29051656.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\29075857.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\29975124.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\30223363.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\31111279.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\31243710.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\32959732.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\33241454.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\33381211.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\35325329.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\36434348.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\36856210.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\37242217.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\37764298.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\38753827.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\39413067.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\39718499.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\40018190.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\41344156.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\46260230.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\48037995.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\51363762.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\51639418.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\52246737.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\52618188.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\57002858.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\64017585.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\66832845.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\68460556.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\70089206.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\79541391.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\81761658.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\83816738.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\89413122.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\90867631.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\91121135.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\91635250.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\91697974.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\INFORMATION-TECHNOLOGY\\92069209.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\10070224.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\10554045.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\10873344.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\10926726.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\11160414.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\11624880.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\11635137.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\11842274.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\11850315.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\11902276.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\12191094.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\12237267.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\12545844.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\12567516.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\12920612.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\13129275.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\13727873.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\13915715.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14009087.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14128006.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14278888.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14364597.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14536764.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14611516.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14667659.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14910300.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\14966165.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\15917885.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\16103783.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\16226743.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\16620172.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\18133495.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\18436190.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\19072267.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\19497420.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\19503224.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\19558834.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\19929506.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\20470943.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\20966771.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21297828.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21321598.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21386255.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21478007.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21549195.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21663616.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\21669215.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\22455205.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\22560013.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\22754014.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\22861181.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23015611.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23048999.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23143731.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23602130.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23631724.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23673025.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\23771896.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\24491862.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\24559558.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\24590489.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\24677466.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\24710433.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\24977396.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\25001005.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\25070914.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\25413261.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\26127853.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\26130673.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\26173524.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\26330995.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\27000192.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\27257013.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\28290448.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\28531493.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\28831442.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\28862054.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\28975482.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\29329075.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\29525715.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\30642458.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\31211074.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\31220062.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\31292364.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\31392754.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\32441790.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\33072201.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\34712719.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\36107065.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\36671891.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\37087371.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\37375999.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\37913536.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\38056161.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\41590605.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\42332765.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\45462344.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\45900271.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\49119887.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\51415089.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\53701275.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\59346975.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\61319162.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\65237556.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\75329822.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\85766635.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\85973397.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\88651471.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\91197243.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\93828034.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\PUBLIC-RELATIONS\\98086373.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\10138632.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\10464113.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\10603337.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\10724818.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\10898339.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\12082377.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\12351749.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\12696104.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\12820557.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\13178604.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\13348915.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\13637605.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\13812481.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\14267489.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\14358578.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\14381464.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\15273850.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\15581242.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\15620421.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\15765660.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\15918496.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\15973307.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\16121015.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\16223371.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\16280971.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\16511249.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\17378327.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\17410700.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\17509935.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\17704246.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\17781039.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\18062906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\18171955.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\18328743.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\18368613.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\18885231.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\19147494.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\19147947.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\19156751.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\19473948.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\19582792.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\20141807.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\20423658.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\20552814.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\20819838.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\21595057.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\22047665.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\22319662.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\23032182.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\23296286.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\23760084.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\23782450.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\23929500.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\24610685.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\25315791.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\25810233.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\25839123.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\26425074.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\26530696.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\26932091.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\26994282.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\27233183.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\27607632.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\27624540.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\28139742.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\28198029.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\28377361.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\28867567.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29134721.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29184740.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29211919.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29332616.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29399491.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29805310.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29815762.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\29928796.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\30083943.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\30529547.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\30608780.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\31199035.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\31454430.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\32140087.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\33236701.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\33578873.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\34131484.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\34303500.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\36074301.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\36621169.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\36904300.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\36970996.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\37360517.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\37540732.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\37735467.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\37792474.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\38087844.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\39581020.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\40987524.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\42304307.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\51349448.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\54101961.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\55097118.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\55104715.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\55477468.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\58428843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\59422148.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\65456466.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\69155584.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\70528646.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\71772815.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\79376680.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\85918100.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\87118391.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\90682785.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\92200491.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\98108571.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\SALES\\98509238.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\10504237.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\10527994.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\10909720.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\11336022.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\11616482.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\11943065.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\12467531.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\12587973.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\13087952.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\13296856.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\13330982.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\13583538.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\13855004.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\14958913.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\15850434.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\15899269.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\16210888.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\16270906.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\16820422.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\17311685.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\17481570.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\18001081.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\19302310.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\19464810.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\19556300.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\19786924.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\19918523.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\20230207.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\20399718.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\20478831.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\20626794.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\21531811.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\21550454.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\21611212.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\21773106.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22056333.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22408666.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22510753.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22551979.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22632070.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22807104.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22884757.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\22968380.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\23398843.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\23628651.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\23939133.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\24240349.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\24791126.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\25588694.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\25729119.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\27126818.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\27524018.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\27531694.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\27798860.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\28013287.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\28063132.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\28086303.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\28642819.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\28772892.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\28933005.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\29267293.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\29486525.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\29639533.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\29797594.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\29930479.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\31552617.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\32067700.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\33704389.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\34033933.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\34465087.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\34689720.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\34745915.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\35421497.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\36206485.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\36569713.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\37402097.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\37660306.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\38750659.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\45286020.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\45987048.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\48547319.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\49285644.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\51209395.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\53129155.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\58105060.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\58665241.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\58708773.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\62184086.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\63391085.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\66683238.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\66906212.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\69005326.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\69532425.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\70892619.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\74816727.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\76196367.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\79663360.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\86322251.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\86597425.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\90363254.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\96547039.pdf\n",
      "Processing for training: C:\\Users\\merie\\Downloads\\dataset\\data\\data\\TEACHER\\99244405.pdf\n",
      "‚úÖ Created dataset with 2483 samples across 24 categories\n",
      "üìã Categories: ['ACCOUNTANT', 'ADVOCATE', 'AGRICULTURE', 'APPAREL', 'ARTS', 'AUTOMOBILE', 'AVIATION', 'BANKING', 'BPO', 'BUSINESS-DEVELOPMENT', 'CHEF', 'CONSTRUCTION', 'CONSULTANT', 'DESIGNER', 'DIGITAL-MEDIA', 'ENGINEERING', 'FINANCE', 'FITNESS', 'HEALTHCARE', 'HR', 'INFORMATION-TECHNOLOGY', 'PUBLIC-RELATIONS', 'SALES', 'TEACHER']\n",
      "‚úÖ Label mapping saved!\n",
      "üìä Training data overview:\n",
      "   - Total samples: 2483\n",
      "   - Categories: 24\n",
      "   - Sample categories: ['ACCOUNTANT', 'ADVOCATE', 'AGRICULTURE', 'APPAREL', 'ARTS']...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Preparing Fine-Tuning Data for Model Training\n",
    "print(\"üéØ Step 2: Preparing Fine-Tuning Data...\")\n",
    "\n",
    "# Initialize the data preparer with the dataset path\n",
    "ft_preparer = FineTuningDataPreparer(dataset_path)\n",
    "\n",
    "# Create classification dataset from the CV PDFs\n",
    "# Returns:\n",
    "# - training_df: DataFrame with text samples and labels\n",
    "# - label_mapping: Dictionary mapping category names to numerical IDs\n",
    "# - id_to_label: Reverse mapping from numerical IDs back to category names\n",
    "training_df, label_mapping, id_to_label = ft_preparer.create_classification_dataset()\n",
    "\n",
    "# Check if training data was successfully created\n",
    "if training_df is not None:\n",
    "    # Save the label mapping to JSON file for future use during inference\n",
    "    with open('label_mapping.json', 'w') as f:\n",
    "        json.dump(label_mapping, f)\n",
    "    print(\"‚úÖ Label mapping saved!\")\n",
    "    \n",
    "    # Display training dataset statistics and overview\n",
    "    print(f\"üìä Training data overview:\")\n",
    "    print(f\"   - Total samples: {len(training_df)}\")  # Number of CV samples processed\n",
    "    print(f\"   - Categories: {len(label_mapping)}\")   # Number of unique job categories\n",
    "    print(f\"   - Sample categories: {list(label_mapping.keys())[:5]}...\")  # Show first 5 categories as examples\n",
    "    \n",
    "else:\n",
    "    # Handle case where no training data could be extracted\n",
    "    print(\"‚ùå No training data available - check your dataset path\")\n",
    "    training_df = None  # Explicitly set to None for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42e38f",
   "metadata": {},
   "source": [
    "## 5. Classification Model Trainer\n",
    "\n",
    "The `CVClassifierTrainer` class implements:\n",
    "- BERT-based sequence classification\n",
    "- Custom training loop with evaluation\n",
    "- Model fine-tuning for job categorization\n",
    "- Performance metrics tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CVClassifierTrainer class defined!\n"
     ]
    }
   ],
   "source": [
    "class CVClassifierTrainer:\n",
    "    def __init__(self, model_name: str = \"bert-base-uncased\", num_labels: int = 22):\n",
    "        \"\"\"\n",
    "        Initialize the CV Classifier Trainer for fine-tuning transformer models.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Hugging Face model name/path to use as base model\n",
    "            num_labels (int): Number of classification categories (job types)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        # Load the tokenizer for the specified model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # Load the base model and adapt it for sequence classification\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, \n",
    "            num_labels=num_labels  # Set number of output classes\n",
    "        )\n",
    "    \n",
    "    def prepare_dataset(self, df: pd.DataFrame, text_column: str = 'text', label_column: str = 'label'):\n",
    "        \"\"\"\n",
    "        Prepare and tokenize the dataset for training.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing text and label columns\n",
    "            text_column (str): Name of the column containing CV text\n",
    "            label_column (str): Name of the column containing numerical labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Tokenized training and evaluation datasets\n",
    "        \"\"\"\n",
    "        # Split data into training (80%) and evaluation (20%) sets\n",
    "        train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Convert pandas DataFrames to Hugging Face datasets\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        eval_dataset = Dataset.from_pandas(eval_df)\n",
    "        \n",
    "        def tokenize_function(examples):\n",
    "            \"\"\"\n",
    "            Tokenize text examples for model input.\n",
    "            \n",
    "            Args:\n",
    "                examples: Batch of examples from the dataset\n",
    "                \n",
    "            Returns:\n",
    "                dict: Tokenized inputs with attention masks\n",
    "            \"\"\"\n",
    "            return self.tokenizer(\n",
    "                examples[text_column], \n",
    "                padding=\"max_length\",      # Pad sequences to max length\n",
    "                truncation=True,           # Truncate sequences longer than max_length\n",
    "                max_length=512             # BERT's maximum sequence length\n",
    "            )\n",
    "        \n",
    "        # Apply tokenization to both datasets in batches for efficiency\n",
    "        tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "        tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "        \n",
    "        return tokenized_train, tokenized_eval\n",
    "    \n",
    "    def compute_metrics(self, eval_pred):\n",
    "        \"\"\"\n",
    "        Compute evaluation metrics during training.\n",
    "        \n",
    "        Args:\n",
    "            eval_pred: Tuple containing predictions and true labels\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary with accuracy and F1 score\n",
    "        \"\"\"\n",
    "        predictions, labels = eval_pred\n",
    "        # Convert logits to class predictions (argmax)\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy_score(labels, predictions),\n",
    "            'f1': f1_score(labels, predictions, average='weighted')  # Weighted F1 for imbalanced classes\n",
    "        }\n",
    "    \n",
    "    def train(self, train_dataset, eval_dataset, output_dir: str = \"./cv_classifier\"):\n",
    "        \"\"\"\n",
    "        Train the classification model.\n",
    "        \n",
    "        Args:\n",
    "            train_dataset: Tokenized training dataset\n",
    "            eval_dataset: Tokenized evaluation dataset\n",
    "            output_dir (str): Directory to save the trained model\n",
    "            \n",
    "        Returns:\n",
    "            Trainer: Hugging Face trainer object\n",
    "        \"\"\"\n",
    "        # Define training arguments and hyperparameters\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,          # Output directory for model checkpoints\n",
    "            num_train_epochs=3,             # Number of training epochs\n",
    "            per_device_train_batch_size=8,  # Batch size per device during training\n",
    "            per_device_eval_batch_size=8,   # Batch size for evaluation\n",
    "            warmup_steps=500,               # Number of warmup steps for learning rate\n",
    "            weight_decay=0.01,              # Strength of weight decay\n",
    "            logging_dir='./logs',           # Directory for storing logs\n",
    "            logging_steps=10,               # Log every X steps\n",
    "            evaluation_strategy=\"epoch\",    # Evaluate after each epoch\n",
    "            save_strategy=\"epoch\",          # Save checkpoint after each epoch\n",
    "            load_best_model_at_end=True,    # Load the best model at the end of training\n",
    "        )\n",
    "        \n",
    "        # Initialize the trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            compute_metrics=self.compute_metrics,  # Custom metrics function\n",
    "        )\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        # Start the training process\n",
    "        trainer.train()\n",
    "        \n",
    "        # Save the final model and tokenizer\n",
    "        trainer.save_model()\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "        \n",
    "        return trainer\n",
    "\n",
    "print(\"‚úÖ CVClassifierTrainer class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f2048",
   "metadata": {},
   "source": [
    "## 6. Model Training Execution\n",
    "\n",
    "Train the fine-tuned classifier with:\n",
    "- Custom training loop for better control\n",
    "- Real-time metrics monitoring\n",
    "- Validation set evaluation\n",
    "- Model checkpointing and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Step 3: Training Fine-Tuned Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1986/1986 [00:01<00:00, 1625.47 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 497/497 [00:00<00:00, 1519.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting custom training loop...\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 0/249, Loss: 3.2692\n",
      "Epoch 1, Batch 10/249, Loss: 3.1067\n",
      "Epoch 1, Batch 20/249, Loss: 3.2631\n",
      "Epoch 1, Batch 30/249, Loss: 3.0434\n",
      "Epoch 1, Batch 40/249, Loss: 3.2701\n",
      "Epoch 1, Batch 50/249, Loss: 3.2211\n",
      "Epoch 1, Batch 60/249, Loss: 3.1530\n",
      "Epoch 1, Batch 70/249, Loss: 3.1973\n",
      "Epoch 1, Batch 80/249, Loss: 3.1603\n",
      "Epoch 1, Batch 90/249, Loss: 3.0785\n",
      "Epoch 1, Batch 100/249, Loss: 3.0789\n",
      "Epoch 1, Batch 110/249, Loss: 3.0385\n",
      "Epoch 1, Batch 120/249, Loss: 3.1629\n",
      "Epoch 1, Batch 130/249, Loss: 3.0685\n",
      "Epoch 1, Batch 140/249, Loss: 3.2311\n",
      "Epoch 1, Batch 150/249, Loss: 3.2260\n",
      "Epoch 1, Batch 160/249, Loss: 3.1675\n",
      "Epoch 1, Batch 170/249, Loss: 2.9358\n",
      "Epoch 1, Batch 180/249, Loss: 2.6773\n",
      "Epoch 1, Batch 190/249, Loss: 2.5379\n",
      "Epoch 1, Batch 200/249, Loss: 2.4632\n",
      "Epoch 1, Batch 210/249, Loss: 2.6021\n",
      "Epoch 1, Batch 220/249, Loss: 2.3858\n",
      "Epoch 1, Batch 230/249, Loss: 2.0739\n",
      "Epoch 1, Batch 240/249, Loss: 2.3614\n",
      "‚úÖ Epoch 1 completed:\n",
      "   - Average Loss: 2.9277\n",
      "   - Training Accuracy: 0.2080\n",
      "   - Training F1: 0.2022\n",
      "   - Validation Accuracy: 0.6660\n",
      "   - Validation F1: 0.6145\n",
      "Epoch 2, Batch 0/249, Loss: 1.9750\n",
      "Epoch 2, Batch 10/249, Loss: 2.1146\n",
      "Epoch 2, Batch 20/249, Loss: 1.7385\n",
      "Epoch 2, Batch 30/249, Loss: 1.8643\n",
      "Epoch 2, Batch 40/249, Loss: 1.3431\n",
      "Epoch 2, Batch 50/249, Loss: 2.0354\n",
      "Epoch 2, Batch 60/249, Loss: 1.1739\n",
      "Epoch 2, Batch 70/249, Loss: 1.8283\n",
      "Epoch 2, Batch 80/249, Loss: 1.5613\n",
      "Epoch 2, Batch 90/249, Loss: 1.1804\n",
      "Epoch 2, Batch 100/249, Loss: 0.7583\n",
      "Epoch 2, Batch 110/249, Loss: 1.0553\n",
      "Epoch 2, Batch 120/249, Loss: 0.5527\n",
      "Epoch 2, Batch 130/249, Loss: 1.3803\n",
      "Epoch 2, Batch 140/249, Loss: 1.3796\n",
      "Epoch 2, Batch 150/249, Loss: 1.2133\n",
      "Epoch 2, Batch 160/249, Loss: 0.9640\n",
      "Epoch 2, Batch 170/249, Loss: 0.5975\n",
      "Epoch 2, Batch 180/249, Loss: 1.8378\n",
      "Epoch 2, Batch 190/249, Loss: 2.1910\n",
      "Epoch 2, Batch 200/249, Loss: 0.6622\n",
      "Epoch 2, Batch 210/249, Loss: 1.2877\n",
      "Epoch 2, Batch 220/249, Loss: 0.8881\n",
      "Epoch 2, Batch 230/249, Loss: 0.4283\n",
      "Epoch 2, Batch 240/249, Loss: 0.2714\n",
      "‚úÖ Epoch 2 completed:\n",
      "   - Average Loss: 1.2210\n",
      "   - Training Accuracy: 0.7759\n",
      "   - Training F1: 0.7566\n",
      "   - Validation Accuracy: 0.7827\n",
      "   - Validation F1: 0.7702\n",
      "Epoch 3, Batch 0/249, Loss: 1.4471\n",
      "Epoch 3, Batch 10/249, Loss: 0.7906\n",
      "Epoch 3, Batch 20/249, Loss: 0.2532\n",
      "Epoch 3, Batch 30/249, Loss: 1.0280\n",
      "Epoch 3, Batch 40/249, Loss: 0.9518\n",
      "Epoch 3, Batch 50/249, Loss: 1.6140\n",
      "Epoch 3, Batch 60/249, Loss: 0.9621\n",
      "Epoch 3, Batch 70/249, Loss: 0.3365\n",
      "Epoch 3, Batch 80/249, Loss: 0.3603\n",
      "Epoch 3, Batch 90/249, Loss: 0.2214\n",
      "Epoch 3, Batch 100/249, Loss: 0.7931\n",
      "Epoch 3, Batch 110/249, Loss: 0.0680\n",
      "Epoch 3, Batch 120/249, Loss: 1.1103\n",
      "Epoch 3, Batch 130/249, Loss: 0.5266\n",
      "Epoch 3, Batch 140/249, Loss: 0.6645\n",
      "Epoch 3, Batch 150/249, Loss: 1.5293\n",
      "Epoch 3, Batch 160/249, Loss: 0.4538\n",
      "Epoch 3, Batch 170/249, Loss: 0.5654\n",
      "Epoch 3, Batch 180/249, Loss: 0.9753\n",
      "Epoch 3, Batch 190/249, Loss: 0.0767\n",
      "Epoch 3, Batch 200/249, Loss: 0.3452\n",
      "Epoch 3, Batch 210/249, Loss: 0.4330\n",
      "Epoch 3, Batch 220/249, Loss: 0.3904\n",
      "Epoch 3, Batch 230/249, Loss: 1.3095\n",
      "Epoch 3, Batch 240/249, Loss: 0.5440\n",
      "‚úÖ Epoch 3 completed:\n",
      "   - Average Loss: 0.6462\n",
      "   - Training Accuracy: 0.8474\n",
      "   - Training F1: 0.8384\n",
      "   - Validation Accuracy: 0.8068\n",
      "   - Validation F1: 0.7979\n",
      "üéØ Training completed successfully!\n",
      "üíæ Model saved to: ./cv_classifier\n",
      "üìä Final Validation Accuracy: 0.8068\n",
      "üìä Final Validation F1: 0.7979\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Training Fine-Tuned Classifier for CV Categorization\n",
    "print(\"ü§ñ Step 3: Training Fine-Tuned Classifier...\")\n",
    "\n",
    "# Check if training data is available and model hasn't been trained yet\n",
    "if training_df is not None and not os.path.exists('./cv_classifier'):\n",
    "    # Initialize the classifier trainer with the number of unique job categories\n",
    "    classifier_trainer = CVClassifierTrainer(num_labels=len(label_mapping))\n",
    "    \n",
    "    # Prepare and tokenize the training and evaluation datasets\n",
    "    train_dataset, eval_dataset = classifier_trainer.prepare_dataset(training_df)\n",
    "    \n",
    "    print(\"üöÄ Starting custom training loop...\")\n",
    "    \n",
    "    # Import required libraries for custom training loop\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from transformers import get_linear_schedule_with_warmup\n",
    "    import numpy as np\n",
    "    \n",
    "    # Setup device - use GPU if available, otherwise CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Move the model to the appropriate device (GPU/CPU)\n",
    "    model = classifier_trainer.model.to(device)\n",
    "    tokenizer = classifier_trainer.tokenizer\n",
    "    \n",
    "    # Convert Hugging Face datasets to PyTorch tensor format\n",
    "    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    eval_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    \n",
    "    # Create data loaders for batching\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Shuffle for better training\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=8)  # No shuffle for evaluation\n",
    "    \n",
    "    # Initialize optimizer with weight decay for regularization\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    \n",
    "    # Calculate total training steps for scheduler\n",
    "    total_steps = len(train_dataloader) * 3  # batches per epoch * number of epochs\n",
    "    \n",
    "    # Create learning rate scheduler with warmup\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=500,  # Warmup phase for stable training\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop over 3 epochs\n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        all_predictions = []  # Store predictions for metric calculation\n",
    "        all_labels = []       # Store true labels for metric calculation\n",
    "        \n",
    "        # Iterate through training batches\n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            # Move batch tensors to the same device as model\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Reset gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute model outputs and loss\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backward pass - compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients to prevent explosion\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate\n",
    "            \n",
    "            # Accumulate loss for reporting\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate predictions for metrics (without tracking gradients)\n",
    "            with torch.no_grad():\n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=-1)  # Get predicted class\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Print progress every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                current_loss = loss.item()\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_dataloader)}, Loss: {current_loss:.4f}\")\n",
    "        \n",
    "        # Calculate training metrics for the epoch\n",
    "        train_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        train_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"‚úÖ Epoch {epoch+1} completed:\")\n",
    "        print(f\"   - Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"   - Training Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"   - Training F1: {train_f1:.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        # Disable gradient computation for validation (faster, less memory)\n",
    "        with torch.no_grad():\n",
    "            for val_batch in eval_dataloader:\n",
    "                val_input_ids = val_batch['input_ids'].to(device)\n",
    "                val_attention_mask = val_batch['attention_mask'].to(device)\n",
    "                val_batch_labels = val_batch['label'].to(device)\n",
    "                \n",
    "                # Forward pass for validation\n",
    "                val_outputs = model(val_input_ids, attention_mask=val_attention_mask)\n",
    "                val_preds = torch.argmax(val_outputs.logits, dim=-1)\n",
    "                val_predictions.extend(val_preds.cpu().numpy())\n",
    "                val_labels.extend(val_batch_labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "        val_f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "        \n",
    "        print(f\"   - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"   - Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Set model back to training mode for next epoch\n",
    "        model.train()\n",
    "    \n",
    "    print(\"üéØ Training completed successfully!\")\n",
    "    \n",
    "    # Save the trained model and tokenizer for future use\n",
    "    model.save_pretrained(\"./cv_classifier\")\n",
    "    tokenizer.save_pretrained(\"./cv_classifier\")\n",
    "    \n",
    "    print(\"üíæ Model saved to: ./cv_classifier\")\n",
    "    print(f\"üìä Final Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"üìä Final Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "else:\n",
    "    # Handle cases where training is skipped\n",
    "    if os.path.exists('./cv_classifier'):\n",
    "        print(\"‚úÖ Fine-tuned model already exists at ./cv_classifier\")\n",
    "    else:\n",
    "        print(\"‚ùå Skipping training - no training data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb024f",
   "metadata": {},
   "source": [
    "## 7. Enhanced CV Analyzer\n",
    "\n",
    "The `EnhancedCVAnalyzer` integrates all components:\n",
    "- **RAG system** for semantic search\n",
    "- **Fine-tuned classifier** for category prediction  \n",
    "- **Gemini LLM** for intelligent analysis\n",
    "- Fallback mechanisms for robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "556f4218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EnhancedCVAnalyzer class defined!\n"
     ]
    }
   ],
   "source": [
    "# Configure Gemini API with the provided API key\n",
    "GEMINI_API_KEY = \"AIzaSyB3_hb-Yws5Dcz3HL4ybbabHNQNSOEHuco\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "class EnhancedCVAnalyzer:\n",
    "    def __init__(self, cv_processor: CVProcessor, classifier_path: str = None):\n",
    "        \"\"\"\n",
    "        Initialize Enhanced CV Analyzer with RAG and fine-tuned classification capabilities.\n",
    "        \n",
    "        Args:\n",
    "            cv_processor (CVProcessor): Pre-initialized CV processor for semantic search\n",
    "            classifier_path (str): Path to fine-tuned classifier model directory\n",
    "        \"\"\"\n",
    "        self.cv_processor = cv_processor\n",
    "        \n",
    "        # Load fine-tuned classifier if available\n",
    "        if classifier_path and os.path.exists(classifier_path):\n",
    "            try:\n",
    "                # Load tokenizer and model from the fine-tuned classifier\n",
    "                self.classifier_tokenizer = AutoTokenizer.from_pretrained(classifier_path)\n",
    "                self.classifier_model = AutoModelForSequenceClassification.from_pretrained(classifier_path)\n",
    "                \n",
    "                # Load label mapping created during training\n",
    "                with open('label_mapping.json', 'r') as f:\n",
    "                    label_mapping = json.load(f)\n",
    "                # Create reverse mapping from ID to label name\n",
    "                self.id_to_label = {int(v): k for k, v in label_mapping.items()}\n",
    "                print(\"‚úÖ Fine-tuned classifier loaded successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading classifier: {e}\")\n",
    "                self.classifier_model = None\n",
    "        else:\n",
    "            self.classifier_model = None\n",
    "            print(\"‚ÑπÔ∏è No fine-tuned classifier available\")\n",
    "        \n",
    "        # Initialize Gemini LLM with fallback options\n",
    "        try:\n",
    "            self.llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
    "            print(\"‚úÖ Using model: gemini-2.0-flash-exp\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå gemini-2.0-flash-exp not available: {e}\")\n",
    "            try:\n",
    "                # Fallback to a more stable model if experimental one fails\n",
    "                self.llm_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "                print(\"‚úÖ Using fallback model: gemini-1.5-flash\")\n",
    "            except:\n",
    "                self.llm_model = None\n",
    "                print(\"‚ùå No working LLM models found\")\n",
    "    \n",
    "    def predict_category(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Use fine-tuned model to predict CV category/job role.\n",
    "        \n",
    "        Args:\n",
    "            text (str): CV text to classify\n",
    "            \n",
    "        Returns:\n",
    "            str: Predicted job category or error message\n",
    "        \"\"\"\n",
    "        if self.classifier_model is None:\n",
    "            return \"Classifier not available\"\n",
    "        \n",
    "        try:\n",
    "            # Tokenize input text for the classifier\n",
    "            inputs = self.classifier_tokenizer(\n",
    "                text[:512],  # Use first 512 characters for efficiency\n",
    "                return_tensors=\"pt\",      # Return PyTorch tensors\n",
    "                padding=True,             # Pad sequences to same length\n",
    "                truncation=True,          # Truncate longer sequences\n",
    "                max_length=512            # Maximum sequence length\n",
    "            )\n",
    "            \n",
    "            # Make prediction without gradient computation (faster)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.classifier_model(**inputs)\n",
    "                # Convert logits to probabilities using softmax\n",
    "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                # Get the predicted class ID\n",
    "                predicted_class_id = predictions.argmax().item()\n",
    "                \n",
    "            # Map class ID back to human-readable label\n",
    "            return self.id_to_label.get(predicted_class_id, \"Unknown\")\n",
    "        except Exception as e:\n",
    "            return f\"Prediction error: {str(e)}\"\n",
    "    \n",
    "    def analyze_cv(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Enhanced RAG analysis combining semantic search and fine-tuned classification.\n",
    "        \n",
    "        Args:\n",
    "            query (str): Job requirement or search query\n",
    "            \n",
    "        Returns:\n",
    "            str: Comprehensive CV analysis and hiring recommendations\n",
    "        \"\"\"\n",
    "        if self.llm_model is None:\n",
    "            return \"LLM model not available.\"\n",
    "        \n",
    "        # Search for relevant CV chunks using semantic similarity\n",
    "        similar_docs = self.cv_processor.search_similar(query, top_k=5)\n",
    "        \n",
    "        if not similar_docs:\n",
    "            return \"No relevant CV information found for your query. Try searching for different skills or roles.\"\n",
    "        \n",
    "        # Prepare context from similar documents\n",
    "        context = \"\\n\\n\".join([doc['document'] for doc in similar_docs])\n",
    "        \n",
    "        # Use fine-tuned classifier for additional insights on top matches\n",
    "        category_insights = []\n",
    "        for doc in similar_docs[:3]:  # Analyze top 3 matches\n",
    "            category = self.predict_category(doc['document'])\n",
    "            category_insights.append(f\"‚Ä¢ {category} (confidence: {doc['score']:.2f})\")\n",
    "        \n",
    "        # IMPROVED PROMPT - More specific and query-focused for better recruitment analysis\n",
    "        enhanced_prompt = f\"\"\"\n",
    "        You are an experienced HR recruiter analyzing CVs for a client.\n",
    "\n",
    "JOB REQUIREMENT: {query}\n",
    "\n",
    "CANDIDATE CV DATA:\n",
    "{context}\n",
    "\n",
    "JOB CATEGORIES:\n",
    "{chr(10).join(category_insights)}\n",
    "\n",
    "TASK: Provide a recruitment assessment focusing on:\n",
    "- Which candidates best match the job requirement\n",
    "- Their specific relevant skills and experience\n",
    "- Any gaps or concerns\n",
    "- Your hiring recommendation\n",
    "\n",
    "Keep it professional and concise (under 150 words). Focus on actionable insights for hiring.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Generate analysis using Gemini LLM\n",
    "            response = self.llm_model.generate_content(enhanced_prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def categorize_candidate(self, cv_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Enhanced categorization using fine-tuned model with LLM fallback.\n",
    "        \n",
    "        Args:\n",
    "            cv_text (str): Full CV text to categorize\n",
    "            \n",
    "        Returns:\n",
    "            str: Job category or role classification\n",
    "        \"\"\"\n",
    "        # Prefer fine-tuned classifier for accuracy\n",
    "        if self.classifier_model:\n",
    "            return self.predict_category(cv_text)\n",
    "        else:\n",
    "            # Fallback to LLM-based categorization if classifier unavailable\n",
    "            prompt = f\"Analyze this CV text and categorize it: {cv_text[:1000]}\"\n",
    "            try:\n",
    "                response = self.llm_model.generate_content(prompt)\n",
    "                return response.text\n",
    "            except:\n",
    "                return \"Categorization failed\"\n",
    "\n",
    "print(\"‚úÖ EnhancedCVAnalyzer class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54f9f0",
   "metadata": {},
   "source": [
    "## 8. System Initialization\n",
    "\n",
    "Initialize the complete analysis system and verify all components:\n",
    "- RAG search capability ‚úÖ\n",
    "- Fine-tuned classifier ‚úÖ  \n",
    "- LLM integration ‚úÖ\n",
    "- Ready for production use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82948597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Step 4: Initializing Enhanced Analyzer...\n",
      "‚úÖ Fine-tuned classifier loaded successfully!\n",
      "‚úÖ Using model: gemini-2.0-flash-exp\n",
      "‚úÖ Enhanced analyzer initialized successfully!\n",
      "üìä System capabilities:\n",
      "   - RAG Search: ‚úÖ\n",
      "   - Fine-Tuned Classifier: ‚úÖ\n",
      "   - LLM Integration: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Initializing the Enhanced CV Analyzer with all integrated components\n",
    "print(\"üöÄ Step 4: Initializing Enhanced Analyzer...\")\n",
    "\n",
    "# Initialize the enhanced analyzer with the CV processor and optional classifier\n",
    "enhanced_analyzer = EnhancedCVAnalyzer(\n",
    "    cv_processor,  # Pass the pre-initialized CV processor with FAISS index\n",
    "    classifier_path=\"./cv_classifier\" if os.path.exists(\"./cv_classifier\") else None  # Conditionally load fine-tuned classifier if available\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhanced analyzer initialized successfully!\")\n",
    "\n",
    "# Display system capabilities and component status\n",
    "print(\"üìä System capabilities:\")\n",
    "print(f\"   - RAG Search: {'‚úÖ' if cv_processor.index is not None else '‚ùå'}\")  # Check if FAISS index is loaded for semantic search\n",
    "print(f\"   - Fine-Tuned Classifier: {'‚úÖ' if enhanced_analyzer.classifier_model is not None else '‚ùå'}\")  # Check if custom classifier is available\n",
    "print(f\"   - LLM Integration: {'‚úÖ' if enhanced_analyzer.llm_model is not None else '‚ùå'}\")  # Check if Gemini AI is connected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e038520",
   "metadata": {},
   "source": [
    "## 9. Comprehensive System Testing\n",
    "\n",
    "Test the integrated system with diverse queries across different job domains:\n",
    "- Technical roles (Python developers)\n",
    "- Business roles (Financial analysts) \n",
    "- Creative roles (Marketing professionals)\n",
    "- Validation of category prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be011981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Step 5: Testing the System...\n",
      "Running test queries...\n",
      "\n",
      "üîç Test 1: Find candidates with Python programming experience\n",
      "--------------------------------------------------\n",
      "üìù Result:\n",
      "Here's an assessment of the candidates focusing on Python programming experience:\n",
      "\n",
      "**Best Matches:**\n",
      "\n",
      "*   **Software Developer:** Strongest candidate. Lists Python experience, including related frameworks (TensorFlow, Keras, Pandas, NLTK). Details Python projects involving BERT, ELMO, Flask, and data visualization.\n",
      "*   **Information Designer:** Lists Python under \"Technical Skills,\" but lacks detailed project experience.\n",
      "\n",
      "**Relevant Skills:**\n",
      "\n",
      "*   **Software Developer:** Python, Flask, BERT, ELMO, Tensorflow, Keras, Pandas, NLTK.\n",
      "*   **Information Designer:** Python.\n",
      "\n",
      "**Gaps/Concerns:**\n",
      "\n",
      "*   **Information Designer:** Needs verification of proficiency and practical application of Python.\n",
      "*   **ALL:** The experience level is unclear since we are not given the number of years of experience.\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "Prioritize the Software Developer candidate for an interview to deeply assess Python skills and project contributions. Explore the Information Designer's Python expertise only if the first candidate is unsuitable.\n",
      "\n",
      "üéØ Category Prediction Test: 'Python developer with machine learning experience and cloud computing skills.' -> INFORMATION-TECHNOLOGY\n",
      "================================================================================\n",
      "\n",
      "üîç Test 2: Looking for financial analysts with Excel skills\n",
      "--------------------------------------------------\n",
      "üìù Result:\n",
      "Here's a recruitment assessment of the candidates:\n",
      "\n",
      "**Best Matches:** The \"Acting Finance Manager\" and \"FINANCIAL ANALYST INTERN\" are the strongest fits due to their titles and experience.\n",
      "\n",
      "**Relevant Skills and Experience:**\n",
      "*   **Acting Finance Manager:** Advanced Excel, Hyperion, Oracle Financials, budgeting, financial reporting & analysis. Experience in multiple industries is a plus.\n",
      "*   **FINANCIAL ANALYST INTERN:** Strong focus on financial analysis, forecasting, and modeling. Mentions financial process improvement and due diligence. Experience with Quickbooks.\n",
      "\n",
      "**Gaps/Concerns:**\n",
      "*   **Acting Finance Manager:** Not a perfect \"Financial Analyst\" title. Needs a clear understanding of their current role to see if it's similar to Financial Analyst.\n",
      "*   **FINANCIAL ANALYST INTERN:** Internship experience, and may lack practical application of Excel skill.\n",
      "\n",
      "**Recommendation:** Prioritize interviewing the \"Acting Finance Manager\" and \"FINANCIAL ANALYST INTERN.\" Verify Excel skills and depth of analysis during the interview process for the Financial Analyst Intern.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Test 3: Software developers with cloud computing background\n",
      "--------------------------------------------------\n",
      "üìù Result:\n",
      "Based on the provided CVs, the strongest candidate for a Software Developer with a Cloud Computing background is the **Sr. Project Manager**.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "*   Experience managing software lifecycles within a cloud environment (AT&T Cloud Services).\n",
      "*   Hands-on experience with pre-production lab planning, testing, and deployment for cloud projects.\n",
      "*   Familiar with VMware and cloud-related project budgets.\n",
      "*   Experience with leading project team, consulting with clients.\n",
      "\n",
      "**Gaps/Concerns:**\n",
      "\n",
      "*   The level of hands-on coding skills isn't explicitly stated. Cloud implementation experience is primarily at a managerial level.\n",
      "*   Details on specific cloud platforms (AWS, Azure, GCP) used are lacking.\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "Prioritize an interview to assess their coding abilities and experience with specific cloud platforms. Verify depth of technical understanding during the interview process.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Test 4: Marketing professionals with digital media experience\n",
      "--------------------------------------------------\n",
      "üìù Result:\n",
      "Here's an assessment of the provided candidates:\n",
      "\n",
      "**Top Matches:**\n",
      "\n",
      "*   **Digital Marketing Specialist:** This candidate is a strong match. They possess extensive digital marketing experience, proficiency in relevant tools (Google Analytics, AdWords, Adobe Creative Suite), and experience in email marketing, SEO/SEM, and digital strategy. Their experience in strategic management and digital operations, combined with their understanding of media planning, makes them a valuable asset.\n",
      "\n",
      "*   **Videographer:** This candidate also is well-matched. They have experience creating digital marketing plans, using social media to drive engagement, and email marketing campaigns.\n",
      "\n",
      "**Concerns:**\n",
      "\n",
      "*   **Digital Media Consultant:** While this candidate has sales experience in the digital media space, their focus is primarily on sales and business development, not digital marketing execution.\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "Prioritize interviewing the \"Digital Marketing Specialist\" and \"Videographer\". These candidates have relevant digital media experience, technical skills, and a demonstrated ability to execute digital marketing strategies.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ System testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Comprehensive System Testing and Validation\n",
    "print(\"üß™ Step 5: Testing the System...\")\n",
    "\n",
    "# Define diverse test queries to evaluate different system capabilities\n",
    "test_queries = [\n",
    "    \"Find candidates with Python programming experience\",           # Technical/Programming role\n",
    "    \"Looking for financial analysts with Excel skills\",             # Finance/Business role\n",
    "    \"Software developers with cloud computing background\",          # Cloud/Infrastructure role\n",
    "    \"Marketing professionals with digital media experience\"         # Marketing/Creative role\n",
    "]\n",
    "\n",
    "print(\"Running test queries...\\n\")\n",
    "\n",
    "# Iterate through each test query to validate system functionality\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"üîç Test {i}: {query}\")\n",
    "    print(\"-\" * 50)  # Visual separator for better readability\n",
    "    \n",
    "    # Execute the enhanced CV analysis using RAG + classifier + LLM\n",
    "    result = enhanced_analyzer.analyze_cv(query)\n",
    "    print(f\"üìù Result:\\n{result}\")\n",
    "    \n",
    "    # Additional test: Validate category prediction functionality\n",
    "    # Only run this once (on first query) to avoid redundancy\n",
    "    if i == 1 and enhanced_analyzer.classifier_model is not None:\n",
    "        sample_text = \"Python developer with machine learning experience and cloud computing skills.\"\n",
    "        predicted = enhanced_analyzer.predict_category(sample_text)\n",
    "        print(f\"üéØ Category Prediction Test: '{sample_text}' -> {predicted}\")\n",
    "    \n",
    "    print(\"=\" * 80)  # Major separator between test cases\n",
    "    print()  # Blank line for better visual spacing\n",
    "\n",
    "print(\"‚úÖ System testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c01a27",
   "metadata": {},
   "source": [
    "# Production Deployment\n",
    "\n",
    "## 10. REST API Development\n",
    "\n",
    "Build a production-ready Flask API with:\n",
    "- RESTful endpoints for CV analysis\n",
    "- Health monitoring and diagnostics\n",
    "- CORS support for web applications\n",
    "- Structured request/response handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "375fee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Flask API setup complete!\n"
     ]
    }
   ],
   "source": [
    "class CVAnalysisAPI:\n",
    "    def __init__(self, analyzer: EnhancedCVAnalyzer):\n",
    "        \"\"\"\n",
    "        Initialize CV Analysis API handler.\n",
    "        \n",
    "        Args:\n",
    "            analyzer (EnhancedCVAnalyzer): Pre-initialized analyzer with all components\n",
    "        \"\"\"\n",
    "        self.analyzer = analyzer\n",
    "    \n",
    "    def process_request(self, data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Process incoming API requests and route to appropriate functionality.\n",
    "        \n",
    "        Args:\n",
    "            data (Dict): Request data containing action, query, text, etc.\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Response data with analysis results or error messages\n",
    "        \"\"\"\n",
    "        # Extract request parameters with defaults\n",
    "        action = data.get('action', 'analyze')  # Default to analysis action\n",
    "        query = data.get('query', '')           # Search query for analysis\n",
    "        category = data.get('category', '')     # Optional category filter\n",
    "        \n",
    "        # Route to analysis functionality\n",
    "        if action == 'analyze':\n",
    "            if not query:\n",
    "                return {'error': 'Query is required for analysis'}\n",
    "            \n",
    "            # Perform comprehensive RAG analysis with fine-tuned components\n",
    "            result = self.analyzer.analyze_cv(query)\n",
    "            \n",
    "            return {\n",
    "                'action': 'analysis',\n",
    "                'query': query,\n",
    "                'category': category,\n",
    "                'analysis': result,\n",
    "                'fine_tuned': True,  # Indicates enhanced analyzer is being used\n",
    "                'timestamp': pd.Timestamp.now().isoformat()  # Add timestamp for tracking\n",
    "            }\n",
    "        \n",
    "        # Route to categorization functionality\n",
    "        elif action == 'categorize':\n",
    "            text = data.get('text', query)  # Use text field or fallback to query\n",
    "            if not text:\n",
    "                return {'error': 'Text is required for categorization'}\n",
    "            \n",
    "            # Use fine-tuned classifier for accurate categorization\n",
    "            if self.analyzer.classifier_model:\n",
    "                category = self.analyzer.predict_category(text)\n",
    "                return {\n",
    "                    'action': 'categorization',\n",
    "                    'text': text[:500],  # Return truncated text for response\n",
    "                    'predicted_category': category,\n",
    "                    'fine_tuned': True,  # Indicates classifier was used\n",
    "                    'timestamp': pd.Timestamp.now().isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {'error': 'Fine-tuned classifier not available'}\n",
    "        \n",
    "        # Handle unknown actions\n",
    "        else:\n",
    "            return {'error': f'Unknown action: {action}'}\n",
    "\n",
    "def setup_flask_app(analyzer: EnhancedCVAnalyzer):\n",
    "    \"\"\"\n",
    "    Setup Flask web application with CV analysis endpoints.\n",
    "    \n",
    "    Args:\n",
    "        analyzer (EnhancedCVAnalyzer): Pre-initialized analyzer instance\n",
    "        \n",
    "    Returns:\n",
    "        Flask: Configured Flask application instance\n",
    "    \"\"\"\n",
    "    app = Flask(__name__)\n",
    "    CORS(app)  # Enable Cross-Origin Resource Sharing for web clients\n",
    "    \n",
    "    # Initialize API handler\n",
    "    cv_api = CVAnalysisAPI(analyzer)\n",
    "    \n",
    "    @app.route('/analyze', methods=['POST'])\n",
    "    def analyze_cv():\n",
    "        \"\"\"\n",
    "        Analyze CVs based on job requirements query.\n",
    "        \n",
    "        Expected JSON:\n",
    "        {\n",
    "            \"action\": \"analyze\",\n",
    "            \"query\": \"Find candidates with Python experience\",\n",
    "            \"category\": \"optional_category_filter\"\n",
    "        }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = request.json\n",
    "            result = cv_api.process_request(data)\n",
    "            return jsonify(result)\n",
    "        except Exception as e:\n",
    "            # Handle any unexpected errors\n",
    "            return jsonify({'error': str(e)}), 500\n",
    "    \n",
    "    @app.route('/health', methods=['GET'])\n",
    "    def health_check():\n",
    "        \"\"\"\n",
    "        Health check endpoint to verify API is running.\n",
    "        \"\"\"\n",
    "        return jsonify({\n",
    "            'status': 'healthy', \n",
    "            'service': 'CV Analysis API',\n",
    "            'version': '1.0'\n",
    "        })\n",
    "    \n",
    "    @app.route('/categories', methods=['GET'])\n",
    "    def get_categories():\n",
    "        \"\"\"\n",
    "        Get list of available job categories for classification.\n",
    "        \"\"\"\n",
    "        categories = [\n",
    "            'HR', 'ACCOUNTANT', 'ADVOCATE', 'APPAREL', 'ARTS', 'AUTOMOBILE', \n",
    "            'AVIATION', 'BANKING', 'BUSINESS-DEVELOPMENT', 'BPO', 'CHEF', \n",
    "            'CONSTRUCTION', 'CONSULTANT', 'DESIGNER', 'DIGITAL-MEDIA', \n",
    "            'ENGINEERING', 'FINANCE', 'HEALTHCARE', 'INFORMATION-TECHNOLOGY',\n",
    "            'SALES', 'PUBLIC-RELATIONS', 'TEACHER'\n",
    "        ]\n",
    "        return jsonify({'categories': categories})\n",
    "    \n",
    "    return app\n",
    "\n",
    "print(\"‚úÖ Flask API setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdaf8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Testing API with Correct Method...\n",
      "‚úÖ Response Status: 200\n",
      "üéØ Analysis Result:\n",
      "{\n",
      "  \"analysis\": \"Based on the provided CVs, the \\\"SOFTWARE DEVELOPER\\\" is the strongest candidate.\\n\\n**Strengths:**\\n*   Explicit mention of Python experience in \\\"Skills\\\" and \\\"Projects\\\" section.\\n*   Demonstrates experience with relevant frameworks like TensorFlow, Keras, Pandas, and NLTK.\\n*   \\\"Question Answering System\\\" and \\\"Data Visualization Tool\\\" projects showcase practical Python application.\\n\\n**Gaps/Concerns:**\\n*   The candidate has extensive experience using C#, so make sure their Python experience is adequate.\\n\\n**Recommendation:** Prioritize interviewing the \\\"SOFTWARE DEVELOPER.\\\" Verify Python proficiency and the depth of experience during the interview. The \\\"INFORMATION DESIGNER\\\" and \\\"INFORMATION DESIGNER\\\" candidates are less relevant as Python isn't prominent in their profiles. The last candidate might be worth a look if he wants to switch to IT, but he has no proven commercial record of working with Python.\\n\",\n",
      "  \"category\": \"INFORMATION-TECHNOLOGY\",\n",
      "  \"query\": \"Find candidates with Python programming experience\",\n",
      "  \"status\": \"success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# API Testing with Correct HTTP Methods\n",
    "print(\"üîß Testing API with Correct Method...\")\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Base URL for the Flask API (assuming it's running on localhost port 8000)\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "# CORRECT: Use POST method for /analyze endpoint with JSON payload\n",
    "test_data = {\n",
    "    \"action\": \"analyze\",  # Specify the action type\n",
    "    \"query\": \"Find candidates with Python programming experience\",  # Search query\n",
    "    \"category\": \"INFORMATION-TECHNOLOGY\"  # Optional category filter\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Send POST request with JSON data (correct method for /analyze endpoint)\n",
    "    response = requests.post(f\"{base_url}/analyze\", json=test_data)  # ‚Üê Using POST not GET\n",
    "    \n",
    "    # Print HTTP status code for immediate feedback\n",
    "    print(f\"‚úÖ Response Status: {response.status_code}\")\n",
    "    \n",
    "    # Process successful responses\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"üéØ Analysis Result:\")\n",
    "        # Pretty print the JSON response for readability\n",
    "        print(json.dumps(result, indent=2))\n",
    "    else:\n",
    "        # Handle HTTP errors (4xx, 5xx status codes)\n",
    "        print(f\"‚ùå Error: {response.text}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Connection failed - Make sure the Flask server is running on port 8000\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"‚ùå Request timeout - Server took too long to respond\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Request failed: {e}\")  # Catch any other unexpected errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f592e",
   "metadata": {},
   "source": [
    "## 12. Cloud Deployment with Ngrok\n",
    "\n",
    "Expose the local API to the internet using ngrok tunneling for:\n",
    "- External access and testing\n",
    "- Webhook integrations\n",
    "- Demo and sharing capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Starting ngrok tunnel...\n",
      "‚è≥ Waiting for ngrok to start...\n",
      "ngrok status: Downloading ngrok ...\n",
      "Downloading ngrok: 0%\n",
      "Downloading ngrok: 1%\n",
      "Downloading ngrok: 2%\n",
      "Downloading ngrok: 3%\n",
      "Downloading ngrok: 4%\n",
      "Downloading ngrok: 5%\n",
      "Downloading ngrok: 6%\n",
      "Downloading ngrok: 7%\n",
      "Downloading ngrok: 8%\n",
      "Downloading ngrok: 9%\n",
      "Downloading ngrok: 10%\n",
      "Downloading ngrok: 11%\n",
      "Downloading ngrok: 12%\n",
      "Downloading ngrok: 13%\n",
      "Downloading ngrok: 14%\n",
      "Downloading ngrok: 15%\n",
      "Downloading ngrok: 16%\n",
      "Downloading ngrok: 17%\n",
      "Downloading ngrok: 18%\n",
      "Downloading ngrok: 19%\n",
      "Downloading ngrok: 20%\n",
      "Downloading ngrok: 21%\n",
      "Downloading ngrok: 22%\n",
      "Downloading ngrok: 23%\n",
      "Downloading ngrok: 24%\n",
      "Downloading ngrok: 25%\n",
      "Downloading ngrok: 26%\n",
      "Downloading ngrok: 27%\n",
      "Downloading ngrok: 28%\n",
      "Downloading ngrok: 29%\n",
      "Downloading ngrok: 30%\n",
      "Downloading ngrok: 31%\n",
      "Downloading ngrok: 32%\n",
      "Downloading ngrok: 33%\n",
      "Downloading ngrok: 34%\n",
      "Downloading ngrok: 35%\n",
      "Downloading ngrok: 36%\n",
      "Downloading ngrok: 37%\n",
      "Downloading ngrok: 38%\n",
      "Downloading ngrok: 39%\n",
      "Downloading ngrok: 40%\n",
      "Downloading ngrok: 41%\n",
      "Downloading ngrok: 42%\n",
      "Downloading ngrok: 43%\n",
      "Downloading ngrok: 44%\n",
      "Downloading ngrok: 45%\n",
      "Downloading ngrok: 46%\n",
      "Downloading ngrok: 47%\n",
      "Downloading ngrok: 48%\n",
      "Downloading ngrok: 49%\n",
      "Downloading ngrok: 50%\n",
      "Downloading ngrok: 51%\n",
      "Downloading ngrok: 52%\n",
      "Downloading ngrok: 53%\n",
      "Downloading ngrok: 54%\n",
      "Downloading ngrok: 55%\n",
      "Downloading ngrok: 56%\n",
      "Downloading ngrok: 57%\n",
      "Downloading ngrok: 58%\n",
      "Downloading ngrok: 59%\n",
      "Downloading ngrok: 60%\n",
      "Downloading ngrok: 61%\n",
      "Downloading ngrok: 62%\n",
      "Downloading ngrok: 63%\n",
      "Downloading ngrok: 64%\n",
      "Downloading ngrok: 65%\n",
      "Downloading ngrok: 66%\n",
      "Downloading ngrok: 67%\n",
      "Downloading ngrok: 68%\n",
      "Downloading ngrok: 69%\n",
      "Downloading ngrok: 70%\n",
      "Downloading ngrok: 71%\n",
      "Downloading ngrok: 72%\n",
      "Downloading ngrok: 73%\n",
      "Downloading ngrok: 74%\n",
      "Downloading ngrok: 75%\n",
      "Downloading ngrok: 76%\n",
      "Downloading ngrok: 77%\n",
      "Downloading ngrok: 78%\n",
      "Downloading ngrok: 79%\n",
      "Downloading ngrok: 80%\n",
      "Downloading ngrok: 81%\n",
      "Downloading ngrok: 82%\n",
      "Downloading ngrok: 83%\n",
      "Downloading ngrok: 84%\n",
      "Downloading ngrok: 85%\n",
      "Downloading ngrok: 86%\n",
      "Downloading ngrok: 87%\n",
      "Downloading ngrok: 88%\n",
      "Downloading ngrok: 89%\n",
      "Downloading ngrok: 90%\n",
      "Downloading ngrok: 91%\n",
      "Downloading ngrok: 92%\n",
      "Downloading ngrok: 93%\n",
      "Downloading ngrok: 94%\n",
      "Downloading ngrok: 95%\n",
      "Downloading ngrok: 96%\n",
      "Downloading ngrok: 97%\n",
      "Downloading ngrok: 98%\n",
      "Downloading ngrok: 99%\n",
      "Downloading ngrok: 100%\n",
      "                                                                                                    \n",
      "Installing ngrok ... \n",
      "\n",
      "Active tunnels: Downloading ngrok ...\n",
      "Downloading ngrok: 0%\n",
      "Downloading ngrok: 1%\n",
      "Downloading ngrok: 2%\n",
      "Downloading ngrok: 3%\n",
      "Downloading ngrok: 4%\n",
      "Downloading ngrok: 5%\n",
      "Downloading ngrok: 6%\n",
      "Downloading ngrok: 7%\n",
      "Downloading ngrok: 8%\n",
      "Downloading ngrok: 9%\n",
      "Downloading ngrok: 10%\n",
      "Downloading ngrok: 11%\n",
      "Downloading ngrok: 12%\n",
      "Downloading ngrok: 13%\n",
      "Downloading ngrok: 14%\n",
      "Downloading ngrok: 15%\n",
      "Downloading ngrok: 16%\n",
      "Downloading ngrok: 17%\n",
      "Downloading ngrok: 18%\n",
      "Downloading ngrok: 19%\n",
      "Downloading ngrok: 20%\n",
      "Downloading ngrok: 21%\n",
      "Downloading ngrok: 22%\n",
      "Downloading ngrok: 23%\n",
      "Downloading ngrok: 24%\n",
      "Downloading ngrok: 25%\n",
      "Downloading ngrok: 26%\n",
      "Downloading ngrok: 27%\n",
      "Downloading ngrok: 28%\n",
      "Downloading ngrok: 29%\n",
      "Downloading ngrok: 30%\n",
      "Downloading ngrok: 31%\n",
      "Downloading ngrok: 32%\n",
      "Downloading ngrok: 33%\n",
      "Downloading ngrok: 34%\n",
      "Downloading ngrok: 35%\n",
      "Downloading ngrok: 36%\n",
      "Downloading ngrok: 37%\n",
      "Downloading ngrok: 38%\n",
      "Downloading ngrok: 39%\n",
      "Downloading ngrok: 40%\n",
      "Downloading ngrok: 41%\n",
      "Downloading ngrok: 42%\n",
      "Downloading ngrok: 43%\n",
      "Downloading ngrok: 44%\n",
      "Downloading ngrok: 45%\n",
      "Downloading ngrok: 46%\n",
      "Downloading ngrok: 47%\n",
      "Downloading ngrok: 48%\n",
      "Downloading ngrok: 49%\n",
      "Downloading ngrok: 50%\n",
      "Downloading ngrok: 51%\n",
      "Downloading ngrok: 52%\n",
      "Downloading ngrok: 53%\n",
      "Downloading ngrok: 54%\n",
      "Downloading ngrok: 55%\n",
      "Downloading ngrok: 56%\n",
      "Downloading ngrok: 57%\n",
      "Downloading ngrok: 58%\n",
      "Downloading ngrok: 59%\n",
      "Downloading ngrok: 60%\n",
      "Downloading ngrok: 61%\n",
      "Downloading ngrok: 62%\n",
      "Downloading ngrok: 63%\n",
      "Downloading ngrok: 64%\n",
      "Downloading ngrok: 65%\n",
      "Downloading ngrok: 66%\n",
      "Downloading ngrok: 67%\n",
      "Downloading ngrok: 68%\n",
      "Downloading ngrok: 69%\n",
      "Downloading ngrok: 70%\n",
      "Downloading ngrok: 71%\n",
      "Downloading ngrok: 72%\n",
      "Downloading ngrok: 73%\n",
      "Downloading ngrok: 74%\n",
      "Downloading ngrok: 75%\n",
      "Downloading ngrok: 76%\n",
      "Downloading ngrok: 77%\n",
      "Downloading ngrok: 78%\n",
      "Downloading ngrok: 79%\n",
      "Downloading ngrok: 80%\n",
      "Downloading ngrok: 81%\n",
      "Downloading ngrok: 82%\n",
      "Downloading ngrok: 83%\n",
      "Downloading ngrok: 84%\n",
      "Downloading ngrok: 85%\n",
      "Downloading ngrok: 86%\n",
      "Downloading ngrok: 87%\n",
      "Downloading ngrok: 88%\n",
      "Downloading ngrok: 89%\n",
      "Downloading ngrok: 90%\n",
      "Downloading ngrok: 91%\n",
      "Downloading ngrok: 92%\n",
      "Downloading ngrok: 93%\n",
      "Downloading ngrok: 94%\n",
      "Downloading ngrok: 95%\n",
      "Downloading ngrok: 96%\n",
      "Downloading ngrok: 97%\n",
      "Downloading ngrok: 98%\n",
      "Downloading ngrok: 99%\n",
      "Downloading ngrok: 100%\n",
      "                                                                                                    \n",
      "Installing ngrok ... \n",
      "\n",
      "‚úÖ ngrok tunnel started!\n"
     ]
    }
   ],
   "source": [
    "# Cell: Start ngrok tunnel for public API access\n",
    "print(\"üåê Starting ngrok tunnel...\")\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def start_ngrok_tunnel():\n",
    "    \"\"\"\n",
    "    Start ngrok tunnel to expose local Flask server to the internet.\n",
    "    \n",
    "    Returns:\n",
    "        subprocess.Popen: Ngrok process object or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Start ngrok tunnel forwarding port 8000 to a public URL\n",
    "        process = subprocess.Popen(\n",
    "            ['ngrok', 'http', '8000'],  # Command to start ngrok for port 8000\n",
    "            stdout=subprocess.PIPE,     # Capture standard output\n",
    "            stderr=subprocess.PIPE,     # Capture error output\n",
    "            text=True                   # Return output as text (not bytes)\n",
    "        )\n",
    "        \n",
    "        print(\"‚è≥ Waiting for ngrok to start...\")\n",
    "        time.sleep(5)  # Give ngrok time to initialize and establish tunnel\n",
    "        \n",
    "        # Check ngrok configuration to verify it's running properly\n",
    "        status_process = subprocess.run(\n",
    "            ['ngrok', 'config', 'check'],  # Verify ngrok configuration\n",
    "            capture_output=True,           # Capture both stdout and stderr\n",
    "            text=True                      # Return output as text\n",
    "        )\n",
    "        \n",
    "        # Get list of active tunnels to find the public URL\n",
    "        tunnels_process = subprocess.run(\n",
    "            ['ngrok', 'api', 'tunnels', 'list'],  # List all active tunnels\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # Print diagnostic information\n",
    "        print(\"ngrok status:\", status_process.stdout)\n",
    "        if tunnels_process.stdout:\n",
    "            print(\"Active tunnels:\", tunnels_process.stdout)\n",
    "            \n",
    "        return process  # Return the process object for later management\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå ngrok not found. Please install ngrok first:\")\n",
    "        print(\"   - Download from: https://ngrok.com/download\")\n",
    "        print(\"   - Or install via pip: pip install pyngrok\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to start ngrok: {e}\")\n",
    "        return None\n",
    "\n",
    "# Start ngrok tunnel in background\n",
    "ngrok_process = start_ngrok_tunnel()\n",
    "\n",
    "if ngrok_process:\n",
    "    print(\"‚úÖ ngrok tunnel started!\")\n",
    "    print(\"üì¢ Your API is now accessible via public URL (check ngrok output above)\")\n",
    "    print(\"üí° Use the ngrok URL to test your API from external services\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to start ngrok tunnel\")\n",
    "    print(\"üí° Alternative: You can still use the API locally at http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a4a11078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking ngrok tunnel status\n",
      "üìä Active ngrok tunnels:\n",
      "   ‚Üí https://favorably-rhetorical-morris.ngrok-free.dev -> http://localhost:8000\n",
      "     Protocol: https\n"
     ]
    }
   ],
   "source": [
    "# Cell: Check ngrok tunnel details\n",
    "print(\"üîç Checking ngrok tunnel status\")\n",
    "\n",
    "try:\n",
    "    response = requests.get('http://localhost:4040/api/tunnels', timeout=5)\n",
    "    tunnels = response.json().get('tunnels', [])\n",
    "    \n",
    "    print(\"üìä Active ngrok tunnels:\")\n",
    "    for tunnel in tunnels:\n",
    "        print(f\"   ‚Üí {tunnel['public_url']} -> {tunnel['config']['addr']}\")\n",
    "        print(f\"     Protocol: {tunnel['proto']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cannot access ngrok: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91afd7e",
   "metadata": {},
   "source": [
    "# üéØ Interactive CV Analysis System\n",
    "\n",
    "## Final Production Interface\n",
    "\n",
    "Launch the fully interactive system that provides:\n",
    "- User-friendly command-line interface\n",
    "- Real-time AI analysis with progress indicators\n",
    "- Multiple job category selection\n",
    "- Results export and saving\n",
    "- Continuous analysis capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60ec9b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FULLY INTERACTIVE CV ANALYSIS SYSTEM\n",
      "============================================================\n",
      "ü§ñ AI-Powered CV Analysis System\n",
      "üìä Analyzes hundreds of CVs using RAG + Fine-tuned AI\n",
      "\n",
      "============================================================\n",
      "\n",
      "üéØ ENTER YOUR ANALYSIS REQUEST\n",
      "----------------------------------------\n",
      "\n",
      "üîç What skills or positions are you looking for?\n",
      "   Examples:\n",
      "   ‚Ä¢ Python developers with Django experience\n",
      "   ‚Ä¢ Financial analysts with Excel skills\n",
      "   ‚Ä¢ Marketing managers with social media experience\n",
      "   ‚Ä¢ Sales professionals with B2B background\n",
      "\n",
      "üìÇ SELECT A CATEGORY:\n",
      "------------------------------\n",
      "Available categories:\n",
      "    1. INFORMATION-TECHNOLOGY       2. FINANCE                      3. ENGINEERING              \n",
      "    4. MARKETING                    5. HEALTHCARE                   6. SALES                    \n",
      "    7. HUMAN-RESOURCES              8. DIGITAL-MEDIA                9. EDUCATION                \n",
      "   10. OPERATIONS                  11. DESIGN                      12. LEGAL                    \n",
      "\n",
      "üí° You can also type a custom category name\n",
      "\n",
      "‚úÖ READY TO ANALYZE:\n",
      "   üîç Query: Marketing managers with social media experience\n",
      "   üìÇ Category: MARKETING\n",
      "\n",
      "üì° Sending to AI analysis system...\n",
      "‚è≥ Processing through RAG + Fine-tuned AI + Gemini...\n",
      "‚úÖ Analysis completed in 4.1s\n",
      "\n",
      "============================================================\n",
      "üìä AI ANALYSIS RESULTS\n",
      "============================================================\n",
      "Here's a recruitment assessment based on the provided CV data:\n",
      "\n",
      "**Best Matches:** The \"PR & Event Manager\" and \"DIRECTOR OF SOCIAL MEDIA MARKETING\" candidates are the strongest matches.\n",
      "\n",
      "**Skills & Experience:**\n",
      "\n",
      "*   **PR & Event Manager:** Demonstrates experience in social media strategy, influencer marketing, content creation across multiple platforms, and analyzing social media performance. This candidate highlights follower growth management and community engagement.\n",
      "*   **DIRECTOR OF SOCIAL MEDIA MARKETING:** Has extensive experience leading social media strategy for a major network, managing budgets, agency oversight, and cross-departmental collaboration. Notable achievements include significant community growth and impressions.\n",
      "\n",
      "**Gaps & Concerns:**\n",
      "\n",
      "*   **SOCIAL MEDIA MARKETING MANAGER:** Lacks depth and overall experience\n",
      "*   **SOCIAL MEDIA & COMMUNICATIONS MANAGER:** While experienced, their focus is broader than pure social media marketing.\n",
      "\n",
      "**Recommendation:** The \"DIRECTOR OF SOCIAL MEDIA MARKETING\" would be the better fit.\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéâ Thank you for using AI CV Analysis System!\n",
      "üåü Your production system is ready for real-world use!\n"
     ]
    }
   ],
   "source": [
    "# Cell: FULLY INTERACTIVE CV ANALYSIS SYSTEM\n",
    "print(\"üéØ FULLY INTERACTIVE CV ANALYSIS SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def interactive_cv_analysis():\n",
    "    \"\"\"\n",
    "    Interactive command-line interface for the AI-powered CV Analysis System.\n",
    "    Connects to n8n webhook for processing and provides real-time analysis results.\n",
    "    \"\"\"\n",
    "    # Your n8n webhook URL - this is the endpoint that processes our requests\n",
    "    N8N_WEBHOOK_URL = \"https://mimita22.app.n8n.cloud/webhook-test/cv-analysis\"\n",
    "    \n",
    "    # All available job categories for classification\n",
    "    categories = [\n",
    "        \"INFORMATION-TECHNOLOGY\", \"FINANCE\", \"ENGINEERING\", \"MARKETING\",\n",
    "        \"HEALTHCARE\", \"SALES\", \"HUMAN-RESOURCES\", \"DIGITAL-MEDIA\",\n",
    "        \"EDUCATION\", \"OPERATIONS\", \"DESIGN\", \"LEGAL\"\n",
    "    ]\n",
    "    \n",
    "    # System introduction\n",
    "    print(\"ü§ñ AI-Powered CV Analysis System\")\n",
    "    print(\"üìä Analyzes hundreds of CVs using RAG + Fine-tuned AI\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Main interactive loop\n",
    "    while True:\n",
    "        print(\"\\nüéØ ENTER YOUR ANALYSIS REQUEST\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Get the search query from user\n",
    "        print(\"\\nüîç What skills or positions are you looking for?\")\n",
    "        print(\"   Examples:\")\n",
    "        print(\"   ‚Ä¢ Python developers with Django experience\")\n",
    "        print(\"   ‚Ä¢ Financial analysts with Excel skills\") \n",
    "        print(\"   ‚Ä¢ Marketing managers with social media experience\")\n",
    "        print(\"   ‚Ä¢ Sales professionals with B2B background\")\n",
    "        \n",
    "        query = input(\"\\n‚Üí Enter your query: \").strip()\n",
    "        \n",
    "        # Exit condition\n",
    "        if query.lower() in ['exit', 'quit', 'stop']:\n",
    "            print(\"üëã Thank you for using CV Analysis System!\")\n",
    "            break\n",
    "            \n",
    "        # Validate query\n",
    "        if not query:\n",
    "            print(\"‚ùå Please enter a valid query\")\n",
    "            continue\n",
    "        \n",
    "        # Category selection interface\n",
    "        print(\"\\nüìÇ SELECT A CATEGORY:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"Available categories:\")\n",
    "        \n",
    "        # Display categories in a formatted 3-column layout\n",
    "        for i in range(0, len(categories), 3):\n",
    "            row = categories[i:i+3]\n",
    "            line = \"\"\n",
    "            for j, category in enumerate(row):\n",
    "                line += f\"   {i+j+1:2d}. {category:<25}\"\n",
    "            print(line)\n",
    "        \n",
    "        print(\"\\nüí° You can also type a custom category name\")\n",
    "        \n",
    "        # Category input loop with validation\n",
    "        while True:\n",
    "            category_input = input(\"\\n‚Üí Enter category number or name: \").strip()\n",
    "            \n",
    "            # Allow empty category for broad analysis\n",
    "            if not category_input:\n",
    "                print(\"‚ö†Ô∏è  Using no category - AI will analyze broadly\")\n",
    "                category = \"\"\n",
    "                break\n",
    "                \n",
    "            # Handle numeric category selection\n",
    "            if category_input.isdigit():\n",
    "                category_num = int(category_input) - 1\n",
    "                if 0 <= category_num < len(categories):\n",
    "                    category = categories[category_num]\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"‚ùå Please enter a number between 1 and {len(categories)}\")\n",
    "            else:\n",
    "                # Handle custom category input\n",
    "                category = category_input.upper().replace(' ', '-')\n",
    "                print(f\"‚úÖ Using custom category: {category}\")\n",
    "                break\n",
    "        \n",
    "        # Confirmation before processing\n",
    "        print(f\"\\n‚úÖ READY TO ANALYZE:\")\n",
    "        print(f\"   üîç Query: {query}\")\n",
    "        print(f\"   üìÇ Category: {category if category else 'Any Category'}\")\n",
    "        \n",
    "        confirm = input(\"\\nüöÄ Start AI analysis? (y/n): \").lower()\n",
    "        if confirm not in ['y', 'yes']:\n",
    "            print(\"‚Ü©Ô∏è  Let's try again...\")\n",
    "            continue\n",
    "        \n",
    "        # Processing phase with visual feedback\n",
    "        print(f\"\\nüì° Sending to AI analysis system...\")\n",
    "        print(\"‚è≥ Processing through RAG + Fine-tuned AI + Gemini...\")\n",
    "        \n",
    "        # Animated progress indicator\n",
    "        for i in range(5):\n",
    "            dots = \".\" * (i % 4)\n",
    "            print(f\"üîÑ Analyzing CVs{dots}\", end=\"\\r\")\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        try:\n",
    "            # Send request to n8n webhook with timeout\n",
    "            start_time = time.time()\n",
    "            response = requests.post(\n",
    "                N8N_WEBHOOK_URL,\n",
    "                json={\n",
    "                    \"action\": \"analyze\",\n",
    "                    \"query\": query,\n",
    "                    \"category\": category  # Can be empty string\n",
    "                },\n",
    "                timeout=60  # 60 second timeout for analysis\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            print(f\"‚úÖ Analysis completed in {processing_time:.1f}s\")\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"üìä AI ANALYSIS RESULTS\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Process successful response\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                \n",
    "                # Handle different response formats from n8n\n",
    "                analysis_text = None\n",
    "                \n",
    "                # Format 1: Array response with analysis data\n",
    "                if isinstance(result, list) and len(result) > 0:\n",
    "                    first_item = result[0]\n",
    "                    if isinstance(first_item, dict):\n",
    "                        if 'analysis' in first_item:\n",
    "                            analysis_text = first_item['analysis']\n",
    "                        elif 'data' in first_item and 'analysis' in first_item['data']:\n",
    "                            analysis_text = first_item['data']['analysis']\n",
    "                \n",
    "                # Format 2: Direct dictionary response\n",
    "                elif isinstance(result, dict):\n",
    "                    if 'analysis' in result:\n",
    "                        analysis_text = result['analysis']\n",
    "                    elif 'message' in result:\n",
    "                        print(f\"‚ÑπÔ∏è  {result['message']}\")\n",
    "                        print(\"üí° Check n8n.cloud executions for full results\")\n",
    "                        analysis_text = None\n",
    "                \n",
    "                # Display analysis results\n",
    "                if analysis_text:\n",
    "                    print(analysis_text)\n",
    "                    \n",
    "                    # Save results option\n",
    "                    save = input(f\"\\nüíæ Save this analysis to file? (y/n): \").lower()\n",
    "                    if save in ['y', 'yes']:\n",
    "                        timestamp = int(time.time())\n",
    "                        filename = f\"cv_analysis_{timestamp}.txt\"\n",
    "                        with open(filename, 'w', encoding='utf-8') as f:\n",
    "                            f.write(\"CV ANALYSIS REPORT\\n\")\n",
    "                            f.write(\"=\" * 50 + \"\\n\")\n",
    "                            f.write(f\"Query: {query}\\n\")\n",
    "                            f.write(f\"Category: {category if category else 'Any'}\\n\")\n",
    "                            f.write(f\"Time: {time.ctime()}\\n\")\n",
    "                            f.write(f\"Processing: {processing_time:.1f}s\\n\")\n",
    "                            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                            f.write(analysis_text)\n",
    "                        print(f\"‚úÖ Analysis saved to: {filename}\")\n",
    "                else:\n",
    "                    # Fallback: show raw response\n",
    "                    print(\"üìä Raw response received:\")\n",
    "                    print(json.dumps(result, indent=2))\n",
    "                    \n",
    "            else:\n",
    "                # Handle HTTP errors\n",
    "                print(f\"‚ùå Error: {response.status_code}\")\n",
    "                print(f\"Response: {response.text}\")\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"‚ùå Request timeout - Analysis took too long\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"‚ùå Connection error - Check your internet connection\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Request failed: {e}\")\n",
    "        \n",
    "        # Continue or exit prompt\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        continue_analysis = input(\"\\nüîÑ Analyze another query? (y/n): \").lower()\n",
    "        if continue_analysis not in ['y', 'yes']:\n",
    "            print(\"üéâ Thank you for using AI CV Analysis System!\")\n",
    "            print(\"üåü Your production system is ready for real-world use!\")\n",
    "            break\n",
    "\n",
    "# Start the interactive system\n",
    "interactive_cv_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb7f22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING FLASK APP...\n",
      "‚è≥ Starting Flask server on port 8000...\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://192.168.1.195:8000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Flask connection...\n",
      "‚úÖ Flask app is now RUNNING!\n",
      "üìä Status: {'service': 'CV Analysis API', 'status': 'healthy'}\n"
     ]
    }
   ],
   "source": [
    "# Cell: Start Flask App Immediately\n",
    "print(\"üöÄ STARTING FLASK APP...\")\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import threading\n",
    "\n",
    "# Create Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Your existing Flask routes\n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze_cv():\n",
    "    try:\n",
    "        data = request.json\n",
    "        query = data.get('query', '') or data.get('message', '')\n",
    "        \n",
    "        print(f\"üéØ Query received: '{query}'\")\n",
    "        \n",
    "        # Get the analysis result\n",
    "        analysis_result = enhanced_analyzer.analyze_cv(query)\n",
    "        \n",
    "        # RETURN PROPER STRUCTURE FOR n8n\n",
    "        response_data = {\n",
    "            'analysis': analysis_result,  # This is what n8n expects in $json.analysis\n",
    "            'category': '',\n",
    "            'query': query,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        print(f\"üì§ Sending to n8n: {response_data['analysis'][:100]}...\")\n",
    "        \n",
    "        return jsonify(response_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return jsonify({\n",
    "            'analysis': f\"Error: {str(e)}\",\n",
    "            'category': '',\n",
    "            'query': '',\n",
    "            'status': 'error'\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({'status': 'healthy', 'service': 'CV Analysis API'})\n",
    "\n",
    "# Start Flask in background thread\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=8000, debug=False, use_reloader=False)\n",
    "\n",
    "print(\"‚è≥ Starting Flask server on port 8000...\")\n",
    "flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "flask_thread.start()\n",
    "\n",
    "# Wait for Flask to start\n",
    "import time\n",
    "time.sleep(3)\n",
    "\n",
    "# Test if Flask is running\n",
    "print(\"üîç Testing Flask connection...\")\n",
    "try:\n",
    "    response = requests.get('http://localhost:8000/health', timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Flask app is now RUNNING!\")\n",
    "        print(f\"üìä Status: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Flask started but returned: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Flask not accessible: {e}\")\n",
    "    print(\"üí° Make sure no other app is using port 8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b922b",
   "metadata": {},
   "source": [
    "### Key Innovations:\n",
    "\n",
    "1. **Hybrid AI Approach**: Combines RAG, fine-tuned models, and LLMs\n",
    "2. **Production-Ready**: Modular, scalable, with comprehensive error handling\n",
    "3. **Domain-Specific**: Tailored for HR and recruitment use cases\n",
    "4. **Integration Ready**: REST API, cloud workflows, external access\n",
    "\n",
    "The system represents a state-of-the-art application of modern AI techniques to solve real-world recruitment challenges, providing intelligent, scalable, and actionable candidate analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
